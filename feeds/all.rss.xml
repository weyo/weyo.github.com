<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Let There Be Light</title><link>http://weyo.me/</link><description></description><lastBuildDate>Fri, 15 Jan 2016 00:00:00 +0800</lastBuildDate><item><title>[转]分布式系统经典论文翻译集</title><link>http://weyo.me/pages/techs/distributed-essays-translation-cc/</link><description>&lt;p&gt;最近兴致来了准备研究一下分布式领域的经典论文，顺便把大牛的文章给翻译一下，想想能够做点微小的工作就很激动。结果兴冲冲地跑去查资料才发现，已经有大神（phylips@bmy）把事情做完了：
&lt;a href="http://duanple.blog.163.com/blog/static/709717672011330101333271/"&gt;http://duanple.blog.163.com/blog/static/709717672011330101333271/&lt;/a&gt;，甚至结集出了 PDF 版本。phylips@bmy 整理的论文包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google 论文系列&lt;/li&gt;
&lt;li&gt;分布式理论系列&lt;/li&gt;
&lt;li&gt;数据库理论系列&lt;/li&gt;
&lt;li&gt;大规模存储与计算(NoSql理论系列)&lt;/li&gt;
&lt;li&gt;基本算法和数据结构&lt;/li&gt;
&lt;li&gt;基本系统和实践经验&lt;/li&gt;
&lt;li&gt;其他辅助系统&lt;/li&gt;
&lt;li&gt;Hadoop相关&lt;/li&gt;
&lt;li&gt;其他&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看完了这个目录就没别的想法了，虽然还不是很全面，但基本上已经把分布式领域的文章一网打尽了，而且文章的质量也很不错。不多说了，献上膝盖去看书了~~&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Fri, 15 Jan 2016 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2016-01-15:pages/techs/distributed-essays-translation-cc/</guid><category>分布式计算</category><category>translation</category></item><item><title>Storm 官方文档翻译说明</title><link>http://weyo.me/pages/techs/storm-documents-translation/</link><description>&lt;p&gt;Storm 官方文档翻译转移至并发编程网 &lt;a href="http://ifeve.com/apache-storm/"&gt;Apache Storm 官方文档中文版&lt;/a&gt; 以及 Github - &lt;a href="https://github.com/weyo/Storm-Documents"&gt;Storm Documents&lt;/a&gt;，本站不再提供 Storm 官方文档翻译更新，敬请谅解。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Wed, 12 Aug 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-08-12:pages/techs/storm-documents-translation/</guid><category>Storm</category></item><item><title>Hadoop 源码走读之 Key 的变与不变</title><link>http://weyo.me/pages/techs/mapreduce-how-does-reducetask-manage-key/</link><description>&lt;h1&gt;Issues&lt;/h1&gt;
&lt;p&gt;最近在写 MapReduce Job 时发现 Reducer 输出的结果总是一组完全相同的 Key，而每个 Key 对应的 Value 却不尽相同。以最简单的 word-count 为例，假设我们有一个表示“特征”的对象 &lt;code&gt;Feature&lt;/code&gt;（为简单起见，这里省略了部分构造器、方法）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;Feature&lt;/span&gt; {
    &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;;
    &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="nb"&gt;num&lt;/span&gt;;

    &lt;span class="nv"&gt;@Override&lt;/span&gt;
    &lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;toString&lt;/span&gt;() {
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;.&lt;span class="n"&gt;format&lt;/span&gt;(&lt;span class="s"&gt;&amp;quot;[attribute=%s,num=%d]&amp;quot;&lt;/span&gt;, &lt;span class="n"&gt;attribute&lt;/span&gt;, &lt;span class="nb"&gt;num&lt;/span&gt;);    
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Map 对象读取 sentence 中的第一个 word，并写入 &lt;code&gt;Feature&lt;/code&gt; 对象：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;//map
    private word  = new Text();

    @Override
    public void map(Object key, Text value, Context context)
            throws IOException, InterruptedException {
        String line = value.toString();
        String[] words = line.split(&amp;quot;\\|&amp;quot;);
        String w = words[0];

        word.set(w);
        Feature f = new Feature(w, one);
        context.write(word, f);
    }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在 Reduce 对象中分两步处理，第一步是将收到的同类 &lt;code&gt;Feature&lt;/code&gt; 进行汇总（汇总到一个 &lt;code&gt;HashMap&lt;/code&gt; 中），然后在汇总完毕之后对结果进行统一处理：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="nt"&gt;reduce&lt;/span&gt;
    &lt;span class="nt"&gt;private&lt;/span&gt; &lt;span class="nt"&gt;Map&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;Text&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;Feature&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nt"&gt;map&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;new&lt;/span&gt; &lt;span class="nt"&gt;HashMap&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;Text&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;Feature&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;();&lt;/span&gt;

    &lt;span class="k"&gt;@Override&lt;/span&gt;
    &lt;span class="nt"&gt;public&lt;/span&gt; &lt;span class="nt"&gt;void&lt;/span&gt; &lt;span class="nt"&gt;reduce&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;Text&lt;/span&gt; &lt;span class="nt"&gt;key&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;Iterable&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;Feature&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nt"&gt;values&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;Context&lt;/span&gt; &lt;span class="nt"&gt;context&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
            &lt;span class="nt"&gt;throws&lt;/span&gt; &lt;span class="nt"&gt;IOException&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;InterruptedException&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;Feature&lt;/span&gt; &lt;span class="nt"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;new&lt;/span&gt; &lt;span class="nt"&gt;Feature&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;key&lt;/span&gt;&lt;span class="nc"&gt;.toString&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
        &lt;span class="nt"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;Feature&lt;/span&gt; &lt;span class="nt"&gt;f&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;values&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gather&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;

        &lt;span class="nt"&gt;map&lt;/span&gt;&lt;span class="nc"&gt;.put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;key&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;sum&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="k"&gt;@Override&lt;/span&gt;
    &lt;span class="nt"&gt;public&lt;/span&gt; &lt;span class="nt"&gt;void&lt;/span&gt; &lt;span class="nt"&gt;cleanup&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;Context&lt;/span&gt; &lt;span class="nt"&gt;context&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nt"&gt;throws&lt;/span&gt; &lt;span class="nt"&gt;IOException&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
            &lt;span class="nt"&gt;InterruptedException&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;System&lt;/span&gt;&lt;span class="nc"&gt;.out.println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Within Reduce, we got a map: &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nt"&gt;map&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="nt"&gt;do&lt;/span&gt; &lt;span class="nt"&gt;something&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;运行这个 Job 就会出现类似下面的结果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Within Reduce, we got a map: {Tag=[attribute=Col,num=25], Tag=[attribute=Tag,num=13], Tag=[attribute=Row,num=37]}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这里可以看出，生成的 map 中所有的 key 值完全相同，不同的仅仅是 value 值。&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;Analysis&lt;/h1&gt;
&lt;p&gt;由于 HashMap 是根据对象的哈希值来确定 key 的位置的，而这些 key 值相同却能存放到不同的位置，说明这些 key 对象（这里是 &lt;code&gt;Text&lt;/code&gt; 对象）必然有着不同的哈希值。根据这一点就能逐步推断出问题的根源。&lt;/p&gt;
&lt;h2&gt;Speculation&lt;/h2&gt;
&lt;p&gt;进一步在 debug 模式下运行 Job 可以发现，在 &lt;code&gt;reduce&lt;/code&gt; 方法中，map 的每一个 put 操作都会造成 map 中所有已有的 key 的变化。一开始我认为这可能是由于 &lt;code&gt;reduce&lt;/code&gt; 方法中传入了不同的 &lt;code&gt;Text&lt;/code&gt; 对象，而对象中的值的引用（bytes 数组）相同的缘故造成的。因为 &lt;code&gt;Text&lt;/code&gt; 中的 bytes 数组并不是一个 final 对象，而是在每次 set 的过程中都会变化的。&lt;code&gt;Text&lt;/code&gt; 在写入过程中如果发现输入数据大小与本身的 bytes 大小一致，就会使用 &lt;code&gt;System.arraycopy(utf8, start, bytes, 0, len);&lt;/code&gt; 直接将输入数组拷贝到已有的 bytes 数组中，而不会创建新的 bytes 对象来进行写入操作，也就是说，如果每次写入的对象大小不变，那么 &lt;code&gt;Text&lt;/code&gt; 中的 bytes 域也是不会发生变化的。由于这里的 Job 中处理的 key 都是相同大小的字符串，也就是说 &lt;code&gt;Text&lt;/code&gt; 对象中的引用不会变化，这有可能会导致所有的 &lt;code&gt;Text&lt;/code&gt; 对象共用同一个 bytes 引用，从而出现新的 &lt;code&gt;Text&lt;/code&gt; 对象的变化引起所有对象变化的问题。那么这个问题会不会就是由于这个原因造成的呢？&lt;/p&gt;
&lt;p&gt;答案是否定的。&lt;/p&gt;
&lt;p&gt;上面所述的情况只有可能在一种场景下出现，那就是新的 &lt;code&gt;Text&lt;/code&gt; 对象通过调用旧的 &lt;code&gt;Text&lt;/code&gt; 对象中的 bytes 数组来构造，如下面的这段代码所示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;// A fictitious example
Text oldtext = new Text();
oldtext.set(string1);
Text newtext = new Text(oldtext.getBytes());
newtext.set(string2);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;但是，如果去运行这段代码，你会发现 &lt;code&gt;oldtext&lt;/code&gt; 和 &lt;code&gt;newtext&lt;/code&gt; 并不包含相同的引用，这是因为在构造 &lt;code&gt;Text&lt;/code&gt; 对象时，程序会先通过 &lt;code&gt;setCapacity&lt;/code&gt; 方法来检查自身的 bytes：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  private void setCapacity(int len, boolean keepData) {
    if (bytes == null || bytes.length &amp;lt; len) {
      if (bytes != null &amp;amp;&amp;amp; keepData) {
        bytes = Arrays.copyOf(bytes, Math.max(len,length &amp;lt;&amp;lt; 1));
      } else {
        bytes = new byte[len]; // case when bytes is null
      }
    }
  }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果 bytes 为空（在构造 &lt;code&gt;Text&lt;/code&gt; 时这是成立的），那么会创建一个全新的 bytes 数组，而不会直接复用已有的数组，这也是 &lt;code&gt;Text&lt;/code&gt; 的一种安全性保障机制。&lt;/p&gt;
&lt;p&gt;那么，如果不是这个原因那会是什么原因造成的呢？&lt;/p&gt;
&lt;h2&gt;Hashes in Java&lt;/h2&gt;
&lt;p&gt;我们再回过头来复习下 Java 中使用了哈希算法的集合。在 &lt;code&gt;HashMap&lt;/code&gt; 、&lt;code&gt;HashSet&lt;/code&gt; 这样的集合中，对于对象哈希值的计算都是通过下面的方法实现的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    final int hash(Object k) {
        int h = hashSeed;
        if (0 != h &amp;amp;&amp;amp; k instanceof String) {
            return sun.misc.Hashing.stringHash32((String) k);
        }

        h ^= k.hashCode(); // 哈希计算的关键步骤

        // This function ensures that hashCodes that differ only by
        // constant multiples at each bit position have a bounded
        // number of collisions (approximately 8 at default load factor).
        h ^= (h &amp;gt;&amp;gt;&amp;gt; 20) ^ (h &amp;gt;&amp;gt;&amp;gt; 12);
        return h ^ (h &amp;gt;&amp;gt;&amp;gt; 7) ^ (h &amp;gt;&amp;gt;&amp;gt; 4);
    }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以看出，对于非 String 类型的对象，是通过调用对象本身的 &lt;code&gt;hashCode&lt;/code&gt; 方法来计算哈希值的。这一点对于理解 &lt;code&gt;Text&lt;/code&gt; 对象的一致性非常重要。&lt;/p&gt;
&lt;h2&gt;Hashes in Hadoop&lt;/h2&gt;
&lt;p&gt;再来看 &lt;code&gt;Text&lt;/code&gt; 对象的 &lt;code&gt;hashCode&lt;/code&gt; 实现。&lt;code&gt;Text&lt;/code&gt; 的哈希值计算直接使用的父类 &lt;code&gt;BinaryComparable&lt;/code&gt; 的 &lt;code&gt;hashCode&lt;/code&gt; 方法实现的，而 &lt;code&gt;BinaryComparable&lt;/code&gt; 最终又是通过下面的方法来实现哈希计算的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  public static int hashBytes(byte[] bytes, int offset, int length) {
    int hash = 1;
    for (int i = offset; i &amp;lt; offset + length; i++)
      hash = (31 * hash) + (int)bytes[i];
    return hash;
  }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;也就是说，Hadoop 中的这类序列化对象都是通过字节数组的值来计算哈希值的。如果 &lt;code&gt;Text&lt;/code&gt; 对象包含的内容（也就是 bytes 数组）发生了变化，那么该对象的哈希值也会相应改变；相对的，如果两个 &lt;code&gt;Text&lt;/code&gt; 对象具有相同的字符串内容（也就是 bytes 数组的值相同），那么这两个对象的哈希值就会是相同的。明白了这一点，我们就可以通过 Hadoop 的任务调度机制来最终解决这个问题了。&lt;/p&gt;
&lt;h2&gt;Hadoop Task&lt;/h2&gt;
&lt;p&gt;我们知道，&lt;code&gt;Reducer&lt;/code&gt; 的运行是在 &lt;code&gt;ReducerTask&lt;/code&gt; 中定义的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  void runNewReducer(...) {
    // initializing...
    try {
      reducer.run(reducerContext);
    } finally {
      trackedRW.close(reducerContext);
    }
  }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;由于 &lt;code&gt;Reducer&lt;/code&gt; 默认是以一种循环遍历的方式处理数据的，这里的 &lt;code&gt;reducerContext&lt;/code&gt; 是伴随着 reducer 的整个生命周期的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  public void run(Context context) throws IOException, InterruptedException {
    setup(context);
    try {
      while (context.nextKey()) {
        reduce(context.getCurrentKey(), context.getValues(), context);
        // If a back up store is used, reset it
        Iterator&amp;lt;VALUEIN&amp;gt; iter = context.getValues().iterator();
        if(iter instanceof ReduceContext.ValueIterator) {
          ((ReduceContext.ValueIterator&amp;lt;VALUEIN&amp;gt;)iter).resetBackupStore();        
        }
      }
    } finally {
      cleanup(context);
    }
  }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以看出，这里的 context 通过 &lt;code&gt;nextKey&lt;/code&gt; 来判断是否还有输入值，再调用 &lt;code&gt;getCurrentKey&lt;/code&gt; 和 &lt;code&gt;getValues&lt;/code&gt; 来获取相应的 key 与 values。而 Context 的最终实现类就是 &lt;code&gt;org.apache.hadoop.mapreduce.task.ReduceContextImpl&amp;lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&amp;gt;&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;继续观察 &lt;code&gt;ReduceContextImpl&lt;/code&gt; 会发现，&lt;code&gt;Context&lt;/code&gt; 中的 key 对象是保持不变的，也就是说，key 引用本身不变，改变的只是 key 中的域的取值（类似于添加了 final 关键字的效果）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;private KEYIN key;
key = keyDeserializer.deserialize(key);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;对于 &lt;code&gt;Text&lt;/code&gt; 类型对象，这里的 keyDeserializer 就是 &lt;code&gt;org.apache.hadoop.io.serializer.WritableSerialization.WritableDeserializer&lt;/code&gt;，它的反序列化操作非常简单粗暴：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    public Writable deserialize(Writable w) throws IOException {
      Writable writable;
      if (w == null) {
        writable 
          = (Writable) ReflectionUtils.newInstance(writableClass, getConf());
      } else {
        writable = w;
      }
      writable.readFields(dataIn);
      return writable;
    }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;对于 null 对象，上述方法会创建一个新的 &lt;code&gt;Writable&lt;/code&gt; 对象，而对于已有的对象，则会直接返回原对象，只是在返回之前先读入输入流中的数据。这里的输入流也是在 &lt;code&gt;Context&lt;/code&gt; 中定义好的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;// initialize
private RawKeyValueIterator input;
private DataInputBuffer buffer = new DataInputBuffer();
this.keyDeserializer.open(buffer);

// nextKey()
DataInputBuffer nextKey = input.getKey();
currentRawKey.set(nextKey.getData(), nextKey.getPosition(), 
                  nextKey.getLength() - nextKey.getPosition());
buffer.reset(currentRawKey.getBytes(), 0, currentRawKey.getLength());
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;到这里顺便说一下 &lt;code&gt;RawKeyValueIterator&lt;/code&gt;，它是真正用于获取 sort/merge 过程中产生的原始数据的迭代器。从实际实现类 &lt;code&gt;org.apache.hadoop.mapred.Merger.MergeQueue&amp;lt;K, V&amp;gt;&lt;/code&gt; 的源码中可以看出，它是通过一个基于小根堆结构的 &lt;code&gt;PriorityQueue&lt;/code&gt; 队列来实现有序的数据消费的。&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;从上面的叙述中我们已经知道了，不论数据生产的方式是什么样的，对于 &lt;code&gt;Reducer&lt;/code&gt; 而言，它接收到的 &lt;code&gt;Text&lt;/code&gt; 永远是同一个对象，变化的只是 &lt;code&gt;Text&lt;/code&gt; 中 bytes 的取值。这大概可以称为 reduce 中 key 的不变性。这种对象本身的不变性加上实际取值的变化以及哈希值计算方法，就是造成本文开头所述问题的根本原因。我们再用一段代码来模拟一下 Hadoop 中 Reduce 任务运行的基本过程。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;package&lt;/span&gt; &lt;span class="n"&gt;me&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weyo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mapred&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;testing&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.DataInputStream&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.IOException&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.conf.Configuration&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.DataInputBuffer&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.Text&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.Writable&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.util.GenericOptionsParser&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.util.ReflectionUtils&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="o"&gt;/**&lt;/span&gt;
 &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nd"&gt;@author&lt;/span&gt; &lt;span class="n"&gt;weyo&lt;/span&gt;
 &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nd"&gt;@date&lt;/span&gt; &lt;span class="mi"&gt;2015&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
 &lt;span class="o"&gt;*/&lt;/span&gt;
&lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MapKeys&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;private&lt;/span&gt; &lt;span class="n"&gt;static&lt;/span&gt; &lt;span class="n"&gt;Class&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;writableClass&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;private&lt;/span&gt; &lt;span class="n"&gt;static&lt;/span&gt; &lt;span class="n"&gt;DataInputStream&lt;/span&gt; &lt;span class="n"&gt;dataIn&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;private&lt;/span&gt; &lt;span class="n"&gt;static&lt;/span&gt; &lt;span class="n"&gt;Configuration&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="n"&gt;static&lt;/span&gt; &lt;span class="n"&gt;Writable&lt;/span&gt; &lt;span class="n"&gt;deserialize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Writable&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;Writable&lt;/span&gt; &lt;span class="n"&gt;writable&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;null&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="n"&gt;writable&lt;/span&gt; 
            &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Writable&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;ReflectionUtils&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newInstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;writableClass&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="n"&gt;writable&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;writable&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readFields&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataIn&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;writable&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
      &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="n"&gt;static&lt;/span&gt; &lt;span class="n"&gt;void&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;HashMap&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;map&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="n"&gt;HashMap&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
        &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="err"&gt;模拟一般&lt;/span&gt; &lt;span class="n"&gt;MR&lt;/span&gt; &lt;span class="n"&gt;Job&lt;/span&gt; &lt;span class="err"&gt;的初始化过程&lt;/span&gt;
        &lt;span class="n"&gt;conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Configuration&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="n"&gt;GenericOptionsParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;writableClass&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;Text&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;null&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="n"&gt;Text&lt;/span&gt; &lt;span class="err"&gt;使用&lt;/span&gt; &lt;span class="n"&gt;UTF&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="err"&gt;编码格式&lt;/span&gt;
        &lt;span class="n"&gt;byte&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;obytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;1st&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getBytes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="err"&gt;注意，这里&lt;/span&gt; &lt;span class="nb"&gt;bytes&lt;/span&gt; &lt;span class="err"&gt;第一位必须用于设置内容长度，这是&lt;/span&gt; &lt;span class="n"&gt;Text&lt;/span&gt; &lt;span class="err"&gt;的变长机制决定的&lt;/span&gt;
        &lt;span class="n"&gt;byte&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="nb"&gt;bytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="n"&gt;byte&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;obytes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
        &lt;span class="nb"&gt;bytes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;byte&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;obytes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arraycopy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obytes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;bytes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;obytes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;DataInputBuffer&lt;/span&gt; &lt;span class="nb"&gt;buffer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="n"&gt;DataInputBuffer&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;dataIn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="n"&gt;DataInputStream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="nb"&gt;buffer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;bytes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;bytes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="err"&gt;第一次读入数据&lt;/span&gt;
        &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;deserialize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toString&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;|text.hashCode=&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hashCode&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
        &lt;span class="n"&gt;obytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;2nd&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getBytes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arraycopy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obytes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;bytes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;obytes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="nb"&gt;buffer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;bytes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;bytes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="err"&gt;第二次读入数据&lt;/span&gt;
        &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;deserialize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toString&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;|text.hashCode=&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hashCode&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Map|&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这段代码的输出结果为&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1st|text.hashCode=80561
2nd|text.hashCode=81351
Map|{2nd=2nd, 2nd=1st}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;与我们预想的完全一致。理解了原理之后，我们接下来就可以想办法去解决它。&lt;/p&gt;
&lt;h2&gt;Solutions&lt;/h2&gt;
&lt;h3&gt;Final object&lt;/h3&gt;
&lt;p&gt;考虑下面的 &lt;code&gt;HashSet&lt;/code&gt; 的例子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;HashSet&amp;lt;Date&amp;gt; set = new HashSet&amp;lt;Date&amp;gt;();
Date date = new Date();
set.add(date);
date.setTime(System.currentTimeMillis() + 60000); // 增加 1 分钟时间
set.add(date);
System.out.println(set);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这段代码的输出结果大概是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[Thu Jul 02 19:02:36 CST 2015, Thu Jul 02 19:02:36 CST 2015]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;也就是说 set 中的两个 &lt;code&gt;Date&lt;/code&gt; 对象完全相同（其实就是同一个对象）。这段代码的原理与上文所述的 Hadoop 代码的工作原理完全相同。在这里 &lt;code&gt;HashSet&lt;/code&gt; 实际上是使用了两个 hash 位来保存同一个对象的引用。&lt;code&gt;Date&lt;/code&gt; 是 JDK 中难得的与 &lt;code&gt;Text&lt;/code&gt; 性质相似的对象 —— 拥有可变的 field，并且根据该 field 来计算哈希值。也由于 &lt;code&gt;Date&lt;/code&gt; 的这种可变性，使得 &lt;code&gt;Date&lt;/code&gt; 很多时候对于“时间”这个概念的语义表达并不够准确，所以在 JDK 5 之后的版本也已经不推荐使用 &lt;code&gt;Date&lt;/code&gt; 来表示时间对象（大部分方法被设置为 &lt;code&gt;@Deprecated&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;再回到这个问题上来，既然这个问题是由于 &lt;code&gt;Date&lt;/code&gt; 的可变性引起的，那么将 &lt;code&gt;Date&lt;/code&gt; 转化成某种“不可变”的对象不就可以解决问题了。以下几种方式均可以实现这个目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次向 set 中存入一个新的 &lt;code&gt;Date&lt;/code&gt; 对象：
  &lt;code&gt;set.add(new Date(date.getTime()));&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;HashSet&lt;/code&gt; 不直接处理 &lt;code&gt;Date&lt;/code&gt;，而是处理 &lt;code&gt;Date&lt;/code&gt; 中的 time 域：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;HashSet&amp;lt;Long&amp;gt; set = new HashSet&amp;lt;Long&amp;gt;();
  set.add(date.getTime());&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;而对于本文开始的例子中提到的 reduce 任务，相应的也有两种解决方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;向 map 中存入新的 &lt;code&gt;Text&lt;/code&gt; 对象：
  &lt;code&gt;map.put(new Text(key), sum);&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;HashMap&lt;/code&gt; 直接处理 &lt;code&gt;Text&lt;/code&gt; 中保存的字符串信息：
  &lt;code&gt;Map&amp;lt;String, Feature&amp;gt; map = new HashMap&amp;lt;String, Feature&amp;gt;();
  map.put(key.toString(), sum);&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Different data structure&lt;/h3&gt;
&lt;p&gt;由于这个问题是哈希集合数据结构的特征造成的，那么更换一种数据结构也是可以解决问题的。对于 &lt;code&gt;HashSet&lt;/code&gt; 的例子，可以使用 &lt;code&gt;TreeSet&lt;/code&gt; 来代替；对于 &lt;code&gt;HashMap&lt;/code&gt; 的例子就可以使用 &lt;code&gt;TreeMap&lt;/code&gt; 来代替（前提是 key 必须实现 &lt;code&gt;Comparable&lt;/code&gt; 接口，不过 Hadoop 的序列化对象基本上都符合这个条件）。不过由于 &lt;code&gt;TreeSet&lt;/code&gt; 与 &lt;code&gt;TreeMap&lt;/code&gt; 只允许保存同一个对象的一个引用，这里的 add/put 操作必须针对 new 的新对象。这一点与上面的存入新对象的思路相似，只是使用 Tree 结构之后可以实现更多功能（比如 key 的自动排序），同时也能够更好地定位问题。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Map&amp;lt;Text, Feature&amp;gt; map = new TreeMap&amp;lt;Text, Feature&amp;gt;();
map.put(new Text(key), sum);
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;写到这里差不多该结束了。简单总结一下，由于 MapReduce 在任务调度时使用同一个 &lt;code&gt;Text&lt;/code&gt; 对象来传递数据，所以在直接使用该对象进行规约时就会出现问题。因此，在 &lt;code&gt;Reducer&lt;/code&gt; 中接收新数据时务必要将 &lt;code&gt;Text&lt;/code&gt; 转化为 &lt;code&gt;String&lt;/code&gt; ，或者创建新的 &lt;code&gt;Text&lt;/code&gt; 对象来进行处理（相比之下前一种方法效率可能会更高一点）。对于这个对象不变性问题，本来想向社区提交一个 patch 来改进，但是回过头再想想其实 Hadoop 这么做也无不可。虽然现代的 JVM 对于小对象的频繁创建已经有了很好的性能支持，但是减少创建对象的频率来提高集群性能也没什么错（虽然这点性能提升可能微乎其微），而且 Hadoop 发展了这么多年，到今天这样比较稳定成熟的版本也证明了这种思路没有什么问题。对于程序员来说，不改总比少改好（As we all know the joke, "99 bugs in the code. Fix one bug, compile it down. 167 little bugs in the code....sigh".）。因此，最终还需要我们在编写新任务时理解、注意其中的细节，争取写出具有高鲁棒性的程序。&lt;/p&gt;
&lt;p&gt;That's all.&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;Reference&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://yoyzhou.github.io/blog/2013/05/10/hadoop-serialization-and-writable-object-2/"&gt;http://yoyzhou.github.io/blog/2013/05/10/hadoop-serialization-and-writable-object-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.csdn.net/posa88/article/details/7906426"&gt;http://blog.csdn.net/posa88/article/details/7906426&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.csdn.net/lastsweetop/article/details/9249411"&gt;http://blog.csdn.net/lastsweetop/article/details/9249411&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Thu, 02 Jul 2015 19:13:59 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-07-02:pages/techs/mapreduce-how-does-reducetask-manage-key/</guid><category>Hadoop</category><category>MapReduce</category></item><item><title>Not able to use latest Kafka Consumer API</title><link>http://weyo.me/pages/techs/not-able-to-use-latest-kafka-consumer-api/</link><description>&lt;p&gt;Days ago I was to get start with the newest Kafka document &lt;a href="http://kafka.apache.org/documentation.html"&gt;http://kafka.apache.org/documentation.html&lt;/a&gt; to learn about Kafka. But I meet some problem when I try to use the new Consumer API. I'd done the job with following steps:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Add a new dependency&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.kafka&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;kafka-clients&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;0.8.2.1&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;2. Add configurations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Latest documents did not contains such configurable things, it took me a while to figure out how &lt;code&gt;KafkaProducer&lt;/code&gt; works, and I used some similar configurations to set the config map&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="nt"&gt;Map&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nt"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;new&lt;/span&gt; &lt;span class="nt"&gt;HashMap&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;();&lt;/span&gt;
    &lt;span class="nt"&gt;config&lt;/span&gt;&lt;span class="nc"&gt;.put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ConsumerConfig&lt;/span&gt;&lt;span class="nc"&gt;.BOOTSTRAP_SERVERS_CONFIG&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;host:9092&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="nt"&gt;config&lt;/span&gt;&lt;span class="nc"&gt;.put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ConsumerConfig&lt;/span&gt;&lt;span class="nc"&gt;.GROUP_ID_CONFIG&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="nt"&gt;config&lt;/span&gt;&lt;span class="nc"&gt;.put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ConsumerConfig&lt;/span&gt;&lt;span class="nc"&gt;.KEY_DESERIALIZER_CLASS_CONFIG&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
            &lt;span class="nt"&gt;StringDeserializer&lt;/span&gt;&lt;span class="nc"&gt;.class.getName&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
    &lt;span class="nt"&gt;config&lt;/span&gt;&lt;span class="nc"&gt;.put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ConsumerConfig&lt;/span&gt;&lt;span class="nc"&gt;.VALUE_DESERIALIZER_CLASS_CONFIG&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
            &lt;span class="nt"&gt;StringDeserializer&lt;/span&gt;&lt;span class="nc"&gt;.class.getName&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
    &lt;span class="nt"&gt;config&lt;/span&gt;&lt;span class="nc"&gt;.put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ConsumerConfig&lt;/span&gt;&lt;span class="nc"&gt;.PARTITION_ASSIGNMENT_STRATEGY&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;range&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;3. Use KafkaConsumer API&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;KafkaConsumer&amp;lt;String, String&amp;gt; consumer = new KafkaConsumer&amp;lt;String, String&amp;gt;(config);
consumer.subscribe(&amp;quot;topic&amp;quot;);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;However, when I try to poll message from the broker, I got nothing but null:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Map&amp;lt;String, ConsumerRecords&amp;lt;String, String&amp;gt;&amp;gt; records = consumer.poll(0);
if (records != null)
    process(records);
else
    System.err.println(&amp;quot;null&amp;quot;);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And then I know what's wrong with the consumer after I checked the source code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@Override
public Map&amp;lt;String, ConsumerRecords&amp;lt;K,V&amp;gt;&amp;gt; poll(long timeout) {
    // TODO Auto-generated method stub
    return null;
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To make matters worse, I couldnot find any other useful information about the 0.8.2 API, since all usages about Kafka were not compatible with the latest version. I had to ask a &lt;a href="https://stackoverflow.com/questions/30857650/how-to-use-consumer-api-of-kafka-0-8-2"&gt;question&lt;/a&gt; on SO, wishing to get some helpful advice.&lt;/p&gt;
&lt;p&gt;Unfortunately, I could only get a bad news after ten days waiting:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;--- &lt;em&gt;&lt;a href="https://stackoverflow.com/users/595943/habsq"&gt;@habsq&lt;/a&gt;&lt;/em&gt; ---&lt;br /&gt;
The new KafkaConsumer API will only be available in 0.8.3 &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Future+release+plan"&gt;cwiki.apache.org/confluence/display/KAFKA/Future+release+plan&lt;/a&gt;. Apparently there are some implementation in the trunk, although I have no clue about the state. For the time being I'm using the old consumer implementation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Oops, documents could also lie, that's so sad (x﹏x)&lt;/p&gt;
&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Wed, 01 Jul 2015 20:41:56 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-07-01:pages/techs/not-able-to-use-latest-kafka-consumer-api/</guid><category>Kafka</category></item><item><title>高分辨率下 Gnome 的优化</title><link>http://weyo.me/pages/techs/make-gnome-look-good-on-high-resolution-displays/</link><description>&lt;p&gt;这两天给 Surface Pro 装了个 VirtualBox 虚拟机，系统镜像是 Fedora 22。安装过程一切顺利（纯傻瓜式操作，不得不承认，O 家虽然还是法务部门最牛X，但开(shou)源(gou)的产品做得也还是很不错的），而且即使在只分配了 1G 内存的情况下系统运行也挺顺畅。唯一不满意的就是那可恶的小窗口了。&lt;/p&gt;
&lt;p&gt;一开始只是 VirtualBox 中虚拟机系统窗口很小：&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="pic1" src="../../../images/pics/make-gnome-look-good-on-high-resolution-displays/fig1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;在按照 &lt;a href="http://blog.csdn.net/xubinlxb/article/details/18092297"&gt;VirtualBox虚拟机 Ubuntu分辨率太小的解决方案&lt;/a&gt; 中所说的“安装增强功能”之后，这个问题没有了，系统终于可以真正地全屏了：&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="pic2" src="../../../images/pics/make-gnome-look-good-on-high-resolution-displays/fig2.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;但是这样更新之后系统的实际显示字体还是很小。（到这里就想吐槽下 Win 系的桌面，由于 SP3 是 2160×1440 的高分辨率，而很多应用程序（包括 MS 自身的很多软件）都没有为这种分辨率进行优化，导致系统的正常使用极为别扭，即使调整了显示倍数还是有很多软件的界面不是太大就是太小，严重降低了用户体验。）在 &lt;a href="http://www.pcworld.com/article/2911509/how-to-make-linuxs-desktop-look-good-on-high-resolution-displays.html"&gt;How to make Linux's desktop look good on high-resolution displays&lt;/a&gt; 的建议下，安装 Gnome 的 tweak-tool&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo yum install gnome-tweak-tool
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;然后在 tweak-tool 里将 “Windows” --&amp;gt; “HiDPI” 的值由 1 设置为 2，确认之后，就会发现这个世界还是很美好的 :-)&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="pic3" src="../../../images/pics/make-gnome-look-good-on-high-resolution-displays/fig3.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;BTW，Fedora 的壁纸还是很赞的。
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="pic4" src="../../../images/pics/make-gnome-look-good-on-high-resolution-displays/fig4.png" /&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Mon, 29 Jun 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-29:pages/techs/make-gnome-look-good-on-high-resolution-displays/</guid><category>Gnome</category></item><item><title>Storm 官方文档翻译(13) —— FAQ</title><link>http://weyo.me/pages/techs/storm-translations-faq/</link><description>&lt;h1&gt;FAQ&lt;/h1&gt;
&lt;h2&gt;Storm 最佳实践&lt;/h2&gt;
&lt;h3&gt;关于配置 Storm + Trident 的建议&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;worker 的数量最好是服务器数量的倍数；topology 的总并发度(parallelism)最好是 worker 数量的倍数；Kafka 的分区数(partitions)最好是 Spout（特指 &lt;code&gt;KafkaSpout&lt;/code&gt;）并发度的倍数&lt;/li&gt;
&lt;li&gt;在每个机器（supervisor）上每个拓扑应用只配置一个 worker&lt;/li&gt;
&lt;li&gt;在拓扑最开始运行的时候设置使用较少的大聚合器，并且最好是每个 worker 进程分配一个&lt;/li&gt;
&lt;li&gt;使用独立的调度器（scheduler）来分配任务（关于Scheduler 的知识请参考 &lt;a href="https://xumingming.sinaapp.com/854/twitter-storm-pluggable-scheduler/"&gt;xumingming 的博客&lt;/a&gt; —— 译者注）&lt;/li&gt;
&lt;li&gt;在每个 worker 上只配置使用一个 acker —— 这是 0.9.x 版本的默认特性，不过在早期版本中有所不同&lt;/li&gt;
&lt;li&gt;在配置文件中开启 GC 日志记录；如果一切正常，日志中记录的 major GC 应该会非常少&lt;/li&gt;
&lt;li&gt;将 trident 的 batch interval 配置为你的集群的端到端时延的 50% 左右&lt;/li&gt;
&lt;li&gt;开始时设置一个很小的 &lt;code&gt;TOPOLOGY_MAX_SPOUT_PENDING&lt;/code&gt;（对于 trident 可以设置为 1，对于一般的 topology 可以设置为 executor 的数量），然后逐渐增大，直到数据流不再发生变化。这时你可能会发现结果大约等于 &lt;code&gt;“2 × 吞吐率(每秒收到的消息数) × 端到端时延”&lt;/code&gt; （最小的额定容量的2倍）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;如何避免 worker 总是出现莫名其妙的故障的问题&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;确保 Storm 对你的日志目录有写权限&lt;/li&gt;
&lt;li&gt;确保你的堆内存没有溢出&lt;/li&gt;
&lt;li&gt;确保所有的 worker 上都已经正确地安装了所有的依赖库文件&lt;/li&gt;
&lt;li&gt;确保 ZooKeeper 的 hostname 不是简单地设置为 “localhost”&lt;/li&gt;
&lt;li&gt;确保集群中的每台机器上都配置好了正确、唯一的 hostname，并且这些 hostname 需要配置在所有机器的 Storm 配置文件中&lt;/li&gt;
&lt;li&gt;确保 a) 不同的 worker 之间，b) 不同的 Storm 节点之间，c) Storm 与 ZooKeeper 集群之间， d) 各个 worker 与拓扑运行所需要的 Kafka/Kestrel/其他数据库等 之间没有开启防火墙或者其他安全保护机制；如果有，请使用 netstat 来为各个端口之间的通信授权&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Help！Storm 使用过程中无法获取：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;日志文件&lt;/strong&gt;：日志文件默认记录在 &lt;code&gt;$STORM_HOME/logs&lt;/code&gt; 目录中。请检查你对该目录是否有写权限。具体的日志配置信息位于 logback/cluster.xml 文件中（0.9 之前的版本需要在 log4j/*.properties 配置文件中进行配置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最终输出的 JVM 设置&lt;/strong&gt;：需要在配置文件（storm.yaml）的 &lt;code&gt;childopts&lt;/code&gt; 配置项中添加 &lt;code&gt;-XX+PrintFlagsFinal&lt;/code&gt; 命令选项。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最终输出的 Java 系统属性信息&lt;/strong&gt;：需要在你构建拓扑的位置添加代码 &lt;code&gt;Properties props = System.getProperties(); props.list(System.out);&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;我应该使用多少个 worker？&lt;/h3&gt;
&lt;p&gt;worker 的完整数量是由 supervisor 配置的。每个 supervisor 会分配到一定数量的 JVM slot，你在拓扑中设置的 worker number 就是以这个 slot 数量为依据进行分配的。&lt;/p&gt;
&lt;p&gt;不建议为每个拓扑在每台机器上分配超过一个 worker。&lt;/p&gt;
&lt;p&gt;假如有一个运行于三台 8 核服务器节点的拓扑，它的并行度为24，每个 bolt 在每台机器上分配有 8 个 executor（即每个 CPU 核心分配一个）。这种场景下，使用三个 worker （每个 worker 分配 8 个executor）相对于使用更多的 worker （比如使用 24 个 worker，为每个 executor 分别分配一个）有三点好处：&lt;/p&gt;
&lt;p&gt;首先，在 worker 内部将数据流重新分区到不同的 executor 的操作（比如 shuffle 或者 group-by）就不会产生触发到传输 buffer 缓冲区，tuple 会直接从发送端转储到接收端的 buffer 区。这一点有很大的优势。相反，如果目标 executor 是在同一台机器的不同 worker 进程内，tuple 就需要经历“发送 -&amp;gt; worker 传输队列 -&amp;gt; 本地 socket 端口 -&amp;gt; 接收端 worker -&amp;gt; 接收端 executor”这样一个漫长的过程。虽然这个过程并不会产生网络级传输，但是在同一台机器的不同进程间的传输损耗也是很可观的。&lt;/p&gt;
&lt;p&gt;其次，三个大的聚合器带来的大的缓存空间比 24 个小聚合器带来的小缓存空间要有用得多。因为这回降低数据倾斜造成的影响，同时提高 LRU 的性能。&lt;/p&gt;
&lt;p&gt;最后，更少的 worker 可以有效地降低控制流的频繁变动。&lt;/p&gt;
&lt;h2&gt;拓扑&lt;/h2&gt;
&lt;h3&gt;Trident 拓扑支持多数据流吗&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Trident 拓扑可以设计成条件路径（if-else）的工作流形式吗？例如，bolt0 在接收 spout 的数据流时，可以根据输入 tuple 的值来选择将数据流发送到 bolt1 或者 bolt2，而不是同时向两个 bolt 发送。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Trident 的 “each” 运算符可以返回一个数据流对象，你可以将该对象存储在某个变量中，然后你可以对同一个数据流执行多个 each 操作来分解该数据流，如下述代码所示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Stream&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;topology&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;each&lt;/span&gt;&lt;span class="o"&gt;(...).&lt;/span&gt;&lt;span class="na"&gt;groupBy&lt;/span&gt;&lt;span class="o"&gt;(...).&lt;/span&gt;&lt;span class="na"&gt;aggregate&lt;/span&gt;&lt;span class="o"&gt;(...)&lt;/span&gt; 
&lt;span class="n"&gt;Stream&lt;/span&gt; &lt;span class="n"&gt;branch1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;each&lt;/span&gt;&lt;span class="o"&gt;(...,&lt;/span&gt; &lt;span class="n"&gt;FilterA&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; 
&lt;span class="n"&gt;Stream&lt;/span&gt; &lt;span class="n"&gt;branch2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;each&lt;/span&gt;&lt;span class="o"&gt;(...,&lt;/span&gt; &lt;span class="n"&gt;FilterB&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;你可以使用 join、merge 或者 multiReduce 来联结各个数据流。&lt;/p&gt;
&lt;p&gt;到目前为止，Trident 暂时不支持输出多个数据流。（详见 &lt;a href="https://issues.apache.org/jira/browse/STORM-68"&gt;STORM-68&lt;/a&gt;）&lt;/p&gt;
&lt;h2&gt;Spout&lt;/h2&gt;
&lt;h3&gt;Coordinator 是什么，为什么会有很多 Coordinator？&lt;/h3&gt;
&lt;p&gt;Trident spout 实际上是通过 Storm 的 bolt 运行的。&lt;code&gt;MasterBatchCoordinator&lt;/code&gt;（MBC）封装了 Trident 拓扑的 spout，它负责整合 Trident 中的 batch，这一点对于你所使用的任何类型的 spout 而言都是一样的。Trident 的 batch 就是在 MBC 向各个 spout-coordinator 分发种子 tuple 的过程中生成的。Spout-coordinator bolt 知道你所定义的 spout 是如何互相协作的 —— 实际上，在使用 Kafka 的情况下，各个 spout 就是通过 spout-coordinator 来获取 pull 消息所需要的 partition 和 offset 信息的。&lt;/p&gt;
&lt;h3&gt;在 spout 的 metadata 记录中能够存储什么信息？&lt;/h3&gt;
&lt;p&gt;只能存储少量静态数据，而且是越少越好（尽管你确实可以向其中存储更多的信息，不过我们不推荐这样做）。&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;emitPartitionBatchNew&lt;/code&gt; 函数是多久调用一次的？&lt;/h3&gt;
&lt;p&gt;由于在 Trident 中 MBC 才是实际运行的 spout，一个 batch 中的所有 tuple 都是 MBC 生成的 tuple 树的节点。也就是说，Storm 的 “max spout pending” 参数实际上定义的是可以并发运行的 batch 数量。MBC 在满足以下两个条件下会发送出一个新的 batch：首先，挂起的 tuple 数需要小于 “max pending” 参数；其次，距离上一个 batch 的发送已经过去了至少一个 &lt;a href="https://github.com/apache/storm/blob/master/conf/defaults.yaml#L115"&gt;trident batch interval&lt;/a&gt; 的间隔时间。&lt;/p&gt;
&lt;h3&gt;如果没有数据发送，Trident 会降低发送频率吗？&lt;/h3&gt;
&lt;p&gt;是的，Storm 中有一个可选的 “spout 等待策略”，默认配置是 sleep 一段指定的&lt;a href="https://github.com/apache/storm/blob/master/conf/defaults.yaml#L110"&gt;配置时间&lt;/a&gt;。&lt;/p&gt;
&lt;h3&gt;Trident batch interval 参数有什么用？&lt;/h3&gt;
&lt;p&gt;你知道 486 时代的计算机上面为什么有个 &lt;a href="http://en.wikipedia.org/wiki/Turbo_button"&gt;trubo button&lt;/a&gt; 吗？这个参数的作用和这个按钮有点像。&lt;/p&gt;
&lt;p&gt;实际上，trident batch interval 有两个用处。首先，它可以用于减缓 spout 从远程数据源获取数据的速度，但这不会影响数据处理的效率。例如，对于一个从给定的 S3 存储区中读取批量上传文件并按行发送数据的 spout，我们就不希望它经常触发 S3 的阈值，因为文件要隔几分钟才会上传一次，而且每个 batch 也需要花费一定的时间来执行。&lt;/p&gt;
&lt;p&gt;另一个用处是限制启动期间或者突发数据负载情况下内部消息队列的负载压力。如果 spout 突然活跃起来，并向系统中挤入了 10 个 batch 的记录，那么可能会有从 batch7 开始的大量不紧急的 tuple 堵塞住传输缓冲区，并且阻塞了从 batch3 中的 tuple（甚至可能包含 batch3 中的部分旧 tuple）的 commit 过程&lt;sup&gt;#&lt;/sup&gt;。对于这种情况，我们的解决方法就是将 trident batch interval 设置为正常的端到端处理时延的一半左右 —— 也就是说如果需要花费 600 ms 的时间处理一个 batch，那么就可以每 300 ms 处理一个 batch。&lt;/p&gt;
&lt;p&gt;注意，这个 300 ms 仅仅是一个上限值，而不是额外增加的延时时间，如果你的 batch 需要花费 258 ms 来运行，那么 Trident 就只会延时等待 42 ms。&lt;/p&gt;
&lt;h3&gt;如何设置 batch 大小？&lt;/h3&gt;
&lt;p&gt;Trident 本身不会对 batch 进行限制。不过如果使用 Kafka 的相关 spout，那么就可以使用 max fetch bytes 大小除以 平均 record 大小来计算每个子 batch 分区的有效 record 大小。&lt;/p&gt;
&lt;h3&gt;怎样重新设置 batch 的大小？&lt;/h3&gt;
&lt;p&gt;Trident 的 batch 在某种意义上是一种过载的设施。batch 大小与 partition 的数量均受限于或者是可以用于定义&lt;sup&gt;#&lt;/sup&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;事务安全单元（一段时间内存在风险的 tuple）；&lt;/li&gt;
&lt;li&gt;相对于每个 partition，一个用于窗口数据流分析的有效窗口机制；&lt;/li&gt;
&lt;li&gt;相对于每个 partition，使用 partitionQuery，partitionPersist 等命令时能够同时进行的查询操作数量；&lt;/li&gt;
&lt;li&gt;相对于每个 partition，spout 能够同时分配的 record 数量。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;不能在 batch 生成之后更改 batch 的大小，不过可以通过 shuffle 操作以及修改并行度的方式来改变 partition 的数量。&lt;/p&gt;
&lt;h2&gt;时间相关问题&lt;/h2&gt;
&lt;h3&gt;怎样基于指定时间聚合数据&lt;/h3&gt;
&lt;p&gt;对于带有固定时间戳的 records，如果需要对他们执行计数、求均值或者聚合操作，并将结果整合到离散的时间桶（time bucket）中，Trident 是一个很好的具有可扩展性的解决方案。&lt;/p&gt;
&lt;p&gt;这种情况下可以写一个 &lt;code&gt;each&lt;/code&gt; 函数来将时间戳置入一个时间桶中：如果桶的大小是以“小时”为单位的，那么时间戳 &lt;code&gt;2013-08-08 12:34:56&lt;/code&gt; 就会被匹配到 &lt;code&gt;2013-08-08 12:00:00&lt;/code&gt; 桶中，其他的 12 时到 13 时之间的时间也一样。然后可以使用 &lt;code&gt;persistentAggregate&lt;/code&gt; 来对时间桶分组。&lt;code&gt;persistentAggregate&lt;/code&gt; 会使用一个基于数据存储的本地 cacheMap。这些包含有大量 records 的 group 会使用高效的批量读取/写入方式对数据存储区进行操作，所以并不会对数据存储区进行大量的读操作；只要你的数据传送足够快捷，Trident 就可以高效地使用内存与网络。即使某台服务器宕机了一天，需要重新快速地发送一整天的数据，旧有的结果也可以静默地获取到并进行更新，并且这并不会影响当前结果的计算过程。&lt;/p&gt;
&lt;h3&gt;怎么才能知道某个时间桶中已经收到了所有需要的 record？&lt;/h3&gt;
&lt;p&gt;很遗憾，你不会知道什么时候所有的 event 都已经采集到了 —— 这是一个认识论问题，而不是一个分布式系统的问题。你可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用域相关知识来设定时间限制。&lt;/li&gt;
&lt;li&gt;引入标记机制：对于一个指定时间窗，确定某个 record 会处在所有的 record 的最后位置。Trident 使用这个机制来判断一个 batch 是否结束。例如，你收到一组传感器采集到的 records，每个传感器都是按顺序发送数据的，那么一旦所有的传感器都发送出一个 “3:02:xx” 的数据，你就可以知道可以开始处理这个时间窗了。&lt;/li&gt;
&lt;li&gt;如果可以的话，尽量使你的处理过程增量化：每个新来的值都会使结果越来越准确。Trident ReducerAggregator 就是一个可以通过一个旧有的结果以及一组新数据来返回一个更新的结果的运算符。这使得结果可以被缓存并序列化到一个数据库中；如果某台服务器宕机了一天，在恢复运行之后需要重新快速地发送一整天的数据，旧有的结果也可以静默地获取到并进行更新。&lt;/li&gt;
&lt;li&gt;使用 Lambda 架构：将所有收到的事件数据归档到存储区中（S3，HBase，HDFS）。在快速处理层，一旦时间窗复位，就对对应的时间桶进行处理来获取有效结果，并且在处理过程中跳过所有比早于该时间窗的过期数据。定期地执行全局聚合操作就可以计算出一个较“正确”的结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;h2&gt;&lt;em&gt;附注&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup&gt;#&lt;/sup&gt; 此处译文可能不够准确，有疑问的读者请参考原文对应内容。&lt;/p&gt;
&lt;/blockquote&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sun, 28 Jun 2015 23:10:35 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-28:pages/techs/storm-translations-faq/</guid><category>Storm</category><category>Translation</category></item><item><title>How does HashMap.keySet() return a keySet</title><link>http://weyo.me/pages/techs/how-does-hashmap-keySet-return-a-keyset/</link><description>&lt;h2&gt;Question&lt;/h2&gt;
&lt;p&gt;Recently when I looked over &lt;code&gt;HashMap&lt;/code&gt;, I found an interesting thing about the &lt;code&gt;keySet&lt;/code&gt; method (and then asked a question on &lt;a href="https://stackoverflow.com/questions/30708380/how-do-hashmap-values-and-hashmap-keyset-return-values-and-keys"&gt;StackOverflow&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The source code of HashMap.keySet() is shown as follows&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;Set&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;keySet&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;Set&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;ks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keySet&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ks&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="n"&gt;ks&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;keySet&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;KeySet&lt;/span&gt;&lt;span class="o"&gt;()));&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, when the keySet() method first called, it just returns a &lt;code&gt;KeySet&lt;/code&gt; object. The &lt;code&gt;KeySet&lt;/code&gt; object is a subclass of &lt;code&gt;AbstractSet&lt;/code&gt; with an empty constructor, and contains no element.&lt;/p&gt;
&lt;p&gt;Source codes of &lt;code&gt;KeySet&lt;/code&gt; and &lt;code&gt;AbstractSet&lt;/code&gt; are shown below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;KeySet&lt;/span&gt; &lt;span class="kd"&gt;extends&lt;/span&gt; &lt;span class="n"&gt;AbstractSet&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;Iterator&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;iterator&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;newKeyIterator&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;size&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;boolean&lt;/span&gt; &lt;span class="nf"&gt;contains&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;containsKey&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;boolean&lt;/span&gt; &lt;span class="nf"&gt;remove&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;HashMap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;removeEntryForKey&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;clear&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;HashMap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;clear&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;abstract&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;AbstractSet&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="kd"&gt;extends&lt;/span&gt; &lt;span class="n"&gt;AbstractCollection&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="kd"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;Set&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="cm"&gt;/**&lt;/span&gt;
&lt;span class="cm"&gt;     * Sole constructor.  (For invocation by subclass constructors, typically&lt;/span&gt;
&lt;span class="cm"&gt;     * implicit.)&lt;/span&gt;
&lt;span class="cm"&gt;     */&lt;/span&gt;
    &lt;span class="kd"&gt;protected&lt;/span&gt; &lt;span class="nf"&gt;AbstractSet&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="c1"&gt;// some other methods&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But when you call the method like this&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Collection&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;keySet&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;keySet&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;keySet&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;the method returns a set rapidly, and you can get a set of keys shown on the screen.&lt;/p&gt;
&lt;p&gt;Not only keySet(), but also values() and entrySet() method could do similar things.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What happened here? Is there any magical thing in Java?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yes, there is really a "magician" do some incredible things here, and his magic wand is called &lt;code&gt;Iterator&lt;/code&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Answer&lt;/h2&gt;
&lt;p&gt;Let's start off with how you would use the method in a program. When you first call &lt;code&gt;keySet&lt;/code&gt;, it returns a &lt;code&gt;KeySet&lt;/code&gt; object. However, the object does contain an implicit reference to the &lt;code&gt;HashMap&lt;/code&gt; object created it which means it's an inner class of &lt;code&gt;HashMap&lt;/code&gt; rather than contains nothing.&lt;/p&gt;
&lt;p&gt;Now we get an Set object, but it contains no element of the given type(that is, the generic type of HashMap's key). Then we use a &lt;code&gt;println&lt;/code&gt; method to print the set. When &lt;code&gt;println&lt;/code&gt; is ready to print a non-String object, it will call &lt;code&gt;object.toString()&lt;/code&gt; method to change the object to a String object like this&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;valueOf&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="kd"&gt;synchronized&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
            &lt;span class="n"&gt;newLine&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;AbstractCollection&lt;/code&gt; uses an iterator to iterate its elements in &lt;code&gt;toString&lt;/code&gt; method&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="nf"&gt;toString&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="c1"&gt;// iterator() method is called here&lt;/span&gt;
        &lt;span class="n"&gt;Iterator&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iterator&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(!&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;hasNext&lt;/span&gt;&lt;span class="o"&gt;())&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;[]&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

        &lt;span class="n"&gt;StringBuilder&lt;/span&gt; &lt;span class="n"&gt;sb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;StringBuilder&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;append&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;[&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(;;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;E&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;next&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
            &lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;append&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="k"&gt;this&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;(this Collection)&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(!&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;hasNext&lt;/span&gt;&lt;span class="o"&gt;())&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;append&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;]&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="na"&gt;toString&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
            &lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;append&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="na"&gt;append&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="sc"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And now we find something familiar -- the &lt;code&gt;iterator&lt;/code&gt; method. As we talked above, this method would return a &lt;code&gt;newKeyIterator&lt;/code&gt; object, which also associated to the &lt;code&gt;HashMap&lt;/code&gt; object and then used by &lt;code&gt;toString&lt;/code&gt; method to iterate such &lt;code&gt;HashMap&lt;/code&gt; object. Then, we can get a "set" of keys after &lt;code&gt;toString&lt;/code&gt; method returned. Finally the "set" will be printed by &lt;code&gt;println&lt;/code&gt; method, and we also know how that "magic wand" works.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Some more things&lt;/h2&gt;
&lt;p&gt;Someone uses an IDE(like Eclipse) to develop program might have another question: when a breakpoint is set at the &lt;code&gt;Collection&amp;lt;String&amp;gt; keySet = map.keySet();&lt;/code&gt; line in IDE, run the program as debug mode, and step over the line, the IDE will show that the variable values has been a collection filled with all keys of Hashmap, rather than an object only with an reference to the HashMap object, what happened here?&lt;/p&gt;
&lt;p&gt;You might have guessed that "Someone" is me, and yep, you are right :D I knew the iterator things but was still confused with this question for a long time. The question comes from the fact that when moving the mouse to hover over the values variable, or just clicking the values variable in the Variables view, there would be a small window with all keys in the keySet variable. Nevertheless, that's actually not a question as clicking variable in the Variables view just means executing the &lt;code&gt;toString&lt;/code&gt; method and you know what will happen next.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Inner classes &lt;code&gt;KeySet&lt;/code&gt;, &lt;code&gt;Values&lt;/code&gt; and &lt;code&gt;EntrySet&lt;/code&gt; do not contains any explicit fields except a implicit reference to the &lt;code&gt;HashMap&lt;/code&gt; object which created them. Every time you call &lt;code&gt;keySet()&lt;/code&gt;, &lt;code&gt;values()&lt;/code&gt; or &lt;code&gt;entrySet()&lt;/code&gt; methods, they just return such "empty" objects, and do nothing until &lt;code&gt;iterator&lt;/code&gt; method is called. That means the so-called &lt;code&gt;keySet&lt;/code&gt;, &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;entrySet&lt;/code&gt; are all varied with the &lt;code&gt;HashMap&lt;/code&gt; object contemporaneously. That's why we can always get the latest mapper of the related &lt;code&gt;HashMap&lt;/code&gt; object.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Thank &lt;a href="https://stackoverflow.com/users/4271479/mastov"&gt;@mastov&lt;/a&gt; and &lt;a href="https://stackoverflow.com/users/1221571/eran"&gt;@Eran&lt;/a&gt; for excellent answers.&lt;/p&gt;
&lt;p&gt;Every time I take a look at source codes of kinds of frameworks, I can always find some interesting new things. That's actually what makes programming so charming :-)&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sun, 28 Jun 2015 18:49:45 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-28:pages/techs/how-does-hashmap-keySet-return-a-keyset/</guid><category>Java</category></item><item><title>Storm 官方文档翻译(12) —— 问题与解决</title><link>http://weyo.me/pages/techs/storm-translations-troubleshooting/</link><description>&lt;h1&gt;问题与解决&lt;/h1&gt;
&lt;p&gt;本文介绍了用户在使用 Storm 过程中遇到的问题与相应的解决方法。&lt;/p&gt;
&lt;h2&gt;Worker 进程在启动时挂掉而没有留下堆栈跟踪信息的问题&lt;/h2&gt;
&lt;p&gt;可能出现的现象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拓扑在一个节点上运行正常，但是多个 worker 进程在多个节点上就会崩溃&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;解决方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你的网络配置可能有问题，导致每个节点无法根据 hostname 连接到其他的节点。ZeroMQ 有时会在不能识别 host 的时候挂掉 进程。如果是这种情况，有两种可行的解决方案：&lt;ul&gt;
&lt;li&gt;在 /etc/hosts 文件中配置好 hostname 与 IP 的对应关系&lt;/li&gt;
&lt;li&gt;设置一个局域网 DNS 服务器，使得节点可以根据 hostname 定位到其他节点&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;节点之间无法通信&lt;/h2&gt;
&lt;p&gt;可能出现的现象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个 spout tuple 的处理都不成功&lt;/li&gt;
&lt;li&gt;拓扑中的处理过程不起作用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;解决方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Storm 不支持 ipv6，你可以在 supervisor 的 child-opts 配置中添加 &lt;code&gt;-Djava.net.preferIPv4Stack=true&lt;/code&gt; 参数，然后重启 supervisor。&lt;/li&gt;
&lt;li&gt;你的网络配置可能存在问题，请参考上个问题中的解决方案。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;拓扑在一段时间后停止了 tuple 的处理过程&lt;/h2&gt;
&lt;p&gt;可能出现的现象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拓扑正常运行一段时间后突然停止了数据处理过程，并且 spout 的 tuple 一起开始处理失败&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;解决方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这是 ZeroMQ 2.1.10 中的一个已经确认的问题，请将 ZMQ 降级到 2.1.7 版本。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Storm UI 中没有显示出所有的 supervisor 信息&lt;/h2&gt;
&lt;p&gt;可能出现的现象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Storm UI 中缺少部分 supervisor 的信息&lt;/li&gt;
&lt;li&gt;在刷新 Storm UI 页面后 supervisor 列表会变化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;解决方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;确保 supervisor 的本地工作目录是相互独立的（也就是说不要出现在 NFS 中共享同一个目录的情况）&lt;/li&gt;
&lt;li&gt;尝试删除 supervisor 的本地工作目录，然后重启 supervisor 后台进程。supervisor 启动时会为自己创建一个唯一的 id 并存储在本地目录中。如果这个 id 被复制到其他节点中，就会让 Storm 无法确定哪个 supervisor 正在运行（这种情况并不少见，如果需要扩展集群，就很容易出现直接将某个节点的 Storm 文件直接复制到新节点的情况 —— 译者注）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;“Multiple defaults.yaml found” 错误&lt;/h2&gt;
&lt;p&gt;可能出现的现象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在使用 &lt;code&gt;storm jar&lt;/code&gt; 命令部署拓扑时出现此错误&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;解决方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你很可能在拓扑的 jar 包中包含了 Storm 自身的 jar 包。注意，在打包拓扑时，请不要将 Storm 自身的 jar 包加入，因为 Storm 已经在它的 classpath 中提供了这些 jar 包。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;运行 storm jar 命令时出现 “NoSuchMethorError”&lt;/h2&gt;
&lt;p&gt;可能出现的现象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;运行 &lt;code&gt;storm jar&lt;/code&gt; 命令时出现奇怪的 “NoSuchMethodError”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;解决方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这可能是由于你部署拓扑的 Storm 版本与你构建拓扑时使用的 Storm 版本不同。请确保你编译拓扑时使用的 Storm 版本与你运行拓扑的 Storm 客户端版本相同。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Kryo ConcurrentModificationException&lt;/h2&gt;
&lt;p&gt;可能出现的现象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;系统运行时出现如下的异常堆栈跟踪信息&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;java.lang.RuntimeException: java.util.ConcurrentModificationException&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:84)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:55)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.disruptor&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;consume_batch_when_available&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;disruptor.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;56&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.disruptor&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;consume_loop_STAR_&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__1597&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;disruptor.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;67&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.util&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;async_loop&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__465&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;util.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;377&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at clojure.lang.AFn.run(AFn.java:24)&lt;/span&gt;
&lt;span class="x"&gt;    at java.lang.Thread.run(Thread.java:679)&lt;/span&gt;
&lt;span class="x"&gt;Caused by: java.util.ConcurrentModificationException&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.LinkedHashMap&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;LinkedHashIterator&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;nextEntry&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;LinkedHashMap.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;390&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.LinkedHashMap&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;EntryIterator&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;LinkedHashMap.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;409&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.LinkedHashMap&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;EntryIterator&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;LinkedHashMap.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;408&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.HashMap.writeObject(HashMap.java:1016)&lt;/span&gt;
&lt;span class="x"&gt;    at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)&lt;/span&gt;
&lt;span class="x"&gt;    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;/span&gt;
&lt;span class="x"&gt;    at java.lang.reflect.Method.invoke(Method.java:616)&lt;/span&gt;
&lt;span class="x"&gt;    at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:959)&lt;/span&gt;
&lt;span class="x"&gt;    at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1480)&lt;/span&gt;
&lt;span class="x"&gt;    at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)&lt;/span&gt;
&lt;span class="x"&gt;    at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)&lt;/span&gt;
&lt;span class="x"&gt;    at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:21)&lt;/span&gt;
&lt;span class="x"&gt;    at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:554)&lt;/span&gt;
&lt;span class="x"&gt;    at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:77)&lt;/span&gt;
&lt;span class="x"&gt;    at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18)&lt;/span&gt;
&lt;span class="x"&gt;    at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:472)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:27)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;解决方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这个信息表示你在将一个可变的对象作为 tuple 发送出去。你发送到 outputcollector 中的所有对象必须是非可变的。这个错误表明对象在被序列化并发送到网络中时你的 bolt 正在修改这个对象。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Storm 中的 NullPointerException&lt;/h2&gt;
&lt;p&gt;可能出现的现象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Storm 运行中出现了如下的 NullPointerException&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;java.lang.RuntimeException: java.lang.NullPointerException&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:84)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:55)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.disruptor&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;consume_batch_when_available&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;disruptor.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;56&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.disruptor&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;consume_loop_STAR_&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__1596&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;disruptor.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;67&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.util&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;async_loop&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__465&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;util.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;377&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at clojure.lang.AFn.run(AFn.java:24)&lt;/span&gt;
&lt;span class="x"&gt;    at java.lang.Thread.run(Thread.java:662)&lt;/span&gt;
&lt;span class="x"&gt;Caused by: java.lang.NullPointerException&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:24)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.daemon.worker&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;mk_transfer_fn&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__4126&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__4130&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;worker.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;99&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.util&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fast_list_map&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;util.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;771&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.daemon.worker&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;mk_transfer_fn&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__4126&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;worker.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;99&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.daemon.executor&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;start_batch_transfer__GT_worker_handler_BANG_&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__3904&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;executor.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;205&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.disruptor&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;clojure_handler&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;reify__1584&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;onEvent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;disruptor.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;43&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:81)&lt;/span&gt;
&lt;span class="x"&gt;    ... 6 more&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;解决方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这个问题是由于多个线程同时调用 &lt;code&gt;OutputCollector&lt;/code&gt; 中的方法造成的。Storm 中所有的 emit、ack、fail 方法必须在同一个线程中运行。出现这个问题的一种场景是在一个 &lt;code&gt;IBasicBolt&lt;/code&gt; 中创建了一个独立的线程。由于 &lt;code&gt;IBasicBolt&lt;/code&gt; 会在 &lt;code&gt;execute&lt;/code&gt; 方法调用之后自动调用 &lt;code&gt;ack&lt;/code&gt;，所以这就会出现多个线程同时使用 &lt;code&gt;OutputCollector&lt;/code&gt; 的情况，进而抛出这个异常。也就是说，在使用 &lt;code&gt;IBasicBolt&lt;/code&gt; 时，所有的消息发送操作必须在同一个线程的 &lt;code&gt;execute&lt;/code&gt; 方法中执行。&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sat, 27 Jun 2015 20:04:54 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-27:pages/techs/storm-translations-troubleshooting/</guid><category>Storm</category><category>Translation</category></item><item><title>MR 中定义 Writable 对象的坑</title><link>http://weyo.me/pages/techs/mr-writable-coding-problem/</link><description>&lt;p&gt;最近的一个新的 MR job 中需要定义一个表征状态的 Writable 对象，于是大手一挥，刷刷写出了下面的实现：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Status&lt;/span&gt; &lt;span class="kd"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;WritableComparable&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Status&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;second&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DataOutput&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;write&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;write&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;second&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;readFields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DataInput&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;first&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;readInt&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;second&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;readInt&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;这里由于 Status 中有两个表征计数的变量 &lt;code&gt;first&lt;/code&gt; 与 &lt;code&gt;second&lt;/code&gt;，所以 &lt;code&gt;write&lt;/code&gt; 和 &lt;code&gt;readFields&lt;/code&gt; 方法中均需要写/读两次。&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不过写完之后运行时在 &lt;code&gt;readFields&lt;/code&gt; 方法中读取总会出错，跳出一个莫名其妙的 &lt;code&gt;EOFException&lt;/code&gt;，查代码查资料查了半天也没发现是什么问题。&lt;/p&gt;
&lt;p&gt;没办法，关键时刻还得靠自己。冷静下来再认真看了看 &lt;code&gt;DataOutput&lt;/code&gt; 的 API 文档，才发现是犯了个低级错误被 Java 坑了：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;interface&lt;/span&gt; &lt;span class="nc"&gt;DataOutput&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="cm"&gt;/**&lt;/span&gt;
&lt;span class="cm"&gt;     * Writes to the output stream the eight&lt;/span&gt;
&lt;span class="cm"&gt;     * low-order bits of the argument &amp;lt;code&amp;gt;b&amp;lt;/code&amp;gt;.&lt;/span&gt;
&lt;span class="cm"&gt;     * The 24 high-order  bits of &amp;lt;code&amp;gt;b&amp;lt;/code&amp;gt;&lt;/span&gt;
&lt;span class="cm"&gt;     * are ignored.&lt;/span&gt;
&lt;span class="cm"&gt;     *&lt;/span&gt;
&lt;span class="cm"&gt;     * @param      b   the byte to be written.&lt;/span&gt;
&lt;span class="cm"&gt;     * @throws     IOException  if an I/O error occurs.&lt;/span&gt;
&lt;span class="cm"&gt;     */&lt;/span&gt;
    &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="cm"&gt;/**&lt;/span&gt;
&lt;span class="cm"&gt;     * Writes an &amp;lt;code&amp;gt;int&amp;lt;/code&amp;gt; value, which is&lt;/span&gt;
&lt;span class="cm"&gt;     * comprised of four bytes, to the output stream.&lt;/span&gt;
&lt;span class="cm"&gt;     * The byte values to be written, in the  order&lt;/span&gt;
&lt;span class="cm"&gt;     * shown, are:&lt;/span&gt;
&lt;span class="cm"&gt;     * &amp;lt;p&amp;gt;&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;&lt;/span&gt;
&lt;span class="cm"&gt;     * (byte)(0xff &amp;amp;amp; (v &amp;amp;gt;&amp;amp;gt; 24))&lt;/span&gt;
&lt;span class="cm"&gt;     * (byte)(0xff &amp;amp;amp; (v &amp;amp;gt;&amp;amp;gt; 16))&lt;/span&gt;
&lt;span class="cm"&gt;     * (byte)(0xff &amp;amp;amp; (v &amp;amp;gt;&amp;amp;gt; &amp;amp;#32; &amp;amp;#32;8))&lt;/span&gt;
&lt;span class="cm"&gt;     * (byte)(0xff &amp;amp;amp; v)&lt;/span&gt;
&lt;span class="cm"&gt;     * &amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;&amp;lt;p&amp;gt;&lt;/span&gt;
&lt;span class="cm"&gt;     * The bytes written by this method may be read&lt;/span&gt;
&lt;span class="cm"&gt;     * by the &amp;lt;code&amp;gt;readInt&amp;lt;/code&amp;gt; method of interface&lt;/span&gt;
&lt;span class="cm"&gt;     * &amp;lt;code&amp;gt;DataInput&amp;lt;/code&amp;gt; , which will then&lt;/span&gt;
&lt;span class="cm"&gt;     * return an &amp;lt;code&amp;gt;int&amp;lt;/code&amp;gt; equal to &amp;lt;code&amp;gt;v&amp;lt;/code&amp;gt;.&lt;/span&gt;
&lt;span class="cm"&gt;     *&lt;/span&gt;
&lt;span class="cm"&gt;     * @param      v   the &amp;lt;code&amp;gt;int&amp;lt;/code&amp;gt; value to be written.&lt;/span&gt;
&lt;span class="cm"&gt;     * @throws     IOException  if an I/O error occurs.&lt;/span&gt;
&lt;span class="cm"&gt;     */&lt;/span&gt;
    &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;writeInt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;write(int b)&lt;/code&gt; 方法只读取 int 参数的低 8 位值，而直接抛弃高 24 位；真正用于读取整型数字的还是 &lt;code&gt;writeInt(int v)&lt;/code&gt; 方法，所以，对象实现的 &lt;code&gt;write&lt;/code&gt; 方法应该改成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DataOutput&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;writeInt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;writeInt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;second&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;结果就是这么简单……&lt;/p&gt;
&lt;p&gt;Over.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Fri, 26 Jun 2015 23:38:03 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-26:pages/techs/mr-writable-coding-problem/</guid><category>Hadoop</category><category>MapReduce</category></item><item><title>Storm 官方文档翻译(11) —— Storm 常用模式</title><link>http://weyo.me/pages/techs/storm-translations-common-topoloty-patterns/</link><description>&lt;h1&gt;Storm 常用模式&lt;/h1&gt;
&lt;p&gt;本文列出了 Storm 拓扑中使用的一些常见模式，包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据流的 join&lt;/li&gt;
&lt;li&gt;批处理&lt;/li&gt;
&lt;li&gt;BasicBolt&lt;/li&gt;
&lt;li&gt;内存缓存与域分组的结合&lt;/li&gt;
&lt;li&gt;Top N 流式计算&lt;/li&gt;
&lt;li&gt;TimeCacheMap&lt;/li&gt;
&lt;li&gt;CoordinatedBolt 与 KeyedFairBolt&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Joins&lt;/h2&gt;
&lt;p&gt;数据流的 join 一般指的是通过共有的域来聚合两个或多个数据流的过程。与一般的数据库中 join 操作要求有限的输入与清晰的语义不同，数据流 join 的输入往往是无限的数据集，而且并不具备明确的语义。&lt;/p&gt;
&lt;p&gt;join 的类型一般是由应用的需求决定的。有些应用需要将两个流在某个固定时间内的所有 tuple 进行 join，另外一些应用却可能要求对每个 join 域的 join 操作过程的两侧只保留一个 tuple，而其他的应用也许还有一些其他需求。不过这些 join 类型一般都会有一个基本的模式，那就是将多个输入流进行分区。Storm 可以很容易地使用域分组的方法将多个输入流聚集到一个联结 bolt 中，比如下面这样：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;join&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;MyJoiner&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;parallelism&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;fieldsGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;1&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;joinfield1&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;joinfield2&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;fieldsGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;2&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;joinfield1&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;joinfield2&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;fieldsGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;3&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;joinfield1&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;joinfield2&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当然，上面的代码只是个例子，实际上不同的流完全可以具有不同的输入域。&lt;/p&gt;
&lt;h2&gt;批处理&lt;/h2&gt;
&lt;p&gt;通常由于效率或者其他方面的原因，你需要使用将 tuple 们组合成 batch 来处理，而不是一个个分别处理它们。比如，在做数据库更新操作或者流聚合操作时，你就会需要这样的批处理形式。&lt;/p&gt;
&lt;p&gt;要确保数据处理的可靠性，正确的方式是在 bolt 进行批处理之前将 tuple 们缓存在一个实例变量中。在完成批处理操作之后，你就可以一起 ack 所有的缓存的 tuple 了。&lt;/p&gt;
&lt;p&gt;如果这个批处理 bolt 还需要继续向下游发送 tuple，你可能还需要使用多锚定（multi-anchoring）来确保可靠性。具体怎么做取决于应用的需求。想要了解更多关于可靠性的工作机制的内容请参考&lt;a href="https://github.com/weyo/Storm-Documents/blob/master/Manual/zh/Guaranteeing-Message-Processing.md"&gt;消息的可靠性保障&lt;/a&gt;一文。&lt;/p&gt;
&lt;h2&gt;BasicBolt&lt;/h2&gt;
&lt;p&gt;Bolt 处理 tuple 的一种基本模式是在 &lt;code&gt;execute&lt;/code&gt; 方法中读取输入 tuple、发送出基于输入 tuple 的新 tuple，然后在方法末尾对 tuple 进行应答（ack）。符合这种模式的 bolt 一般是一种函数或者过滤器。对于这种基本的处理模式，Storm 提供了 &lt;code&gt;IBasicBolt&lt;/code&gt; 接口来自动实现这个过程。更多内容请参考&lt;a href="https://github.com/weyo/Storm-Documents/blob/master/Manual/zh/Guaranteeing-Message-Processing.md"&gt;消息的可靠性保障&lt;/a&gt;一文。&lt;/p&gt;
&lt;h2&gt;内存缓存与域分组的结合&lt;/h2&gt;
&lt;p&gt;在 Storm 的 bolt 中保存一定的缓存也是一种比较常见的方式。尤其是在于域分组结合的时候，缓存的作用特别显著。例如，假如你有一个用于将短链接（short URLs，例如 bit.ly, t.co，等等）转化成长链接（龙 URLs）的 bolt。你可以通过一个将短链接映射到长链接的 LRU 缓存来提高系统的性能，避免反复的 HTTP 请求操作。假如现在有一个名为 “urls” 的组件用于发送短链接，另外有一个 “expand” 组件用于将短链接扩展为长链接，并且在 “expand” 内部保留一个缓存。让我们来看看下面两段代码有什么不同：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;expand&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ExpandUrl&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;parallelism&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;shuffleGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;expand&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ExpandUrl&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;parallelism&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;fieldsGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;urls&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;url&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;由于域分组可以使得相同的 URL 永远被发往同一个 task，第二段代码会比第一段代码高效得多。这样可以避免在不同的 task 的缓存中的复制动作，并且看上去短 URL 可以更好地在命中缓存。&lt;/p&gt;
&lt;h2&gt;Top N&lt;/h2&gt;
&lt;p&gt;Storm 中一种常见的连续计算模式是计算数据流中某种形式的 Top N 结果。假如现在有一个可以以 ["value", "count"] 的形式发送 tuple 的 bolt，并且你需要一个可以根据 count 计算结果输出前 N 个 tuple 的 bolt。实现这个操作的最简单的方法就是使用一个对数据流进行全局分组的 bolt，并且在内存中维护一个包含 top N 结果的列表。&lt;/p&gt;
&lt;p&gt;这种方法并不适用于大规模数据流，因为整个数据流都会发往同一个 task，会造成该 task 的内存负载过高。更好的做法是将数据流分区，同时对每个分区计算 top N 结果，然后将这些结果汇总来得到最终的全局 top N 结果。下面是这个模式的代码：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rank&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;RankObjects&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;parallelism&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;fieldsGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;objects&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;merge&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;MergeObjects&lt;/span&gt;&lt;span class="o"&gt;())&lt;/span&gt;
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;globalGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rank&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个方法之所以可行是因为第一个 bolt 的域分组操作确保了每个小分区在语义上的正确性。你可以在 &lt;a href="https://github.com/apache/storm/blob/master/examples/storm-starter/src/jvm/storm/starter/RollingTopWords.java"&gt;storm-starter&lt;/a&gt; 里看到使用这个模式的一个例子。&lt;/p&gt;
&lt;p&gt;当然，如果待处理的数据集存在较严重的数据倾斜，那么还是应该使用 partialKeyGrouping 来代替 fieldsGrouping，因为 partialKeyGrouping 可以通过两个下游 bolt 分散每个 key 的负载。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;count&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;CountObjects&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;parallelism&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;partialKeyGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;objects&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rank&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;AggregateCountsAndRank&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;parallelism&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;fieldsGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;count&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;key&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;merge&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;MergeRanksObjects&lt;/span&gt;&lt;span class="o"&gt;())&lt;/span&gt;
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;globalGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rank&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个拓扑中需要一个中间层来聚合来自上游 bolt 数据流的分区计数结果，但这一层仅仅会做一个简单的聚合处理，这样 bolt 就不会受到由于数据倾斜带来的负载压力。你可以在 &lt;a href="https://github.com/apache/storm/blob/master/examples/storm-starter/src/jvm/storm/starter/SkewedRollingTopWords.java"&gt;storm-starter&lt;/a&gt; 中看到使用这个模式的一个例子。&lt;/p&gt;
&lt;h2&gt;支持 LRU 的 TimeCacheMap&lt;/h2&gt;
&lt;p&gt;有时候你可能会需要一个能够保留“活跃的”数据并且能够使得超时的“非活跃的”数据自动失效的缓存。&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/utils/TimeCacheMap.html"&gt;TimeCacheMap&lt;/a&gt; 是一个可以高效地实现此功能的数据结构。它还提供了一个钩子用于实现在数据失效后的回调操作。&lt;/p&gt;
&lt;h2&gt;用于分布式 RPC 的 CoordinatedBolt 与 KeyedFairBolt&lt;/h2&gt;
&lt;p&gt;在构建 Storm 上层的分布式 RPC 应用时，通常会用到两种常用的模式。现在这两种模式已经被封装为 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/CoordinatedBolt.html"&gt;CoordinatedBolt&lt;/a&gt; 和 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/KeyedFairBolt.html"&gt;KeyedFairBolt&lt;/a&gt;，并且已经加入了 Storm 标准库中。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CoordinatedBolt&lt;/code&gt; 将你的处理逻辑 bolt 包装起来，并且在你的 bolt 收到了指定请求的所有 tuple 之后发出通知。&lt;code&gt;CoordinatedBolt&lt;/code&gt; 中大量使用了直接数据流组来实现此功能。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;KeyedFairBolt&lt;/code&gt; 同样包装了你的处理逻辑 bolt，并且可以让你的拓扑同时处理多个 DRPC 调用，而不是每次只执行一个。&lt;/p&gt;
&lt;p&gt;如果需要了解更多内容请参考&lt;a href="https://github.com/weyo/Storm-Documents/blob/master/Manual/zh/Distributed-RPC.md"&gt;分布式RPC&lt;/a&gt;一文。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Tue, 23 Jun 2015 20:12:13 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-23:pages/techs/storm-translations-common-topoloty-patterns/</guid><category>Storm</category><category>Translation</category></item><item><title>Storm 官方文档翻译(10) —— Trident Spouts</title><link>http://weyo.me/pages/techs/storm-translations-trident-spouts/</link><description>&lt;h1&gt;Trident Spouts&lt;/h1&gt;
&lt;p&gt;与一般的 Storm API 一样，spout 也是 Trident 拓扑的数据来源。不过，为了实现更复杂的功能服务，Trident Spout 在普通的 Storm Spout 之上另外提供了一些 API 接口。&lt;/p&gt;
&lt;p&gt;数据源、数据流以及基于数据流更新 state（比如数据库）的操作，他们之间的耦合关系是不可避免的。&lt;a href="https://github.com/weyo/Storm-Documents/blob/master/Manual/zh/Trident-State.md"&gt;Trident State&lt;/a&gt; 一文中有这方面的详细解释，理解他们之间的这种联系对于理解 spout 的运作方式非常重要。&lt;/p&gt;
&lt;p&gt;Trident 拓扑中的大部分 spout 都是非事务型 spout。在 Trident 拓扑中可以使用普通的 &lt;code&gt;IRichSpout&lt;/code&gt; 接口来创建数据流：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TridentTopology topology = new TridentTopology();
topology.newStream(&amp;quot;myspoutid&amp;quot;, new MyRichSpout());
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Trident 拓扑中的所有 spout 都必须有一个唯一的标识，而且这个标识必须在整个 Storm 集群中都是唯一的。Trident 需要使用这个标识来存储 spout 从 ZooKeeper 中消费的元数据（metadata），包括 txid 以及其他相关的 spout 元数据。&lt;/p&gt;
&lt;p&gt;你可以使用以下配置项来设置用于存储 spout 元数据的 ZooKeeper 地址（一般情况下不需要设置以下选项，因为 Storm 默认会直接使用集群的 ZooKeeper 服务器来存储数据 —— 译者注）：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;transactional.zookeeper.servers&lt;/code&gt;：ZooKeeper 的服务器列表&lt;/li&gt;
&lt;li&gt;&lt;code&gt;transactional.zookeeper.port&lt;/code&gt;：ZooKeeper 集群的端口&lt;/li&gt;
&lt;li&gt;&lt;code&gt;transactional.zookeeper.root&lt;/code&gt;：元数据在 ZooKeeper 中存储的根目录。元数据会直接存储在该设置目录下。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;管道&lt;/h2&gt;
&lt;p&gt;默认情况下，Trident 每次处理只一个 batch，知道该 batch 处理成功或者失败之后才会开始处理其他的 batch。你可以通过将 batch 管道化来提高吞吐率，降低每个 batch 的处理延时。同时处理的 batch 的最大数量可以通过 &lt;code&gt;topology.max.spout.pending&lt;/code&gt; 来进行配置。&lt;/p&gt;
&lt;p&gt;不过，即使在同时处理多个 batch 的情况下，Trident 也会按照 batch 的顺序来更新 state。例如，假如你正在处理一个将全局计数结果聚合并更新到数据库中的任务，那么在你向数据库中更新 batch1 的计数结果时，你同时可以继续处理 batch2、batch3 甚至 batch10 的计数工作。不过，Trident 只会在 batch1 的 state 更新结束之后才会处理后续 batch 的 state 更新操作。这是实现恰好一次处理的语义的必要基础，我们已经在 &lt;a href="https://github.com/weyo/Storm-Documents/blob/master/Manual/zh/Trident-State.md"&gt;Trident State&lt;/a&gt; 一文中讨论了这一点。&lt;/p&gt;
&lt;h2&gt;Trident spout 类型&lt;/h2&gt;
&lt;p&gt;下面列出了一些可用的 spout API 接口：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/storm/trident/spout/ITridentSpout.java"&gt;ITridentSpout&lt;/a&gt;：这是最常用的 API，支持事务型和模糊事务型的语义实现。不过一般会根据需要使用它的某个已有的实现，而不是直接实现该接口。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/storm/trident/spout/IBatchSpout.java"&gt;IBatchSpout&lt;/a&gt;：非事务型 spout，每次会输出一个 batch 的 tuple。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/storm/trident/spout/IPartitionedTridentSpout.java"&gt;IPartitionedTridentSpout&lt;/a&gt;：可以从分布式数据源（比如一个集群或者 Kafka 服务器）读取数据的事务型 spout。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/storm/trident/spout/IOpaquePartitionedTridentSpout.java"&gt;OpaquePartitionedTridentSpout&lt;/a&gt;：可以从分布式数据源读取数据的模糊事务型 spout。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当然，正如这篇教程的开头提到的，除了这些 API 之外，你还可以使用普通的 &lt;code&gt;IRichSpout&lt;/code&gt;。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Mon, 22 Jun 2015 11:10:27 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-22:pages/techs/storm-translations-trident-spouts/</guid><category>Storm</category><category>Translation</category></item><item><title>Storm 官方文档翻译(9) —— Trident State</title><link>http://weyo.me/pages/techs/storm-translations-trident-state/</link><description>&lt;h1&gt;Trident State&lt;/h1&gt;
&lt;p&gt;Trident 中含有对状态化（stateful）的数据源进行读取和写入操作的一级抽象封装工具。这个所谓的状态（state）既可以保存在拓扑内部（保存在内存中并通过 HDFS 来实现备份），也可以存入像 Memcached 或者 Cassandra 这样的外部数据库中。而对于 Trident API 而言，这两种机制并没有任何区别。&lt;/p&gt;
&lt;p&gt;Trident 使用一种容错性的方式实现对 state 的管理，这样，即使在发生操作失败或者重试的情况下状态的更新操作仍然是幂等的。基于这个机制，每条消息都可以看作被恰好处理了一次，然后你就可以很容易地推断出 Trident 拓扑的状态。&lt;/p&gt;
&lt;p&gt;State 的更新过程支持多级容错性保证机制。在讨论这一点之前，我们先来看一个例子，这个例子展示了如何实现恰好一次的语义的技术。假定你正在对数据流进行一个计数聚合操作，并打算将计数结果存入数据库中。在这个例子里，你存入数据库的就是一个对应计数结果的值，每次处理新 tuple 的时候就会增加这个值。&lt;/p&gt;
&lt;p&gt;考虑到可能存在的处理失败情况，tuple 有可能需要重新处理。这样就给 state 的更新操作带来了一个问题（或者其他的副作用）—— 你无法知道当前的这个 tuple 的更新操作是否已经处理过了。也许你之前没有处理过这个 tuple，那么你现在就需要增加计数结果；也许你之前已经处理过 tuple 了并且成功地增加了计数结果，但是在后续操作过程中 tuple 的处理失败了，并由此引发了 tuple 的重新处理操作，这时你就不能再增加计数结果了；还有可能你之前在使用这个 tuple 更新数据库的时候出错了，也就是说计数值的更新操作并未成功，此时在 tuple 的重新处理过程中你仍然需要更新数据库。&lt;/p&gt;
&lt;p&gt;所以说，如果只是向数据库中简单地存入计数值，你确实无法知道 tuple 是否已经被处理过。因此，你需要一些更多的信息来做决定。Trident 提供了一种支持恰好一次处理的语义，如下所述：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过小数据块（batch）的方式来处理 tuple（可以参考&lt;a href="https://github.com/weyo/Storm-Documents/blob/master/Manual/zh/Trident-Tutorial.md"&gt;Trident 教程&lt;/a&gt;一文）&lt;/li&gt;
&lt;li&gt;为每个 batch 提供一个唯一的 id，这个 id 称为 “事务 id”（transaction id，txid）。如果需要对 batch 重新处理，这个 batch 上仍然会赋上相同的 txid。&lt;/li&gt;
&lt;li&gt;State 的更新操作是按照 batch 的顺序进行的。也就是说，在 batch 2 完成处理之前，batch 3 的状态更新操作不会进行。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;基于这几个基本性质，你的 State 的实现就可以检测到 tuple 的 batch 是否已经被处理过，并根据检测结果选择合适的 state 更新操作。你具体采用的操作取决于你的输入 spout 提供的语义，这个语义对每个 batch 都是有效的。有三类支持容错性的 spout：“非事务型”（non-transactional）、“事务型”（transactional）以及“模糊事务型”（opaque transactional）。接下来我们来分析下每种 spout 类型的容错性语义。&lt;/p&gt;
&lt;h2&gt;事务型 spout（Transactional spouts）&lt;/h2&gt;
&lt;p&gt;记住一点，Trident 是通过小数据块（batch）的方式来处理 tuple 的，而且每个 batch 都会有一个唯一的 txid。spout 的特性是由他们所提供的容错性保证机制决定的，而且这种机制也会对每个 batch 发生作用。事务型 spout 包含以下特性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个 batch 的 txid 永远不会改变。对于某个特定的 txid，batch 在执行重新处理操作时所处理的 tuple 集和它的第一次处理操作完全相同。&lt;/li&gt;
&lt;li&gt;不同 batch 中的 tuple 不会出现重复的情况（某个 tuple 只会出现在一个 batch 中，而不会同时出现在多个 batch 中）。&lt;/li&gt;
&lt;li&gt;每个 tuple 都会放入一个 batch 中（处理操作不会遗漏任何的 tuple）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这是一种很容易理解的 spout，其中的数据流会被分解到固定的 batches 中。Storm-contrib 项目中提供了一种基于 Kafka 的&lt;a href="https://github.com/apache/storm/tree/master/external/storm-kafka/src/jvm/storm/kafka/trident/TransactionalTridentKafkaSpout.java"&gt;事务型 spout 实现&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;看到这里，你可能会有这样的疑问：为什么不在拓扑中完全使用事务型 spout 呢？这个原因很好理解。一方面，有些时候事务型 spout 并不能提供足够可靠的容错性保障，所以不需要使用事务型 spout。比如，&lt;code&gt;TransactionalTridentKafkaSpout&lt;/code&gt; 的工作方式就是使得带有某个 txid 的 batch 中包含有来自一个 Kafka topic 的所有 partition 的 tuple。一旦一个 batch 被发送出去，在将来无论重新发送这个 batch 多少次，batch 中都会包含有完全相同的 tuple 集，这是由事务型 spout 的语义决定的。现在假设 &lt;code&gt;TransactionalTridentKafkaSpout&lt;/code&gt; 发送出的某个 batch 处理失败了，而与此同时，Kafka 的某个节点因为故障下线了。这时你就无法重新处理之前的 batch 了（因为 Kafka 的节点故障，Kafka topic 必然有一部分 partition 无法获取到），这个处理过程也会因此终止。&lt;/p&gt;
&lt;p&gt;这就是要有“模糊事务型” spout 的原因了 —— 模糊事务型 spout 支持在数据源节点丢失的情况下仍然可以实现恰好一次的处理语义。我们会在下一节讨论这类 spout。&lt;/p&gt;
&lt;p&gt;顺便提一点，如果 Kafka 支持数据复制，那么就可以放心地使用事务型 spout 提供的容错性机制了，因为这种情况下某个节点的故障不会导致数据丢失，不过 Kafka 暂时还不支持该特性。（本文的写作时间应该较早，Kakfa 早就已经可以支持复制的机制了 —— 译者注）。&lt;/p&gt;
&lt;p&gt;在讨论“模糊事务型” spout 之前，让我们先来看看如何为事务型 spout 设计一种支持恰好一次语义的 State。这个 State 就称为 “事务型 state”，它支持对于特定的 txid 永远只与同一组 tuple 相关联的特性。&lt;/p&gt;
&lt;p&gt;假如你的拓扑需要计算单词数，而且你准备将计数结果存入一个 K-V 型数据库中。这里的 key 就是单词，value 对应于单词数。从上面的讨论中你应该已经明白了仅仅存储计数结果是无法确定某个 batch 中的tuple 是否已经被处理过的。所以，现在你应该将 txid 作为一种原子化的值与计数值一起存入数据库。随后，在更新计数值的时候，你就可以将数据库中的 txid 与当前处理的 batch 的 txid 进行比对。如果两者相同，你就可以跳过更新操作 —— 由于 Trident 的强有序性处理机制，可以确定数据库中的值是对应于当前的 batch 的。如果两者不同，你就可以放心地增加计数值。由于一个 batch 的 txid 永远不会改变，而且 Trident 能够保证 state 的更新操作完全是按照 batch 的顺序进行的，所以，这样的处理逻辑是完全可行的。&lt;/p&gt;
&lt;p&gt;下面来看一个例子。假如你正在处理 txid 3，其中包含有以下几个 tuple：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[&amp;quot;man&amp;quot;]&lt;/span&gt;
&lt;span class="k"&gt;[&amp;quot;man&amp;quot;]&lt;/span&gt;
&lt;span class="k"&gt;[&amp;quot;dog&amp;quot;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;假如数据库中有以下几个 key-value 对：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;man =&amp;gt; [count=3, txid=1]
dog =&amp;gt; [count=4, txid=3]
apple =&amp;gt; [count=10, txid=2]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;其中与 “man” 相关联的 txid 为 1。由于当前处理的 txid 为 3，你就可以确定当前处理的 batch 与数据库中存储的值无关，这样你就可以放心地将 “man” 的计数值加上 2 并更新 txid 为 3。另一方面，由于 “dog” 的 txid 与当前的 txid 相同，所以，“dog” 的计数是之前已经处理过的，现在不能再对数据库中的计数值进行更新操作。这样，在结束 txid3 的更新操作之后，数据库中的结果就会变成这样：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;man =&amp;gt; [count=5, txid=3]
dog =&amp;gt; [count=4, txid=3]
apple =&amp;gt; [count=10, txid=2]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;现在我们再来讨论一下“模糊事务型” spout。&lt;/p&gt;
&lt;h2&gt;模糊事务型 spout（Opaque transactional spouts）&lt;/h2&gt;
&lt;p&gt;前面已经提到过，模糊事务型 spout 不能保证一个 txid 对应的 batch 中包含的 tuple 完全一致。模糊事务型 spout 有以下的特性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个 tuple 都会通过某个 batch 处理完成。不过，在 tuple 处理失败的时候，tuple 有可能继续在另一个 batch 中完成处理，而不一定是在原先的 batch 中完成处理。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="https://github.com/apache/storm/tree/master/external/storm-kafka/src/jvm/storm/kafka/trident/OpaqueTridentKafkaSpout.java"&gt;OpaqueTridentKafkaSpout&lt;/a&gt; 就具有这样的特性，同时它对 Kafka 节点的丢失问题具有很好的容错性。&lt;code&gt;OpaqueTridentKafkaSpout&lt;/code&gt; 在发送一个 batch 的时候总会总上一个 batch 结束的地方开始发送新 tuple。这一点可以保证 tuple 不会被遗漏，而且也不会被多个 batch 处理。&lt;/p&gt;
&lt;p&gt;不过，模糊事务型 spout 的缺点就在于不能通过 txid 来识别数据库中的 state 是否是已经处理过的。这是因为在 state 的更新的过程中，batch 有可能会发生变化。&lt;/p&gt;
&lt;p&gt;在这种情况下，你应该在数据库中存储更多的 state 信息。除了一个结果值和 txid 之外，你还应该存入前一个结果值。我们再以上面的计数值的例子来分析以下这个问题。假如你的 batch 的部分计数值是 “2”，现在你需要应用一个更新操作。假定现在数据库中的值是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{ value = 4,
  prevValue = 1,
  txid = 2
}
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;情形1：假如当前处理的 txid 为 3，这与数据库中的 txid 不同。这时可以将 “prevValue” 的值设为 “value” 的值，再为 “value” 的值加上部分计数的结果并更新 txid。执行完这一系列操作之后的数据库中的值就会变成这样：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{ value = 6,
  prevValue = 4,
  txid = 3
}
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;情形2：如果当前处理的 txid 为 2，也就是和数据库中存储的 txid 一致，这种情况下的处理逻辑与上面的 txid 不一致的情况又有所不同。因为此时你会知道数据库中的更新操作是由上一个拥有相同 txid 的batch 做出的。不过那个 batch 有可能与当前的 batch 并不相同，所以你需要忽略它的操作。这个时候，你应该将 “prevValue” 加上 batch 中的部分计数值来计算新的 “value”。在这个操作之后数据库中的值就会变成这样：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{ value = 3,
  prevValue = 1,
  txid = 2
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这种方法之所以可行是因为 Trident 具有强顺序性处理的特性。一旦 Trident 开始处理一个新的 batch 的状态更新操作，它永远不会回到过去的 batch 的处理上。同时，由于模糊事务型 spout 会保证 batch 之间不会存在重复 —— 每个 tuple 只会被某一个 batch 完成处理 —— 所以你可以放心地使用 prevValue 来更新 value。&lt;/p&gt;
&lt;h2&gt;非事务型 spout（Non-transactional spouts）&lt;/h2&gt;
&lt;p&gt;非事务型 spout 不能为 batch 提供任何的安全性保证。非事务型 spout 有可能提供一种“至多一次”的处理模型，在这种情况下 batch 处理失败后 tuple 并不会重新处理；也有可能提供一种“至少一次”的处理模型，在这种情况下可能会有多个 batch 分别处理某个 tuple。总之，此类 spout 不能提供“恰好一次”的语义。&lt;/p&gt;
&lt;h2&gt;不同类型的 Spout 与 State 的总结&lt;/h2&gt;
&lt;p&gt;下图显示了不同的 spout/state 的组合是否支持恰好一次的消息处理语义：&lt;/p&gt;
&lt;p&gt;&lt;img alt="spout-state" src="http://storm.apache.org/documentation/images/spout-vs-state.png" /&gt;&lt;/p&gt;
&lt;p&gt;模糊事务型 state 具有最好的容错性特征，不过这是以在数据库中存储更多的内容为代价的（一个 txid 和两个 value）。事务型 state 要求的存储空间相对较小，但是它的缺点是只对事务型 spout 有效。相对的，非事务型要求的存储空间最少，但是它也不能提供任何的恰好一次的消息执行语义。&lt;/p&gt;
&lt;p&gt;你选择 state 与 spout 的时候必须在容错性与存储空间占用之间权衡。可以根据你的应用的需求来确定哪种组合最适合你。&lt;/p&gt;
&lt;h2&gt;State API&lt;/h2&gt;
&lt;p&gt;从上文的描述中你已经了解到了恰好一次的消息执行语义的原理是多么的复杂。不过作为用户你并不需要处理这些复杂的 txid 比对、多值存储等操作，Trident 已经在 State 中封装了所有的容错性处理逻辑，你只需要像下面这样写代码即可：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TridentTopology topology = new TridentTopology();        
TridentState wordCounts =
      topology.newStream(&amp;quot;spout1&amp;quot;, spout)
        .each(new Fields(&amp;quot;sentence&amp;quot;), new Split(), new Fields(&amp;quot;word&amp;quot;))
        .groupBy(new Fields(&amp;quot;word&amp;quot;))
        .persistentAggregate(MemcachedState.opaque(serverLocations), new Count(), new Fields(&amp;quot;count&amp;quot;))                
        .parallelismHint(6);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;所有处理模糊事务型 state 的逻辑已经封装在 &lt;code&gt;MemcachedState.opaque&lt;/code&gt; 的调用中了。另外，状态更新都会自动调整为批处理操作，这样可以减小与数据库的反复交互的资源损耗。&lt;/p&gt;
&lt;p&gt;基本的 &lt;code&gt;State&lt;/code&gt; 接口只有两个方法：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;interface&lt;/span&gt; &lt;span class="nc"&gt;State&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;beginCommit&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Long&lt;/span&gt; &lt;span class="n"&gt;txid&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// 对于类似于在 DRPC 流上进行 partitionPersist 的操作，此方法可以为空&lt;/span&gt;
    &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;commit&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Long&lt;/span&gt; &lt;span class="n"&gt;txid&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;前面已经说过，state 更新操作的开始时和结束时都会获取一个 txid。对于你的 state 怎么工作，你在其中使用什么样的方法执行更新操作，或者使用什么样的方法从 state 中读取数据，Trident 并不关心。&lt;/p&gt;
&lt;p&gt;假如你有一个包含有用户的地址信息的定制数据库，你需要使用 Trident 与该数据库交互。你的 State 的实现就会包含有用于获取与设置用户信息的方法，比如下面这样：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;LocationDB&lt;/span&gt; &lt;span class="kd"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;State&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;beginCommit&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Long&lt;/span&gt; &lt;span class="n"&gt;txid&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;    
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;commit&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Long&lt;/span&gt; &lt;span class="n"&gt;txid&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;    
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;setLocation&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;userId&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;location&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="c1"&gt;// code to access database and set location&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="nf"&gt;getLocation&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;userId&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="c1"&gt;// code to get location from database&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;接着你就可以为 Trident 提供一个 StateFactory 来创建 Trident 任务内部的 State 对象的实例。对应于你的数据库（LocationDB）的 StateFactory 大概是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;LocationDBFactory&lt;/span&gt; &lt;span class="kd"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;StateFactory&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
   &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;State&lt;/span&gt; &lt;span class="nf"&gt;makeState&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Map&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;partitionIndex&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;numPartitions&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;LocationDB&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
   &lt;span class="o"&gt;}&lt;/span&gt; 
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Trident 提供了一个用于查询 state 数据源的 &lt;code&gt;QueryFunction&lt;/code&gt; 接口，以及一个用于更新 state 数据源的 &lt;code&gt;StateUpdater&lt;/code&gt; 接口。例如，我们可以写一个查询 LocationDB 中的用户地址信息的 “QueryLocation”。让我们从你在拓扑中使用这个操作的方式开始。假如在拓扑中需要读取输入流中的 userid 信息：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TridentTopology topology = new TridentTopology();
TridentState locations = topology.newStaticState(new LocationDBFactory());
topology.newStream(&amp;quot;myspout&amp;quot;, spout)
        .stateQuery(locations, new Fields(&amp;quot;userid&amp;quot;), new QueryLocation(), new Fields(&amp;quot;location&amp;quot;))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这里的 &lt;code&gt;QueryLocation&lt;/code&gt; 的实现可能是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;QueryLocation&lt;/span&gt; &lt;span class="kd"&gt;extends&lt;/span&gt; &lt;span class="n"&gt;BaseQueryFunction&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;LocationDB&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;batchRetrieve&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LocationDB&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;TridentTuple&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;ret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ArrayList&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TridentTuple&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;ret&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getLocation&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getLong&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)));&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ret&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TridentTuple&lt;/span&gt; &lt;span class="n"&gt;tuple&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;location&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TridentCollector&lt;/span&gt; &lt;span class="n"&gt;collector&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;collector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;emit&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Values&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;location&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;    
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;QueryFunction&lt;/code&gt; 的执行包含两个步骤。首先，Trident 会将读取的一些数据中汇总为一个 batch 传入 batchRetrieve 方法中。在这个例子中，batchRetrieve 方法会收到一些用户 id。然后 batchRetrieve 会返回一个与输入 tuple 列表大小相同的队列。结果队列的第一个元素与第一个输入 tuple 对应，第二个元素与第二个输入 tuple 相对应，以此类推。&lt;/p&gt;
&lt;p&gt;你会发现这段代码并没有发挥出 Trident 批处理的优势，因为这段代码仅仅一次查询一下 LocationDB。所以，实现 LocationDB 的更好的方式应该是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class LocationDB implements State {
    public void beginCommit(Long txid) {    
    }

    public void commit(Long txid) {    
    }

    public void setLocationsBulk(List&amp;lt;Long&amp;gt; userIds, List&amp;lt;String&amp;gt; locations) {
      // set locations in bulk
    }

    public List&amp;lt;String&amp;gt; bulkGetLocations(List&amp;lt;Long&amp;gt; userIds) {
      // get locations in bulk
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;然后，你可以这样实现 &lt;code&gt;QueryLocation&lt;/code&gt; 方法：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class QueryLocation extends BaseQueryFunction&amp;lt;LocationDB, String&amp;gt; {
    public List&amp;lt;String&amp;gt; batchRetrieve(LocationDB state, List&amp;lt;TridentTuple&amp;gt; inputs) {
        List&amp;lt;Long&amp;gt; userIds = new ArrayList&amp;lt;Long&amp;gt;();
        for(TridentTuple input: inputs) {
            userIds.add(input.getLong(0));
        }
        return state.bulkGetLocations(userIds);
    }

    public void execute(TridentTuple tuple, String location, TridentCollector collector) {
        collector.emit(new Values(location));
    }    
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这段代码大幅减少了域数据库的IO，具有更高的执行效率。&lt;/p&gt;
&lt;p&gt;你需要使用 &lt;code&gt;StateUpdater&lt;/code&gt; 接口来更新 state。下面是一个更新 LocationDB 的地址信息的 StateUpdater 实现：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class LocationUpdater extends BaseStateUpdater&amp;lt;LocationDB&amp;gt; {
    public void updateState(LocationDB state, List&amp;lt;TridentTuple&amp;gt; tuples, TridentCollector collector) {
        List&amp;lt;Long&amp;gt; ids = new ArrayList&amp;lt;Long&amp;gt;();
        List&amp;lt;String&amp;gt; locations = new ArrayList&amp;lt;String&amp;gt;();
        for(TridentTuple t: tuples) {
            ids.add(t.getLong(0));
            locations.add(t.getString(1));
        }
        state.setLocationsBulk(ids, locations);
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;然后你就可以在 Trident 拓扑中这样使用这个操作：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TridentTopology topology = new TridentTopology();
TridentState locations = 
    topology.newStream(&amp;quot;locations&amp;quot;, locationsSpout)
        .partitionPersist(new LocationDBFactory(), new Fields(&amp;quot;userid&amp;quot;, &amp;quot;location&amp;quot;), new LocationUpdater())
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;partitionPersist&lt;/code&gt; 操作会更新 state 数据源。&lt;code&gt;StateUpdater&lt;/code&gt; 接收 State 和一批 tuple 作为输入，然后更新这个 State。上面的代码仅仅从输入 tuple 中抓取 userid 和 location 信息，然后对 State 执行一个批处理更新操作。&lt;/p&gt;
&lt;p&gt;在 Trident 拓扑更新 LocationDB 之后，&lt;code&gt;partitionPersist&lt;/code&gt; 会返回一个表示更新后状态的 &lt;code&gt;TridentState&lt;/code&gt; 对象。随后你就可以在拓扑的其他地方使用 &lt;code&gt;stateQuery&lt;/code&gt; 方法对这个 state 执行查询操作。&lt;/p&gt;
&lt;p&gt;你也许注意到了 StateUpdater 中有一个 TridentCollector 参数。发送到这个 collector 的 tuple 会进入一个“新的数值流”中。在这个例子里向这个新的流发送 tuple 并没有意义，不过如果你需要处理类似于更新数据库中的计数值这样的操作，你可以考虑将更新后的技术结果发送到这个流中。可以通过 &lt;code&gt;TridentState.newValuesStream&lt;/code&gt; 方法来获取新的流的数据。&lt;/p&gt;
&lt;h2&gt;persistentAggregate&lt;/h2&gt;
&lt;p&gt;Trident 使用一个称为 &lt;code&gt;persistentAggregate&lt;/code&gt; 的方法来更新 State。你已经在前面的数据流单词统计的例子里见过了这个方法，这里再写一遍：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TridentTopology topology = new TridentTopology();        
TridentState wordCounts =
      topology.newStream(&amp;quot;spout1&amp;quot;, spout)
        .each(new Fields(&amp;quot;sentence&amp;quot;), new Split(), new Fields(&amp;quot;word&amp;quot;))
        .groupBy(new Fields(&amp;quot;word&amp;quot;))
        .persistentAggregate(new MemoryMapState.Factory(), new Count(), new Fields(&amp;quot;count&amp;quot;))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;partitionPersist 是一个接收 Trident 聚合器作为参数并对 state  数据源进行更新的方法，persistentAggregate 就是构建于 partitionPersist 上层的一个编程抽象。在这个例子里，由于是一个分组数据流（grouped stream），Trident 需要你提供一个实现 &lt;code&gt;MapState&lt;/code&gt; 接口的 state。被分组的域就是 state 中的 key，而聚合的结果就是 state 中的 value。&lt;code&gt;MapState&lt;/code&gt; 接口是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public interface MapState&amp;lt;T&amp;gt; extends State {
    List&amp;lt;T&amp;gt; multiGet(List&amp;lt;List&amp;lt;Object&amp;gt;&amp;gt; keys);
    List&amp;lt;T&amp;gt; multiUpdate(List&amp;lt;List&amp;lt;Object&amp;gt;&amp;gt; keys, List&amp;lt;ValueUpdater&amp;gt; updaters);
    void multiPut(List&amp;lt;List&amp;lt;Object&amp;gt;&amp;gt; keys, List&amp;lt;T&amp;gt; vals);
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;而当你在非分组数据流上执行聚合操作时（全局聚合操作），Trident 需要你提供一个实现了 &lt;code&gt;Snapshottable&lt;/code&gt; 接口的对象：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public interface Snapshottable&amp;lt;T&amp;gt; extends State {
    T get();
    T update(ValueUpdater updater);
    void set(T o);
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/storm/trident/testing/MemoryMapState.java"&gt;MemoryMapState&lt;/a&gt; 与 &lt;a href="https://github.com/nathanmarz/trident-memcached/blob/master/src/jvm/trident/memcached/MemcachedState.java"&gt;MemcachedState&lt;/a&gt; 都实现了上面两个接口。&lt;/p&gt;
&lt;h2&gt;实现 Map State 接口&lt;/h2&gt;
&lt;p&gt;实现 &lt;code&gt;MapState&lt;/code&gt; 接口非常简单，Trident 几乎已经为你做好了所有的准备工作。&lt;code&gt;OpaqueMap&lt;/code&gt;、&lt;code&gt;TransactionalMap&lt;/code&gt;、与 &lt;code&gt;NonTransactionalMap&lt;/code&gt; 类都分别实现了各自的容错性语义。你只需要为这些类提供一个用于对不同的 key/value 进行 multiGets 与 multiPuts 处理的 IBackingMap 实现类。&lt;code&gt;IBackingMap&lt;/code&gt; 接口是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public interface IBackingMap&amp;lt;T&amp;gt; {
    List&amp;lt;T&amp;gt; multiGet(List&amp;lt;List&amp;lt;Object&amp;gt;&amp;gt; keys); 
    void multiPut(List&amp;lt;List&amp;lt;Object&amp;gt;&amp;gt; keys, List&amp;lt;T&amp;gt; vals); 
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;OpaqueMap 会使用 &lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/storm/trident/state/OpaqueValue.java"&gt;OpaqueValue&lt;/a&gt; 作为 vals 参数来调用 multiPut 方法，TransactionalMap 会使用 &lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/storm/trident/state/TransactionalValue.java"&gt;TransactionalValue&lt;/a&gt; 作为参数，而 NonTransactionalMap 则直接将拓扑中的对象传入。&lt;/p&gt;
&lt;p&gt;Trident 也提供了一个 &lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/storm/trident/state/map/CachedMap.java"&gt;CachedMap&lt;/a&gt; 用于实现 K-V map 的自动 LRU 缓存功能。&lt;/p&gt;
&lt;p&gt;最后，Trident 还提供了一个 &lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/storm/trident/state/map/SnapshottableMap.java"&gt;SnapshottableMap&lt;/a&gt; 类，该类通过将全局聚合结果存入一个固定的 key 中的方法将 MapState 对象转化为一个 Snapshottable 对象。&lt;/p&gt;
&lt;p&gt;可以参考 &lt;a href="https://github.com/nathanmarz/trident-memcached/blob/master/src/jvm/trident/memcached/MemcachedState.java"&gt;MemcachedState&lt;/a&gt; 的实现来了解如何将这些工具结合到一起来提供一个高性能的 MapState。&lt;code&gt;MemcachedState&lt;/code&gt; 支持选择模糊事务型、事务型或者非事务型语义。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sun, 21 Jun 2015 20:32:03 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-21:pages/techs/storm-translations-trident-state/</guid><category>Storm</category><category>Translation</category></item><item><title>Storm 官方文档翻译(8) —— Trident API 概述</title><link>http://weyo.me/pages/techs/storm-translations-trident-api-overview/</link><description>&lt;h1&gt;Trident API 概述&lt;/h1&gt;
&lt;p&gt;Trident 的核心数据模型是“流”（Stream），不过与普通的拓扑不同的是，这里的流是作为一系列数据块（batch）来处理的。数据流是分布在集群中的不同节点上运行的，并且对数据流的操作也是在数据流的每个小分区上并行运行的。&lt;/p&gt;
&lt;p&gt;Trident 中有 5 类操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;针对每个小分区的本地操作，这类操作不会产生网络数据传输；&lt;/li&gt;
&lt;li&gt;针对一个数据流的重新分区操作，这类操作不会改变数据流中的内容，但是会产生一定的网络传输；&lt;/li&gt;
&lt;li&gt;通过网络数据传输进行的聚合操作；&lt;/li&gt;
&lt;li&gt;针对数据流的分组操作；&lt;/li&gt;
&lt;li&gt;融合与联结操作。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;本地分区操作&lt;/h2&gt;
&lt;p&gt;本地分区操作是在每个分区块上独立运行的操作，其中不涉及网络数据传输。&lt;/p&gt;
&lt;h3&gt;函数&lt;/h3&gt;
&lt;p&gt;函数负责接收一个输入域的集合并选择输出或者不输出 tuple。输出 tuple 的域会被添加到原始数据流的输入域中。如果一个函数不输出 tuple，那么原始的输入 tuple 就会被直接过滤掉。否则，每个输出 tuple 都会复制一份输入 tuple 。假设你有下面这样的函数：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class MyFunction extends BaseFunction {
    public void execute(TridentTuple tuple, TridentCollector collector) {
        for(int i=0; i &amp;lt; tuple.getInteger(0); i++) {
            collector.emit(new Values(i));
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;再假设你有一个名为 “mystream” 的数据流，这个流中包含下面几个 tuple，每个 tuple 中包含有 “a”、“b”、“c” 三个域：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[1, 2, 3]&lt;/span&gt;
&lt;span class="k"&gt;[4, 1, 6]&lt;/span&gt;
&lt;span class="k"&gt;[3, 0, 8]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果你运行这段代码：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mystream.each(new Fields(&amp;quot;b&amp;quot;), new MyFunction(), new Fields(&amp;quot;d&amp;quot;)))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;那么最终输出的结果 tuple 就会包含有 “a”、“b”、“c”、“d” 4 个域，就像下面这样：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[1, 2, 3, 0]&lt;/span&gt;
&lt;span class="k"&gt;[1, 2, 3, 1]&lt;/span&gt;
&lt;span class="k"&gt;[4, 1, 6, 0]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;过滤器&lt;/h3&gt;
&lt;p&gt;过滤器负责判断输入的 tuple 是否需要保留。以下面的过滤器为例：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class MyFilter extends BaseFilter {
    public boolean isKeep(TridentTuple tuple) {
        return tuple.getInteger(0) == 1 &amp;amp;&amp;amp; tuple.getInteger(1) == 2;
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过使用这段代码：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mystream.each(new Fields(&amp;quot;b&amp;quot;, &amp;quot;a&amp;quot;), new MyFilter())
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;就可以将下面这样带有 “a”、“b”、“c” 三个域的 tuple&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[1, 2, 3]&lt;/span&gt;
&lt;span class="k"&gt;[2, 1, 1]&lt;/span&gt;
&lt;span class="k"&gt;[2, 3, 4]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;最终转化成这样的结果 tuple：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[2, 1, 1]
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;partitionAggregate&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;partitionAggregate&lt;/code&gt; 会在一批 tuple 的每个分区上执行一个指定的功能操作。与上面的函数不同，由 &lt;code&gt;partitionAggregate&lt;/code&gt; 发送出的 tuple 会将输入 tuple 的域替换。以下面这段代码为例：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mystream.partitionAggregate(new Fields(&amp;quot;b&amp;quot;), new Sum(), new Fields(&amp;quot;sum&amp;quot;))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;假如输入流中包含有 “a”、“b” 两个域并且有以下几个 tuple 块：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Partition 0:
[&amp;quot;a&amp;quot;, 1]
[&amp;quot;b&amp;quot;, 2]

Partition 1:
[&amp;quot;a&amp;quot;, 3]
[&amp;quot;c&amp;quot;, 8]

Partition 2:
[&amp;quot;e&amp;quot;, 1]
[&amp;quot;d&amp;quot;, 9]
[&amp;quot;d&amp;quot;, 10]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;经过上面的代码之后，输出就会变成带有一个名为 “sum” 的域的数据流，其中的 tuple 就是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Partition 0:
[3]

Partition 1:
[11]

Partition 2:
[20]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Storm 有三个用于定义聚合器的接口：&lt;code&gt;CombinerAggregator&lt;/code&gt;，&lt;code&gt;ReducerAggregator&lt;/code&gt; 以及 &lt;code&gt;Aggregator&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这是 &lt;code&gt;CombinerAggregator&lt;/code&gt; 接口：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public interface CombinerAggregator&amp;lt;T&amp;gt; extends Serializable {
    T init(TridentTuple tuple);
    T combine(T val1, T val2);
    T zero();
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;CombinerAggregator&lt;/code&gt; 会将带有一个域的一个单独的 tuple 返回作为输出。&lt;code&gt;CombinerAggregator&lt;/code&gt; 会在每个输入 tuple 上运行初始化函数，然后使用组合函数来组合所有输入的值。如果在某个分区中没有 tuple， &lt;code&gt;CombinerAggregator&lt;/code&gt; 就会输出 &lt;code&gt;zero&lt;/code&gt; 方法的结果。例如，下面是 &lt;code&gt;Count&lt;/code&gt; 的实现代码：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class Count implements CombinerAggregator&amp;lt;Long&amp;gt; {
    public Long init(TridentTuple tuple) {
        return 1L;
    }

    public Long combine(Long val1, Long val2) {
        return val1 + val2;
    }

    public Long zero() {
        return 0L;
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果你使用 aggregate 方法来代替 partitionAggregate 方法，你就会发现 &lt;code&gt;CombinerAggregator&lt;/code&gt; 的好处了。在这种情况下，Trident 会在发送 tuple 之前通过分区聚合操作来优化计算过程。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ReducerAggregator&lt;/code&gt; 的接口实现是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public interface ReducerAggregator&amp;lt;T&amp;gt; extends Serializable {
    T init();
    T reduce(T curr, TridentTuple tuple);
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;ReducerAggregator&lt;/code&gt; 会使用 &lt;code&gt;init&lt;/code&gt; 方法来产生一个初始化的值，然后使用该值对每个输入 tuple 进行遍历，并最终生成并输出一个单独的 tuple，这个 tuple 中就包含有我们需要的计算结果值。例如，下面是将 Count 定义为 &lt;code&gt;ReducerAggregator&lt;/code&gt; 的代码：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class Count implements ReducerAggregator&amp;lt;Long&amp;gt; {
    public Long init() {
        return 0L;
    }

    public Long reduce(Long curr, TridentTuple tuple) {
        return curr + 1;
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;ReducerAggregator&lt;/code&gt; 同样可以用于 persistentAggregate，你会在后面看到这一点。&lt;/p&gt;
&lt;p&gt;最常用的聚合器接口还是下面的 &lt;code&gt;Aggregator&lt;/code&gt; 接口：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public interface Aggregator&amp;lt;T&amp;gt; extends Operation {
    T init(Object batchId, TridentCollector collector);
    void aggregate(T state, TridentTuple tuple, TridentCollector collector);
    void complete(T state, TridentCollector collector);
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;Aggregator&lt;/code&gt; 聚合器可以生成任意数量的 tuple，这些 tuple 也可以带有任意数量的域。聚合器可以在执行过程中的任意一点输出tuple，他们的执行过程是这样的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在处理一批数据之前先调用 init 方法。init 方法的返回值是一个代表着聚合状态的对象，这个对象接下来会被传入 aggregate 方法和 complete 方法中。&lt;/li&gt;
&lt;li&gt;对于一个区块中的每个 tuple 都会调用 aggregate 方法。这个方法能够更新状态并且有选择地输出 tuple。&lt;/li&gt;
&lt;li&gt;在区块中的所有 tuple 都被 aggregate 方法处理之后就会调用 complete 方法。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面是使用 Count 作为聚合器的代码：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class CountAgg extends BaseAggregator&amp;lt;CountState&amp;gt; {
    static class CountState {
        long count = 0;
    }

    public CountState init(Object batchId, TridentCollector collector) {
        return new CountState();
    }

    public void aggregate(CountState state, TridentTuple tuple, TridentCollector collector) {
        state.count+=1;
    }

    public void complete(CountState state, TridentCollector collector) {
        collector.emit(new Values(state.count));
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;有时你可能会需要同时执行多个聚合操作。这个过程叫做链式处理，可以使用下面这样的代码来实现：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mystream.chainedAgg()
        .partitionAggregate(new Count(), new Fields(&amp;quot;count&amp;quot;))
        .partitionAggregate(new Fields(&amp;quot;b&amp;quot;), new Sum(), new Fields(&amp;quot;sum&amp;quot;))
        .chainEnd()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这段代码会在每个分区上分别执行 Count 和 Sum 聚合器，而输出中只会包含一个带有 ["count", "sum"] 域的单独的 tuple。&lt;/p&gt;
&lt;h3&gt;stateQuery 与 partitionPersist&lt;/h3&gt;
&lt;p&gt;stateQuery 与 partitionPersist 会分别查询、更新 state 数据源。你可以参考 &lt;a href="http://storm.apache.org/documentation/Trident-state.html"&gt;Trident state doc&lt;/a&gt; 来了解如何使用它们。&lt;/p&gt;
&lt;h3&gt;projection&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;projection&lt;/code&gt; 方法只会保留操作中指定的域。如果你有一个带有 ["a", "b", "c", "d"] 域的数据流，通过执行这段代码：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mystream.project(new Fields(&amp;quot;b&amp;quot;, &amp;quot;d&amp;quot;))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;就会使得输出数据流中只包含有 ["b", "d"] 域。&lt;/p&gt;
&lt;h2&gt;重分区操作&lt;/h2&gt;
&lt;p&gt;重分区操作会执行一个用来改变在不同的任务间分配 tuple 的方式的函数。在重分区的过程中分区的数量也可能会发生变化（例如，重分区之后的并行度就有可能会增大）。重分区会产生一定的网络数据传输。下面是重分区操作的几个函数：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;shuffle：通过随机轮询算法来重新分配目标区块的所有 tuple。&lt;/li&gt;
&lt;li&gt;broadcast：每个 tuple 都会被复制到所有的目标区块中。这个函数在 DRPC 中很有用 —— 比如，你可以使用这个函数来获取每个区块数据的查询结果。&lt;/li&gt;
&lt;li&gt;partitionBy：该函数会接收一组域作为参数，并根据这些域来进行分区操作。可以通过对这些域进行哈希化，并对目标分区的数量取模的方法来选取目标区块。partitionBy 函数能够保证来自同一组域的结果总会被发送到相同的目标区间。&lt;/li&gt;
&lt;li&gt;global：这种方式下所有的 tuple 都会被发送到同一个目标分区中，而且数据流中的所有的块都会由这个分区处理。&lt;/li&gt;
&lt;li&gt;batchGlobal：同一个 batch 块中的所有 tuple 会被发送到同一个区块中。当然，在数据流中的不同区块仍然会分配到不同的区块中。&lt;/li&gt;
&lt;li&gt;partition：这个函数使用自定义的分区方法，该方法会实现 &lt;code&gt;backtype.storm.grouping.CustomStreamGrouping&lt;/code&gt; 接口。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;聚类操作&lt;/h2&gt;
&lt;p&gt;Trident 使用 aggregate 方法和 persistentAggregate 方法来对数据流进行聚类操作。其中，aggregate 方法会分别对数据流中的每个 batch 进行处理，而 persistentAggregate 方法则会对数据流中的所有 batch 执行聚类处理，并将结果存入某个 state 中。&lt;/p&gt;
&lt;p&gt;在数据流上执行 aggregate 方法会执行一个全局的聚类操作。在你使用 &lt;code&gt;ReducerAggregator&lt;/code&gt; 或者 &lt;code&gt;Aggregator&lt;/code&gt; 时，数据流首先会被重新分区成一个单独的分区，然后聚类函数就会在该分区上执行操作。而在你使用 &lt;code&gt;CombinerAggregator&lt;/code&gt; 时，Trident 首先会计算每个分区的部分聚类结果，然后将这些结果重分区到一个单独的分区中，最后在网络数据传输完成之后结束这个聚类过程。&lt;code&gt;CombinerAggregator&lt;/code&gt; 比其他的聚合器的运行效率更高，在聚类时应该尽可能使用 &lt;code&gt;CombinerAggregator&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;下面是一个使用 aggregate 来获取一个 batch 的全局计数值的例子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mystream.aggregate(new Count(), new Fields(&amp;quot;count&amp;quot;))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;与 partitionAggregate 一样，aggregate 的聚合器也可以进行链式处理。然而，如果你在一个处理链中同时使用了 &lt;code&gt;CombinerAggregator&lt;/code&gt; 和非 &lt;code&gt;CombinerAggregator&lt;/code&gt;，Trident 就不能对部分聚类操作进行优化了。&lt;/p&gt;
&lt;p&gt;想要了解更多使用 persistentAggregate 的方法，可以参考 &lt;a href="http://storm.apache.org/documentation/Trident-state.html"&gt;Trident state doc&lt;/a&gt; 一文。&lt;/p&gt;
&lt;h2&gt;对分组数据流的操作&lt;/h2&gt;
&lt;p&gt;通过对指定的域执行 partitionBy 操作，groupBy 操作可以将数据流进行重分区，使得相同的域的 tuple 分组可以聚集在一起。例如，下面是一个 groupBy 操作的示例：&lt;/p&gt;
&lt;p&gt;&lt;img alt="groupBy" src="http://storm.apache.org/documentation/images/grouping.png" /&gt;&lt;/p&gt;
&lt;p&gt;如果你在分组数据流上执行聚合操作，聚合器会在每个分组（而不是整个区块）上运行。persistentAggregate 同样可以在一个分组数据里上运行，这种情况下聚合结果会存储在 &lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/storm/trident/state/map/MapState.java"&gt;MapState&lt;/a&gt; 中，其中的 key 就是分组的域名。&lt;/p&gt;
&lt;p&gt;和其他操作一样，对分组数据流的聚合操作也可以以链式的方式执行。&lt;/p&gt;
&lt;h2&gt;融合（Merge）与联结（join）&lt;/h2&gt;
&lt;p&gt;Trident API 的最后一部分是联结不同的数据流的操作。联结数据流最简单的方式就是将所有的数据流融合到一个流中。你可以使用 TridentTopology 的 merge 方法实现该操作，比如这样：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;topology.merge(stream1, stream2, stream3);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Trident 会将融合后的新数据流的域命名为为第一个数据流的输出域。&lt;/p&gt;
&lt;p&gt;联结数据流的另外一种方法是使用 join。像 SQL 那样的标准 join 操作只能用于有限的输入数据集，对于无限的数据集就没有用武之地了。Trident 中的 join 只会应用于每个从 spout 中输出的小 batch。&lt;/p&gt;
&lt;p&gt;下面是两个流的 join 操作的示例，其中一个流含有 ["key", "val1", "val2"] 域，另外一个流含有 ["x", "val1"] 域：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;topology.join(stream1, new Fields(&amp;quot;key&amp;quot;), stream2, new Fields(&amp;quot;x&amp;quot;), new Fields(&amp;quot;key&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;));
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;上面的例子会使用 “key” 和 “x” 作为 join 的域来联结 stream1 和 stream2。Trident 要求先定义好新流的输出域，因为输入流的域可能会覆盖新流的域名。从 join 中输出的 tuple 中会包含：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;join 域的列表。在这个例子里，输出的 “key” 域与 stream1 的 “key” 域以及 stream2 的 “x” 域对应。&lt;/li&gt;
&lt;li&gt;来自所有流的非 join 域的列表。这个列表是按照传入 join 方法的流的顺序排列的。在这个例子里，“
a” 和 “b” 域与 stream1 的 “val1” 和 “val2” 域对应；而 “c” 域则与 stream2 的 “val1” 域相对应。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在对不同的 spout 发送出的流进行 join 时，这些 spout 上会按照他们发送 batch 的方式进行同步处理。也就是说，一个处理中的 batch 中含有每个 spout 发送出的 tuple。&lt;/p&gt;
&lt;p&gt;到这里你大概仍然会对如何进行窗口 join 操作感到困惑。窗口操作（包括平滑窗口、滚动窗口等 —— 译者注）主要是指将当前的 tuple 与过去若干小时时间段内的 tuple 联结起来的过程。&lt;/p&gt;
&lt;p&gt;你可以使用 partitionPersist 和 stateQuery 来实现这个过程。过去一段时间内的 tuple 会以 join 域为关键字被保存到一个 state 源中。然后就可以使用 stateQuery 查询 join 域来实现这个“联结”（join）的过程。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sat, 20 Jun 2015 20:10:57 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-20:pages/techs/storm-translations-trident-api-overview/</guid><category>Storm</category><category>Translation</category></item><item><title>Storm 官方文档翻译(7) —— Trident 教程</title><link>http://weyo.me/pages/techs/storm-translations-trident-tutorial/</link><description>&lt;h1&gt;Trident 教程&lt;/h1&gt;
&lt;p&gt;Trident 是 Storm 的一种高度抽象的实时计算模型，它可以将高吞吐量（每秒百万级）数据输入、带状态的流式处理与低延时的分布式查询无缝结合起来。如果你了解 Pig 或者 Cascading 这样的高级批处理工具，你就会发现 Trident 的概念非常相似。Trident 同样有联结（join）、聚合（aggregation）、分组（grouping）、函数（function）以及过滤器（filter）这些功能。Trident 为数据库或者其他持久化存储上层的状态化、增量式处理提供了基础原语。由于 Trident 有着一致的、恰好一次的语义，因此推断出 Trident 拓扑的状态也是一件很容易的事。&lt;/p&gt;
&lt;h2&gt;使用范例&lt;/h2&gt;
&lt;p&gt;让我们先从一个 Trident 使用的例子开始。这个例子中做了两件事情：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从一个句子的输入数据流中计算出单词流的数量&lt;/li&gt;
&lt;li&gt;实现对一个单词列表中每个单词总数的查询&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了实现这个目的，这个例子将会从下面的数据源中无限循环地读取语句数据流：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FixedBatchSpout spout = new FixedBatchSpout(new Fields(&amp;quot;sentence&amp;quot;), 3,
               new Values(&amp;quot;the cow jumped over the moon&amp;quot;),
               new Values(&amp;quot;the man went to the store and bought some candy&amp;quot;),
               new Values(&amp;quot;four score and seven years ago&amp;quot;),
               new Values(&amp;quot;how many apples can you eat&amp;quot;));
spout.setCycle(true);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个 Spout 会循环地访问语句集来生成语句数据流。下面的代码就是用来实现计算过程中的单词数据流统计部分：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TridentTopology topology = new TridentTopology();        
TridentState wordCounts =
     topology.newStream(&amp;quot;spout1&amp;quot;, spout)
       .each(new Fields(&amp;quot;sentence&amp;quot;), new Split(), new Fields(&amp;quot;word&amp;quot;))
       .groupBy(new Fields(&amp;quot;word&amp;quot;))
       .persistentAggregate(new MemoryMapState.Factory(), new Count(), new Fields(&amp;quot;count&amp;quot;))                
       .parallelismHint(6);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;让我们一行行地来分析上面的代码。首先我们创建了一个 &lt;code&gt;TridentTopology&lt;/code&gt; 对象，这个对象提供了构造 Trident 计算过程的接口。&lt;code&gt;TridentTopology&lt;/code&gt; 有一个叫做 &lt;code&gt;newStream&lt;/code&gt; 的方法，这个方法可以从一个输入数据源中读取数据创建一个新的数据流。在这个例子中，输入的数据源就是前面定义的 &lt;code&gt;FixedBatchSpout&lt;/code&gt;。输入数据源也可以是像 Kestrel 和 Kafka 这样的消息系统。Trident 会通过 ZooKeeper 一直跟踪每个输入数据源的一小部分状态（Trident 具体消费对象的相关元数据）。例如这里的 “spout1” 就对应着 ZooKeeper 中的一个节点，而 Trident 就会在该节点中存放数据源的元数据（metadata）。&lt;/p&gt;
&lt;p&gt;Trident 会将数据流处理为很多个小块 tuple 的集合，例如，输入的句子流就会像下面这样被分割成很多个小块：&lt;/p&gt;
&lt;p&gt;&lt;img alt="batches" src="http://storm.apache.org/documentation/images/batched-stream.png" /&gt;&lt;/p&gt;
&lt;p&gt;这些小块的大小主要取决于你的输入吞吐量，一般可能会在数万甚至数百万元组的级别。&lt;/p&gt;
&lt;p&gt;Trident 为这些小块提供了一个完全成熟的批处理 API。这个 API 和你见到过的 Pig 或者 Cascading 这样的 Hadoop 的高级抽象语言很相似：你可以处理分组（group by）、联结（join）、聚合（aggregation）、函数（function）、过滤器（filter）等各种操作。当然，分别处理每个小块并不是件好事，所以，Trident 提供了适用于处理各个小块之间的聚合操作的函数，并且可以在聚合后将结果保存到持久化存储中，而且无论是内存、Memcached、Cassandra 还是其他类型的存储都可以支持。最后，Trident 还提供了用于查询实时状态结果的一级接口。而这个结果状态既可以像这个例子中演示的那样由 Trident 负责更新，也可以作为一个独立的状态数据源而存在。&lt;/p&gt;
&lt;p&gt;再回到这个例子中，输入数据源 spout 发送出了一个名为 “sentence” 的数据流。接下来拓扑中定义了一个 &lt;code&gt;Split&lt;/code&gt; 方法用于处理流中的每个 tuple，这个方法接收 “sentence” 域并将其分割成若干个单词。每个 sentence tuple 都会创建很多个单词 tuple —— 例如 “the cow jumped over the moon” 这个句子就会创建 6 个 “word” tuple，下面是 &lt;code&gt;Split&lt;/code&gt; 的定义：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class Split extends BaseFunction {
   public void execute(TridentTuple tuple, TridentCollector collector) {
       String sentence = tuple.getString(0);
       for(String word: sentence.split(&amp;quot; &amp;quot;)) {
           collector.emit(new Values(word));                
       }
   }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;从上面的代码中你会发现这个过程真的很简单。这个方法中的所有操作仅仅是抓取句子、以空格分隔句子并且为每个单词发射一个 tuple。&lt;/p&gt;
&lt;p&gt;拓扑的剩余部分负责统计单词的数量并将结果保存到持久化存储中。首先，数据流根据 “word” 域分组，然后使用 &lt;code&gt;Count&lt;/code&gt; 聚合器持续聚合每个小组。&lt;code&gt;persistentAggregate&lt;/code&gt; 方法用于存储并更新 state 源中的聚合结果。在这个例子中，单词的数量结果是保存在内存中的，不过可以根据需要切换到 Memcached、Cassandra 或者其他持久化存储中。切换存储模型也非常简单，只需要像下面这样（使用 &lt;a href="https://github.com/nathanmarz/trident-memcached"&gt;trident-memcached&lt;/a&gt; 修改 &lt;code&gt;persistentAggregate&lt;/code&gt; 行中的一个参数（其中，“serverLocations” 是 Memcached 集群的地址/端口列表）即可：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="na"&gt;.persistentAggregate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="no"&gt;MemcachedState.transactional&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="no"&gt;serverLocations&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="no"&gt;new&lt;/span&gt; &lt;span class="no"&gt;Count&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="no"&gt;new&lt;/span&gt; &lt;span class="no"&gt;Fields&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;persistentAggregate&lt;/code&gt; 方法所存储的值就表示所有从数据流中发送出来的块的聚合结果。&lt;/p&gt;
&lt;p&gt;Trident 的另一个很酷的特性就是它支持完全容错性和恰好一次处理的语义。如果处理过程中出现错误需要重新执行处理操作，Trident 不会向数据库中提交多次来自相同的源数据的更新操作，这就是 Trident 持久化 state 的方式。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;persistentAggregate&lt;/code&gt; 方法也可以将数据流结果传入一个 &lt;code&gt;TridentState&lt;/code&gt; 对象中。这种情况下，这个 &lt;code&gt;TridentState&lt;/code&gt; 就表示所有的单词统计信息。这样我们就可以使用 &lt;code&gt;TridentState&lt;/code&gt; 对象来实现整个计算过程中的分布式查询部分。&lt;/p&gt;
&lt;p&gt;接下来我们就可以在拓扑中实现 word count 的一个低延时分布式查询。这个查询接收一个由空格分隔的单词列表作为参数，然后返回这些单词的数量统计结果。这个查询看上去与普通的 RPC 调用并没有什么分别，不过在后台他们是并发执行的。下面是一个实现这种查询的例子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;DRPCClient client = new DRPCClient(&amp;quot;drpc.server.location&amp;quot;, 3772);
System.out.println(client.execute(&amp;quot;words&amp;quot;, &amp;quot;cat dog the man&amp;quot;);
// prints the JSON-encoded result, e.g.: &amp;quot;[[5078]]&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如你所见，这个查询看上去只是一个普通的远程过程调用（RPC），不过在后台他是在一个 Storm 集群中并发执行的。这种查询的端到端延时一般在 10 ms 左右。当然，更大量的查询会花费更长的时间，尽管这些查询还是取决于你为这个计算过程分配了多少时间。&lt;/p&gt;
&lt;p&gt;拓扑中的分布式查询的实现是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;topology.newDRPCStream(&amp;quot;words&amp;quot;)
       .each(new Fields(&amp;quot;args&amp;quot;), new Split(), new Fields(&amp;quot;word&amp;quot;))
       .groupBy(new Fields(&amp;quot;word&amp;quot;))
       .stateQuery(wordCounts, new Fields(&amp;quot;word&amp;quot;), new MapGet(), new Fields(&amp;quot;count&amp;quot;))
       .each(new Fields(&amp;quot;count&amp;quot;), new FilterNull())
       .aggregate(new Fields(&amp;quot;count&amp;quot;), new Sum(), new Fields(&amp;quot;sum&amp;quot;));
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这里还需要使用前面的 &lt;code&gt;TridentTopology&lt;/code&gt; 对象来创建一个 DRPC 数据流，这个创建数据流的方法叫做 “words”。前面使用 &lt;code&gt;DRPCClient&lt;/code&gt; 进行 RPC 调用的第一个参数必须与这个方法名完全相同。&lt;/p&gt;
&lt;p&gt;在这段代码里，首先是使用 &lt;code&gt;Split&lt;/code&gt; 方法来将请求的参数分割成若干个单词。这些单词构成的单词流是通过 “word” 域来分组的，而 &lt;code&gt;stateQuery&lt;/code&gt; 运算符就是用来查询拓扑中第一个部分中生成的 &lt;code&gt;TridentState&lt;/code&gt; 对象的。&lt;code&gt;stateQuery&lt;/code&gt; 接收一个 state（在这个例子中就是拓扑前面计算得到的单词数结果）和查询这个 state 的方法作为参数。在这个例子里，&lt;code&gt;stateQuery&lt;/code&gt; 调用了 &lt;code&gt;MapGet&lt;/code&gt; 方法，用于获取每个单词的个数。由于 DRPC 数据流是和 TridentState 采用的完全相同的方式进行分组的（通过 “word” 域），每个单词查询都可以精确地定位到 TridentState 对象中的指定部分，同时 TridentState 对象中维护着对应的单词的更新状态。&lt;/p&gt;
&lt;p&gt;接下来，个数为 0 的单词会被 &lt;code&gt;FilterNull&lt;/code&gt; 过滤器过滤掉，然后就可以使用 &lt;code&gt;Sum&lt;/code&gt; 聚合器来获取其他的单词统计个数。接着 Trident 就会自动将结果返回给等待的客户端。&lt;/p&gt;
&lt;p&gt;Trident 很聪明，它知道怎么以最好的性能运行拓扑。在这个拓扑中还有两个会自动发生的有趣的事：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;从 state 中读取或写入的操作（例如 persistentAggregate 和 stateQuery）会自动批处理化。因此，如果当前的批处理过程需要对数据库执行 20 个更新操作，Trident 就会自动将读取或写入操作当作批处理过程，仅仅会对数据库发送一次读请求和一次写请求，而不是发送 20 次读请求和 20 次写请求（而且一般你还可以在你的 state 里使用缓存来消除读请求）。这样做就有两个方面的好处：可以按照你指定的方式来执行你的计算过程，同时还可以维持较好的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Trident 的聚合器是高度优化的。在向网络中发送 tuple 之前，Trident 有时候会做部分聚合操作，而不是将一个分组的所有的 tuple 一股脑地发送到同一台机器中来执行聚合。例如，&lt;code&gt;Count&lt;/code&gt; 聚合器就是这样先计算每个小块的个数，然后向网络中发送很多个部分计数的结果，接着再将所有的部分计数结果汇总来得到最终的统计结果。这个技术与 MapReduce 的 combiner 模型很相似。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们再来看看 Trident 的另一个例子。&lt;/p&gt;
&lt;h2&gt;Reach&lt;/h2&gt;
&lt;p&gt;这个例子是一个纯粹的 DRPC 拓扑，计算了一个指定 URL 的 Reach 数。Reach 指的是 Twitter 上能够看到一个指定的 URL 的独立用户数。要想计算 Reach，你需要先提取所有转发了该 URL 的用户，提取这些用户的关注者，将关注者放入一个 set 集合中来去除重复的关注者，然后再统计这个 set 中的数量。对于单一的一台机器来说，计算 reach 太耗时了，这个过程大概需要数千次数据库调用并生成数千万 tuple。而使用 Storm 和 Trident 就可以通过一个集群来将计算过程的每个步骤进行并行化处理。&lt;/p&gt;
&lt;p&gt;这个拓扑会从两个 state 源中读取数据。其中一个数据库建立了 URL 和转发了该 URL 的用户列表的关联表。另一个数据库中建立了用户和用户的关注者列表的关联表。拓扑的定义是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TridentState urlToTweeters =
       topology.newStaticState(getUrlToTweetersState());
TridentState tweetersToFollowers =
       topology.newStaticState(getTweeterToFollowersState());

topology.newDRPCStream(&amp;quot;reach&amp;quot;)
       .stateQuery(urlToTweeters, new Fields(&amp;quot;args&amp;quot;), new MapGet(), new Fields(&amp;quot;tweeters&amp;quot;))
       .each(new Fields(&amp;quot;tweeters&amp;quot;), new ExpandList(), new Fields(&amp;quot;tweeter&amp;quot;))
       .shuffle()
       .stateQuery(tweetersToFollowers, new Fields(&amp;quot;tweeter&amp;quot;), new MapGet(), new Fields(&amp;quot;followers&amp;quot;))
       .parallelismHint(200)
       .each(new Fields(&amp;quot;followers&amp;quot;), new ExpandList(), new Fields(&amp;quot;follower&amp;quot;))
       .groupBy(new Fields(&amp;quot;follower&amp;quot;))
       .aggregate(new One(), new Fields(&amp;quot;one&amp;quot;))
       .parallelismHint(20)
       .aggregate(new Count(), new Fields(&amp;quot;reach&amp;quot;));
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个拓扑使用 &lt;code&gt;newStaticState&lt;/code&gt; 方法创建了两个分别对应外部于两个外部数据库的 &lt;code&gt;TridentState&lt;/code&gt; 对象。在拓扑的后续部分就可以对这两个 &lt;code&gt;TridentState&lt;/code&gt; 对象执行查询操作。和 state 的所有数据源一样，为了最大程度地提升效率，对这些数据库的查询将会自动地批处理化。&lt;/p&gt;
&lt;p&gt;拓扑的定义很直接 —— 就是一个简单的批处理 job。首先，会通过查询 urlToTweeters 数据库来获取转发了 URL 的用户列表，然后就可以调用 &lt;code&gt;ExpandList&lt;/code&gt; 方法来为每个 tweeter 创建一个 tuple。&lt;/p&gt;
&lt;p&gt;接下来必须要获取每个 tweeter 的关注者。由于需要调用 shuffle 方法将所有的 tweeter 均衡分配到拓扑的所有 worker 中，所以这个步骤必须并发进行，这一点非常重要。然后就可以查询关注者数据库来获取每个 tweeter 的关注者列表。你可能注意到了这个过程的并行度非常高，因为这是整个计算过程中复杂度最高的部分。&lt;/p&gt;
&lt;p&gt;再接下来，关注者就会被放入一个单独的 set 集合中用于计数。这里包含两个步骤。首先，会根据 “follower” 域来执行 “group by” 分组操作，并在每个组上运行 &lt;code&gt;One&lt;/code&gt; 聚合器。“One”聚合器的作用仅仅是为每个组发送一个包含数字 1 的 tuple。然后，就可以通过统计这些 one 结果来得到关注者 set 的大小，也就是真正的关注者数量。下面是 “One” 聚合器的定义：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class One implements CombinerAggregator&amp;lt;Integer&amp;gt; {
   public Integer init(TridentTuple tuple) {
       return 1;
   }

   public Integer combine(Integer val1, Integer val2) {
       return 1;
   }

   public Integer zero() {
       return 1;
   }        
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这是一个“组合聚合器”，它知道怎样在向网络中发送 tuple 之前以最好的效率进行部分聚合操作。同样，Sum 也是一个组合聚合器，所以在拓扑结尾的全局统计操作也会有很高的效率。&lt;/p&gt;
&lt;p&gt;下面让我们再来看看 Trident 中的一些细节。&lt;/p&gt;
&lt;h2&gt;域（Fields）与元组（tuples）&lt;/h2&gt;
&lt;p&gt;Trident 的数据模型 TridentTuple 是一个指定的值列表。在一个拓扑中，tuple 是在一系列操作中不断生成的。这些操作一般会输入一个“输入域”（input fields）集合，然后发送出一个“方法域”（function fields）的集合。输入域主要用于选取一个 tuple 的子集作为操作的输入，而“方法域”主要用于为该操作的输出结果域命名。&lt;/p&gt;
&lt;p&gt;我们来看看这样一个场景。假设你有一个名为 “stream” 的数据流，其中包含域 “x”、“y” 和 “z”。如果要运行一个接收 “y” 作为输入的过滤器 MyFilter，你可以这样写：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;stream.each(new Fields(&amp;quot;y&amp;quot;), new MyFilter())
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;再假设 MyFilter 的实现是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class MyFilter extends BaseFilter {
   public boolean isKeep(TridentTuple tuple) {
       return tuple.getInteger(0) &amp;lt; 10;
   }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这样就会保留所有 “y” 域的值小于 10 的 tuple。MyFilter 输入的 TridentTuple 将会仅包含有 “y” 域。值得注意的是，Trident 可以在选取输入域时以一种非常高效的方式来投射 tuple 的子集：这个投射过程非常灵活。&lt;/p&gt;
&lt;p&gt;我们再来看看 “function fields” 是怎么工作的。假设你有这样一个函数：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class AddAndMultiply extends BaseFunction {
   public void execute(TridentTuple tuple, TridentCollector collector) {
       int i1 = tuple.getInteger(0);
       int i2 = tuple.getInteger(1);
       collector.emit(new Values(i1 + i2, i1 * i2));
   }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个函数接收两个数字作为输入，然后发送出两个新值：分别是两个数字的和和乘积。再假定你有一个包含 “x”、“y” 和 “z” 域的数据流，你可以这样使用这个函数：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;stream.each(new Fields(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), new AddAndMultiply(), new Fields(&amp;quot;added&amp;quot;, &amp;quot;multiplied&amp;quot;));
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个函数的输出增加了两个新的域。因此，这个 each 调用的输出 tuple 会包含 5 个域：“x”、“y” 、“z”、“added” 和 “multiplied”。其中 “added” 与 AddAndMultiply 的第一个输出值相对应，“multiplied” 和 AddAndMultiply 的第二个输出值相对应。&lt;/p&gt;
&lt;p&gt;另一方面，通过聚合器，函数域也可以替换输入 tuple 的域。假如你有一个包含域 “val1” 和域 “val2” 的数据流，通过这样的操作：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;stream.aggregate(new Fields(&amp;quot;val2&amp;quot;), new Sum(), new Fields(&amp;quot;sum&amp;quot;))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;就会使得输出数据流中只包含一个只带有 “sum” 的域的 tuple，这个 “sum” 域就代表了在哪个批处理块中所有的 “val2” 域的总和值。&lt;/p&gt;
&lt;p&gt;通过数据流分组，输出就可以同时包含用于分组的域以及由聚合器发送的域。举个例子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;stream.groupBy(new Fields(&amp;quot;val1&amp;quot;))
     .aggregate(new Fields(&amp;quot;val2&amp;quot;), new Sum(), new Fields(&amp;quot;sum&amp;quot;))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个操作就会使得输出同时包含域 “val1” 以及域 “sum”。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;State&lt;/h2&gt;
&lt;p&gt;实时计算的一个关键问题就在于如何管理状态（state），使得在失败与重试操作之后的更新过程仍然是幂等的。错误是不可消除的，所以在出现节点故障或者其他问题发生时批处理操作还需要进行重试。不过这里最大的问题就在于怎样执行一种合适的状态更新操作（不管是针对外部数据库还是拓扑内部的状态），来使得每个消息都能够被执行且仅仅被执行一次。&lt;/p&gt;
&lt;p&gt;这个问题很麻烦，接下来的例子里面就有这样的问题。假如你正在对你的数据流做一个计数聚合操作，并且打算将计数结果存储到一个数据库中。如果你仅仅把计数结果存到数据库里就完事了的话，那么在你继续准备更新某个块的状态的时候，你没法知道到底这个状态有没有被更新过。这个数据块有可能在更新数据库的步骤上成功了，但在后续的步骤中失败了，也有可能先失败了，没有进行更新数据库的操作。你完全不知道到底发生了什么。&lt;/p&gt;
&lt;p&gt;Trident 通过下面两件事情解决了这个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在 Trident 中为每个数据块标记了一个唯一的 id，这个 id 就叫做“事务 id”（transaction id）。如果数据块由于失败回滚了，那么它持有的事务 id 不会改变。&lt;/li&gt;
&lt;li&gt;State 的更新操作是按照数据块的顺序进行的。也就是说，在成功执行完块 2 的更新操作之前，不会执行块 3 的更新操作。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;基于这两个基础特性，你的 state 更新就可以实现恰好一次（exactly-once）的语义。与仅仅向数据库中存储计数不同，这里你可以以一个原子操作的形式把事务 id 和计数值一起存入数据库。在后续更新这个计数值的时候你就可以先比对这个数据块的事务 id。如果比对结果是相同的，那么就可以跳过更新操作 —— 由于 state 的强有序性，可以确定数据库中已经包含有当前数据库的额值。而如果比对结果不同，就可以放心地更新计数值了。&lt;/p&gt;
&lt;p&gt;当然，你不需要在拓扑中手动进行这个操作，操作逻辑已经在 State 中封装好了，这个过程会自动进行。同样的，你的 State 对象也不一定要实现事务 id 标记：如果你不想在数据库里耗费空间存储事务 id，你就不用那么做。在这样的情况下，State 会在出现失败的情形下保持“至少处理一次”的操作语义（这样对你的应用也是一件好事）。在&lt;a href="http://storm.apache.org/documentation/Trident-state"&gt;这篇文章&lt;/a&gt;里你可以了解到更多关于如何实现 State 以及各种容错性权衡技术。&lt;/p&gt;
&lt;p&gt;你可以使用任何一种你想要的方法来实现 state 的存储操作。你可以把 state 存入外部数据库，也可以保存在内存中然后在存入 HDFS 中（有点像 HBase 的工作机制）。State 也并不需要一直保存某个状态值。比如，你可以实现一个只保存过去几个小时数据并将其余的数据删除的 State。这是一个实现 State 的例子：&lt;a href="https://github.com/nathanmarz/trident-memcached/blob/master/src/jvm/trident/memcached/MemcachedState.java"&gt;Memcached integration&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;Trident 拓扑的运行&lt;/h2&gt;
&lt;p&gt;Trident 拓扑会被编译成一种尽可能和普通拓扑有着同样的运行效率的形式。只有在请求数据的重新分配（比如 groupBy 或者 shuffle 操作）时 tuple 才会被发送到网络中。因此，像下面这样的 Trident 拓扑：&lt;/p&gt;
&lt;p&gt;&lt;img alt="trident-topology" src="http://storm.apache.org/documentation/images/trident-to-storm1.png" /&gt;&lt;/p&gt;
&lt;p&gt;就会被编译成若干个 spout/bolt：&lt;/p&gt;
&lt;p&gt;&lt;img alt="trident-to-spout-and-bolt" src="http://storm.apache.org/documentation/images/trident-to-storm2.png" /&gt;&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;Trident 让实时计算变得非常简单。你已经看到了高吞吐量的数据流处理、状态操作以及低延时查询处理是怎样通过 Trident 的 API 来实现无缝结合的。总而言之，Trident 可以让你以一种更加自然，同时仍然保持着很好的性能的方式实现实时计算。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Fri, 19 Jun 2015 21:45:33 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-19:pages/techs/storm-translations-trident-tutorial/</guid><category>Storm</category><category>Translation</category></item><item><title>Worker 启动后异常退出问题的排查解决</title><link>http://weyo.me/pages/techs/storm-worker-die-with-exceptions/</link><description>&lt;p&gt;最近应用升级之后，有个机器上的 worker 总会在启动一段时间后挂掉。worker 日志如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt; 2015-06-18T17:19:19.931+0800 o.a.s.c.ConnectionState [ERROR] Connection timed out for connection string (z124:2181,z128:2181,z168:2181/storm) and timeout (15000) / elapsed (16172)&lt;/span&gt;
&lt;span class="x"&gt;492856 org.apache.storm.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss&lt;/span&gt;
&lt;span class="x"&gt;492857         at org.apache.storm.curator.ConnectionState.checkTimeouts(ConnectionState.java:198) [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492858         at org.apache.storm.curator.ConnectionState.getZooKeeper(ConnectionState.java:88) [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492859         at org.apache.storm.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115) [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492860         at org.apache.storm.curator.framework.imps.CuratorFrameworkImpl.getZooKeeper(CuratorFrameworkImpl.java:488) [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492861         at org.apache.storm.curator.framework.imps.ExistsBuilderImpl&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="x"&gt;2.call(ExistsBuilderImpl.java:168) [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492862         at org.apache.storm.curator.framework.imps.ExistsBuilderImpl&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="x"&gt;2.call(ExistsBuilderImpl.java:161) [storm-core-0.9.3.jar:0.9.3]492863         at org.apache.storm.curator.RetryLoop.callWithRetry(RetryLoop.java:107) [storm-core-0.9.3.jar:0.9.3]492864         at org.apache.storm.curator.framework.imps.ExistsBuilderImpl.pathInForeground(ExistsBuilderImpl.java:157) [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492865         at org.apache.storm.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:148) [storm-core-0.9.3.jar:0.9.3]492866         at org.apache.storm.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:36) [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492867         at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source) ~[na:na]&lt;/span&gt;
&lt;span class="x"&gt;492868         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_71]&lt;/span&gt;
&lt;span class="x"&gt;492869         at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_71]&lt;/span&gt;
&lt;span class="x"&gt;492870         at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) [clojure-1.5.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;492871         at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) [clojure-1.5.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;492872         at backtype.storm.zookeeper&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;get_version&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;zookeeper.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;156&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492873         at backtype.storm.cluster&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;mk_distributed_cluster_state&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;reify__1915&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;get_version&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;cluster.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;111&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492874         at backtype.storm.cluster&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;mk_storm_cluster_state&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;reify__2372&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;assignment_version&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;cluster.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;287&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492875         at sun.reflect.GeneratedMethodAccessor43.invoke(Unknown Source) ~[na:na]&lt;/span&gt;
&lt;span class="x"&gt;492876         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_71]&lt;/span&gt;
&lt;span class="x"&gt;492877         at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_71]&lt;/span&gt;
&lt;span class="x"&gt;492878         at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) [clojure-1.5.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;492879         at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) [clojure-1.5.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;492880         at backtype.storm.daemon.worker&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;mk_refresh_connections&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;this__3690&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;worker.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;255&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492881         at backtype.storm.daemon.worker&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;mk_refresh_connections&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;this__3690&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;worker.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;253&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492882         at backtype.storm.timer&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;schedule_recurring&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;this__1649&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;timer.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;99&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492883         at backtype.storm.timer&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;mk_timer&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__1632&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__1633&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;timer.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492884         at backtype.storm.timer&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;mk_timer&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__1632&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;timer.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; [storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;492885         at clojure.lang.AFn.run(AFn.java:24) [clojure-1.5.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;492886         at java.lang.Thread.run(Thread.java:745) [na:1.7.0_71]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;而同一时间的 supervisor 不停地提示 “{id} still hasn't started”&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;2015-06-18T17:14:56.752+0800 b.s.d.supervisor [INFO] 2376a892-2a8a-401e-9bd6-85059ab57586 still hasn&amp;#39;t started
646 2015-06-18T17:14:57.254+0800 b.s.d.supervisor [INFO] 2376a892-2a8a-401e-9bd6-85059ab57586 still hasn&amp;#39;t started
647 2015-06-18T17:14:57.756+0800 b.s.d.supervisor [INFO] 2376a892-2a8a-401e-9bd6-85059ab57586 still hasn&amp;#39;t started
...（若干条重复的信息）
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当然，正常情况下 supervisor 在刚启动 worker 的时候也会报这个信息，只不过会在 worker 正常运行之后恢复正常。但是这里的 supervisor 之后仍然会不停地尝试重连，并且最终在超时后放弃这个 worker，这个就不属于正常情况了。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;2015-06-18T17:17:07.880+0800 o.a.s.z.ClientCnxn [INFO] Unable to read additional data from server sessionid 0x804de6f8a15a0000, likely server has closed socket, closing socket connection and attempting reco    nnect
668 2015-06-18T17:17:19.491+0800 o.a.s.z.ClientCnxn [INFO] Opening socket connection to server hd124/192.168.91.124:2181. Will not attempt to authenticate using SASL (unknown error)
669 2015-06-18T17:17:19.492+0800 o.a.s.z.ClientCnxn [INFO] Socket connection established to hd124/192.168.91.124:2181, initiating session
670 2015-06-18T17:17:19.495+0800 o.a.s.z.ClientCnxn [INFO] Session establishment complete on server hd124/192.168.91.124:2181, sessionid = 0x804de6f8a15a0000, negotiated timeout = 20000671 2015-06-18T17:17:27.913+0800 o.a.s.c.f.s.ConnectionStateManager [INFO] State change: SUSPENDED
672 2015-06-18T17:17:27.918+0800 b.s.cluster [WARN] Received event :disconnected::none: with disconnected Zookeeper.
673 2015-06-18T17:17:27.918+0800 o.a.s.c.f.s.ConnectionStateManager [INFO] State change: RECONNECTED

...

689 2015-06-18T17:18:21.492+0800 o.a.s.z.ClientCnxn [INFO] Unable to reconnect to ZooKeeper service, session 0x804de6f8a15a0000 has expired, closing socket connection
690 2015-06-18T17:18:21.492+0800 o.a.s.c.f.s.ConnectionStateManager [INFO] State change: LOST
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个问题乍一看是网络问题，而且很多帖子也这么说，比如&lt;a href="http://blog.csdn.net/jmppok/article/details/17073397]"&gt;http://blog.csdn.net/jmppok/article/details/17073397&lt;/a&gt; 还有 SO 上面搜到的几篇答案说的都是 hosts 配置问题。不过这里的配置并没有问题，网络也没有问题，Storm 的元数据也正常。&lt;/p&gt;
&lt;p&gt;另外也有说是 JVM 配置问题（&lt;a href="http://macrochen.iteye.com/blog/1428093"&gt;http://macrochen.iteye.com/blog/1428093&lt;/a&gt;），但实际上机器的内存一直很稳定，而且 JVM 的日志记录也正常。由于我是在执行 DRPC 的时候出现问题的，还特意检查/重启了 DRPC 服务器，发现也不是 DRPC 的问题。&lt;/p&gt;
&lt;p&gt;这些都没问题，那就有可能是 CPU 的问题了，top 看一下（没有装 sar 和 iostat 就先这么凑合了）&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;top - 09:36:52 up 17 days, 21:16,  1 user,  load average: 20.31, 19.13, 11.12
Tasks: 128 total,   6 running, 122 sleeping,   0 stopped,   0 zombie
Cpu(s): 27.0%us, 73.0%sy,  0.0%ni,  0.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:   2075036k total,  2021612k used,    53424k free,   131148k buffers
Swap:  4128760k total,       68k used,  4128692k free,   722616k cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                                                             
 4950 root      18   0  698m 573m  13m S 99.2 28.3  10:50.45 java  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;果然，99.2% 的 CPU 占用，系统不能长时间承受这么高的负载，就中断了 worker 进程。这个理由可以解释，因为确实我们在新版本应用里把吞吐量加大了一倍，从 Storm UI 中可以看出，在拓扑刚上线的时候，处理量较大的 bolt 的 capacity 会瞬间飙升到接近 1 的程度，虽然在后面数据流平稳下来之后可以慢慢降低，但是这个过程还是有很大的不确定性。所以，暂时需要先把吞吐量降下来，再考虑慢慢调整。不过，这个问题还没这么简单。因为我发现集群中同配置的另一个机器就没有这个问题，而且即使在这台机器 worker 挂掉，nimbus 将这台机器的 worker 分配到另外那台机器的情况下，那台机器上的 CPU 也只有 80+%。同样配置同样的网络运行同样的进程怎么会有这么大的差异？&lt;/p&gt;
&lt;p&gt;对这个问题苦思了半天不得其解，最后想想还是要看看 CPU 设备信息有没有什么问题。然后，就没有然后了，额，不对，说顺口了，然后应该就是出现真相的地方了&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[root@s2 /home/storm/apache-storm-0.9.3/logs]$&amp;gt;cat /proc/cpuinfo 
processor   : 0
vendor_id   : GenuineIntel
cpu family  : 6
model       : 62
model name  : Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这里只有一个 CPU。真是让人哭笑不得，我们的服务器都是用的分配的虚拟机，也不知道谁把这台机器只分了个单核的 CPU，数据流压力稍微高点当然会扛不住。但是也没办法，现在服务器资源还紧张，只能这么凑合着用，然后继续等着新服务器的申请什么时候能批下来……&lt;/p&gt;
&lt;p&gt;当然，除了硬件方面的问题之外，拓扑本身也还有可以优化的地方。一方面，从 Storm UI 上观察到的某些负载较大的 bolt 也确实需要调整下并发度；另一方面，数据流优先进入的部分 bolt 也需要优化下处理方法。这样双管齐下才能真正地解决好问题。&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;彩蛋&lt;/strong&gt; # get 到的新技能
- 在 worker 没有日志的时候可以手动执行 supervisor 中的启动命令（就是 “java xxx” 那个大长串）来启动 worker&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h1&gt;Reference&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://grokbase.com/t/gg/storm-user/131v9gv614/supervisor-is-not-able-to-start-worker-log-files-are-empty"&gt;http://grokbase.com/t/gg/storm-user/131v9gv614/supervisor-is-not-able-to-start-worker-log-files-are-empty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Fri, 19 Jun 2015 19:41:02 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-19:pages/techs/storm-worker-die-with-exceptions/</guid><category>Storm</category></item><item><title>Storm 官方文档翻译(6) —— 理解 Storm 拓扑的并行度(parallelism)概念</title><link>http://weyo.me/pages/techs/storm-translations-understanding-the-parallelism-of-a-storm-topology/</link><description>&lt;h1&gt;理解 Storm 拓扑的并行度(parallelism)概念&lt;/h1&gt;
&lt;h2&gt;一个运行中的拓扑是由什么构成的：工作进程（worker processes），执行器（executors）和任务（tasks）&lt;/h2&gt;
&lt;p&gt;在一个 Storm 集群中，Storm 主要通过以下三个部件来运行拓扑：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;工作进程（worker processes）&lt;/li&gt;
&lt;li&gt;执行器（executors）&lt;/li&gt;
&lt;li&gt;任务（tasks）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面是他们之间相互关系的简单图示。&lt;/p&gt;
&lt;p&gt;&lt;img alt="relationship" src="https://raw.githubusercontent.com/weyo/Storm-Documents/master/Manual/images/fig-parallelism-1.png" /&gt;&lt;/p&gt;
&lt;p&gt;在 Worker 中运行的是拓扑的一个子集。一个 worker 进程是从属于某一个特定的拓扑的，在 worker 进程中会运行一个或者多个与拓扑中的组件相关联的 executor。一个运行中的拓扑就是由这些运行于 Storm 集群中的很多机器上的进程组成的。&lt;/p&gt;
&lt;p&gt;一个 executor 是由 worker 进程生成的一个线程。在 executor 中可能会有一个或者多个 task，这些 task 都是为同一个组件（spout 或者 bolt）服务的。&lt;/p&gt;
&lt;p&gt;task 是实际执行数据处理的最小工作单元（注意，task 并不是线程） —— 在你的代码中实现的每个 spout 或者 bolt 都会在集群中运行很多个 task。在拓扑的整个生命周期中每个组件的 task 数量都是保持不变的，不过每个组件的 executor 数量却是有可能会随着时间变化。在默认情况下 task 的数量是和 executor 的数量一样的，也就是说，默认情况下 Storm 会在每个线程上运行一个 task。&lt;/p&gt;
&lt;h2&gt;配置拓扑的并行度（parallelism）&lt;/h2&gt;
&lt;p&gt;注意，这里所说的术语“并行度”主要是用于表示所谓的 &lt;code&gt;parallelism_hint&lt;/code&gt;，它代表着一个组件的初始 executor （也是线程）数量。在这篇文章里，我们使用这个“并行度”术语来说明在 Storm 拓扑中既可以配置 executor 的数量，也可以配置 worker 和 task 的数量。如果“并行度”的概念需要表示其他的一般情况，我们也会特别指出。&lt;/p&gt;
&lt;p&gt;下面的内容里显示了很多可配置选项，以及在代码中配置他们的方法。可以用于配置的方法有很多种，这里列出的只是其中一部分。另外需要注意的是，Storm 的&lt;a href="https://github.com/weyo/Storm-Documents/blob/master/Manual/zh/Configuration.md"&gt;配置优先级&lt;/a&gt;为 &lt;code&gt;defaults.yaml&lt;/code&gt; &amp;lt; &lt;code&gt;storm.yaml&lt;/code&gt; &amp;lt; 拓扑配置 &amp;lt; 内置型组件信息配置 &amp;lt; 外置型组件信息配置。&lt;/p&gt;
&lt;h2&gt;Worker 数量&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;说明：拓扑在集群中运行所需要的工作进程数&lt;/li&gt;
&lt;li&gt;配置选项：&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/Config.html#TOPOLOGY_WORKERS"&gt;TOPOLOGY_WORKERS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;在代码中如何使用（示例）：&lt;ul&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/Config.html"&gt;Config#setNumWorkers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Executors（线程）数量&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;说明：每个组件需要的执行线程数&lt;/li&gt;
&lt;li&gt;配置选项：（没有拓扑级的通用配置项）&lt;/li&gt;
&lt;li&gt;在代码中如何使用（示例）：&lt;ul&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/TopologyBuilder.html"&gt;TopologyBuilder#setSpout()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/TopologyBuilder.html"&gt;TopologyBuilder#setBolt()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注意：从 Storm 0.8 开始 &lt;code&gt;parallelism_hint&lt;/code&gt; 参数代表 executor 的数量，而不是 task 的数量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tasks 数量&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;说明：每个组件需要的执行任务数&lt;/li&gt;
&lt;li&gt;配置选项：&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/Config.html#TOPOLOGY_TASKS"&gt;TOPOLOGY_TASKS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;在代码中如何使用（示例）：&lt;ul&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/ComponentConfigurationDeclarer.html"&gt;ComponentConfigurationDeclarer#setNumTasks()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下是配置上述参数的一个简单示例代码：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;topologyBuilder.setBolt(&amp;quot;green-bolt&amp;quot;, new GreenBolt(), 2)
               .setNumTasks(4)
               .shuffleGrouping(&amp;quot;blue-spout);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在上面的代码中，我们为 &lt;code&gt;GreenBolt&lt;/code&gt; 配置了 2 个初始执行线程（executor）和 4 个关联任务（task）。这样，每个执行线程中会运行 2 个任务。如果你在设置 bolt 的时候不指定 task 的数量，那么每个 executor 的 task 数会默认设置为 1。&lt;/p&gt;
&lt;h2&gt;拓扑示例&lt;/h2&gt;
&lt;p&gt;下图显示了一个与实际应用场景很接近的简单拓扑的结构。这个拓扑由三个组件构成：一个名为 &lt;code&gt;BlueSpout&lt;/code&gt; 的 spout，和两个名为 &lt;code&gt;GreenBolt&lt;/code&gt; 和 &lt;code&gt;YellowBolt&lt;/code&gt; 的 bolt。这些组件之间的关系是：&lt;code&gt;BlueSpout&lt;/code&gt; 将它的输出发送到 &lt;code&gt;GreenBolt&lt;/code&gt; 中，然后 &lt;code&gt;GreenBolt&lt;/code&gt; 将消息继续发送到 &lt;code&gt;YellowBolt&lt;/code&gt; 中。&lt;/p&gt;
&lt;p&gt;&lt;img alt="running-topology" src="http://storm.apache.org/documentation/images/example-of-a-running-topology.png" /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图中是一个包含有两个 worker 进程的拓扑。其中，蓝色的 &lt;code&gt;BlueSpout&lt;/code&gt; 有两个 executor，每个 executor 中有一个 task，并行度为 2；绿色的 &lt;code&gt;GreenBolt&lt;/code&gt; 有两个 executor，每个 executor 有两个 task，并行度也为2；而黄色的 &lt;code&gt;YellowBolt&lt;/code&gt; 有 6 个 executor，每个 executor 中有一个 task，并行度为 6，因此，这个拓扑的总并行度就是 2 + 2 + 6 = 10。具体分配到每个 worker 就有 10 / 2 = 5 个 executor。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上图中，&lt;code&gt;GreenBolt&lt;/code&gt; 配置了 task 数，而 &lt;code&gt;BlueSpout&lt;/code&gt; 和 &lt;code&gt;YellowBolt&lt;/code&gt; 仅仅配置了 executor 数。下面是相关代码：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Config conf = new Config();
conf.setNumWorkers(2); // use two worker processes

topologyBuilder.setSpout(&amp;quot;blue-spout&amp;quot;, new BlueSpout(), 2); // set parallelism hint to 2

topologyBuilder.setBolt(&amp;quot;green-bolt&amp;quot;, new GreenBolt(), 2)
               .setNumTasks(4)
               .shuffleGrouping(&amp;quot;blue-spout&amp;quot;);

topologyBuilder.setBolt(&amp;quot;yellow-bolt&amp;quot;, new YellowBolt(), 6)
               .shuffleGrouping(&amp;quot;green-bolt&amp;quot;);

StormSubmitter.submitTopology(
        &amp;quot;mytopology&amp;quot;,
        conf,
        topologyBuilder.createTopology()
    );
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当然，Storm 还有一些其他的配置项可以控制拓扑的并行度，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/Config.html#TOPOLOGY_MAX_TASK_PARALLELISM"&gt;TOPOLOGY_MAX_TASK_PARALLELISM&lt;/a&gt;：该选项设置了一个组件最多能够分配的 executor 数（线程数上限），一般用于在本地模式运行拓扑时测试分配线程的数量限制。你可以通过 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/Config.html#setMaxTaskParallelism(int)"&gt;Config#setMaxTaskParallelism()&lt;/a&gt; 来配置该参数。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;如何修改运行中的拓扑的并行度&lt;/h2&gt;
&lt;p&gt;Storm 的一个很有意思的特点是你可以随时增加或者减少 worker 或者 executor 的数量，而不需要重启集群或者拓扑。这个方法就叫做再平衡（rebalance）。&lt;/p&gt;
&lt;p&gt;有两种方法可以对一个拓扑执行再平衡操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用 Storm UI&lt;/li&gt;
&lt;li&gt;使用以下所示的客户端（CLI）工具&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面是使用 CLI 工具的一个简单示例：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;## 重新配置拓扑 &amp;quot;mytopology&amp;quot;，使得该拓扑拥有 5 个 worker processes，
## 另外，配置名为 &amp;quot;blue-spout&amp;quot; 的 spout 使用 3 个 executor，
## 配置名为 &amp;quot;yellow-bolt&amp;quot; 的 bolt 使用 10 个 executor。

$ storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Thu, 18 Jun 2015 19:29:02 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-18:pages/techs/storm-translations-understanding-the-parallelism-of-a-storm-topology/</guid><category>Storm</category><category>Translation</category></item><item><title>Storm 官方文档翻译(5) —— 命令行操作</title><link>http://weyo.me/pages/techs/storm-translations-command-line-client/</link><description>&lt;h1&gt;命令行操作&lt;/h1&gt;
&lt;p&gt;本文介绍了 Storm 命令行客户端中的所有命令操作。如果想要了解怎样设置你的 Strom 客户端和远程集群的交互，请按照&lt;a href="http://storm.apache.org/documentation/Setting-up-a-development-environment.html"&gt;配置开发环境&lt;/a&gt;一文中的步骤操作。&lt;/p&gt;
&lt;p&gt;Storm 中支持的命令包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;jar&lt;/li&gt;
&lt;li&gt;kill&lt;/li&gt;
&lt;li&gt;activate&lt;/li&gt;
&lt;li&gt;deactivate&lt;/li&gt;
&lt;li&gt;rebalance&lt;/li&gt;
&lt;li&gt;repl&lt;/li&gt;
&lt;li&gt;classpath&lt;/li&gt;
&lt;li&gt;localconfvalue&lt;/li&gt;
&lt;li&gt;remoteconfvalue&lt;/li&gt;
&lt;li&gt;nimbus&lt;/li&gt;
&lt;li&gt;supervisor&lt;/li&gt;
&lt;li&gt;ui&lt;/li&gt;
&lt;li&gt;drpc&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;jar&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm jar topology-jar-path class ...&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;使用指定的参数运行 main 方法（也就是打包好的拓扑 jar 包中的 main 方法）。Storm 所需要的 jar 包和配置信息都在类路径（classpath）中。这个运行过程已经配置好了，这样 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/StormSubmitter.html"&gt;StormSubmitter&lt;/a&gt; 就可以在提交拓扑的时候将 &lt;code&gt;topology-jar-path&lt;/code&gt; 中的 jar 包上传到集群中。&lt;/p&gt;
&lt;h2&gt;kill&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm kill topology-name [-w wait-time-secs]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;杀死集群中正在运行的名为 &lt;code&gt;topology-name&lt;/code&gt; 的拓扑。执行该操作后，Storm 首先会注销拓扑中的 spout，使得拓扑中的消息超时，这样当前的所有消息就会结束执行。随后，Storm 会将所有的 worker 关闭，并清除他们的状态。你可以使用 &lt;code&gt;-w&lt;/code&gt; 参数来调整 Storm 在注销与关闭拓扑之间的间隔时间。&lt;/p&gt;
&lt;h2&gt;activate&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm activate topology-name&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;激活运行指定拓扑的所有 spout。&lt;/p&gt;
&lt;h2&gt;deactivate&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm deactivate topology-name&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;停止指定拓扑的所有 spout 的运行。&lt;/p&gt;
&lt;h2&gt;rebalance&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm rebalance topology-name [-w wait-time-secs]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;有些场景下需要对正在运行的拓扑的工作进程（worker）进行弹性扩展。例如，加入你有 10 个节点，每个节点上运行有 4 个 worker，现在由于各种原因你需要为集群添加 10 个新节点。这时你就会希望通过扩展正在运行的拓扑的 worker 来使得每个节点只运行两个 worker，降低集群的负载。实现这个目的的一种直接的办法是 kill 掉正在运行的拓扑，然后重新向集群提交。不过 Storm 提供了再平衡命令可以以一种更简单的方法实现目的。&lt;/p&gt;
&lt;p&gt;再平衡首先会在一个超时时间内（这个时间是可以通过 &lt;code&gt;-w&lt;/code&gt; 参数配置的）注销掉拓扑，然后在整个集群中重新分配 worker。接着拓扑就会自动回到之前的状态（也就是说之前处于注销状态的拓扑仍然会保持注销状态，而处于激活状态的拓扑则会返回激活状态）。&lt;/p&gt;
&lt;h2&gt;repl&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm repl&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;打开一个带有类路径上的 jar 包和配置信息的 Clojure 的交互式解释器（REPL）。该命令主要用于调试。&lt;/p&gt;
&lt;h2&gt;classpath&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm classpath&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;打印客户端执行命令时使用的类路径环境变量。&lt;/p&gt;
&lt;h2&gt;localconfvalue&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm localconfvalue conf-name&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;打印出本地 Storm 配置中 &lt;code&gt;conf-name&lt;/code&gt; 属性的值。这里的本地配置指的是 &lt;code&gt;~/.storm/storm.yaml&lt;/code&gt; 和 &lt;code&gt;defaults.yaml&lt;/code&gt; 两个配置文件综合后的配置信息。&lt;/p&gt;
&lt;h2&gt;remoteconfvalue&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm remoteconfvalue conf-name&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;打印出集群配置中 &lt;code&gt;conf-name&lt;/code&gt; 属性的值。这里的集群配置指的是 &lt;code&gt;$STORM-PATH/conf/storm.yaml&lt;/code&gt; 和 &lt;code&gt;defaults.yaml&lt;/code&gt; 两个配置文件综合后的配置信息。该命令必须在一个集群机器上执行。&lt;/p&gt;
&lt;h2&gt;nimbus&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm nimbus&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;启动 nimbus 后台进程。该命令应该在 &lt;a href="http://cr.yp.to/daemontools.html"&gt;daemontools&lt;/a&gt; 或者 &lt;a href="http://mmonit.com/monit/"&gt;monit&lt;/a&gt; 这样的工具监控下执行。详细信息请参考&lt;a href="http://mmonit.com/monit/"&gt;配置 Storm 集群&lt;/a&gt;一文。&lt;/p&gt;
&lt;h2&gt;supervisor&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm supervisor&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;启动 supervisor 后台进程。该命令应该在 &lt;a href="http://cr.yp.to/daemontools.html"&gt;daemontools&lt;/a&gt; 或者 &lt;a href="http://mmonit.com/monit/"&gt;monit&lt;/a&gt; 这样的工具监控下执行。详细信息请参考&lt;a href="http://mmonit.com/monit/"&gt;配置 Storm 集群&lt;/a&gt;一文。&lt;/p&gt;
&lt;h2&gt;ui&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm ui&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;启动 UI 后台进程。UI 提供了一个访问 Storm 集群的 Web 接口，其中包含有运行中的拓扑的详细信息。该命令应该在 &lt;a href="http://cr.yp.to/daemontools.html"&gt;daemontools&lt;/a&gt; 或者 &lt;a href="http://mmonit.com/monit/"&gt;monit&lt;/a&gt; 这样的工具监控下执行。详细信息请参考&lt;a href="http://mmonit.com/monit/"&gt;配置 Storm 集群&lt;/a&gt;一文。&lt;/p&gt;
&lt;h2&gt;drpc&lt;/h2&gt;
&lt;p&gt;语法：&lt;code&gt;storm drpc&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;启动 DRPC 后台进程。该命令应该在 &lt;a href="http://cr.yp.to/daemontools.html"&gt;daemontools&lt;/a&gt; 或者 &lt;a href="http://mmonit.com/monit/"&gt;monit&lt;/a&gt; 这样的工具监控下执行。详细信息请参考&lt;a href="http://storm.apache.org/documentation/Distributed-RPC.html"&gt;分布式 RPC&lt;/a&gt;一文。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Wed, 17 Jun 2015 20:57:17 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-17:pages/techs/storm-translations-command-line-client/</guid><category>Storm</category><category>Translation</category></item><item><title>KafkaSpout 引起的 log4j 的问题</title><link>http://weyo.me/pages/techs/kafka-problem-with-log4j/</link><description>&lt;p&gt;今天在测试 &lt;code&gt;KafkaSpout&lt;/code&gt; 的时候突然冒出了 log4j 的问题，先是两行醒目的红色警告：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SLF4J&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Detected&lt;/span&gt; &lt;span class="n"&gt;both&lt;/span&gt; &lt;span class="n"&gt;log4j&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;over&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;slf4j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;jar&lt;/span&gt; &lt;span class="n"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;slf4j&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;log4j12&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;jar&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;preempting&lt;/span&gt; &lt;span class="n"&gt;StackOverflowError&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; 
&lt;span class="n"&gt;SLF4J&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;See&lt;/span&gt; &lt;span class="n"&gt;also&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;://&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;slf4j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;codes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;html&lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="n"&gt;log4jDelegationLoop&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;more&lt;/span&gt; &lt;span class="n"&gt;details&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;跟着 topology 就挂掉了，只留下了一堆无奈的日志：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;5370 [Thread-14-newKafka] ERROR backtype.storm.util - Async loop died!&lt;/span&gt;
&lt;span class="x"&gt;java.lang.NoClassDefFoundError: Could not initialize class org.apache.log4j.Log4jLoggerFactory&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.log4j.Logger.getLogger(Logger.java:39) ~[log4j-over-slf4j-1.6.6.jar:1.6.6]&lt;/span&gt;
&lt;span class="x"&gt;    at kafka.utils.Logging&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;class&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;logger&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;Logging.scala&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;24&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; ~[kafka_2.10-0.8.2.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;    at kafka.consumer.SimpleConsumer.logger&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;lzycompute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;SimpleConsumer.scala&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; ~[kafka_2.10-0.8.2.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;    at kafka.consumer.SimpleConsumer.logger(SimpleConsumer.scala:30) ~[kafka_2.10-0.8.2.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;    at kafka.utils.Logging&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;class&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;Logging.scala&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;67&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; ~[kafka_2.10-0.8.2.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;    at kafka.consumer.SimpleConsumer.info(SimpleConsumer.scala:30) ~[kafka_2.10-0.8.2.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;    at kafka.consumer.SimpleConsumer.liftedTree1&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="x"&gt;1(SimpleConsumer.scala:74) ~[kafka_2.10-0.8.2.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;    at kafka.consumer.SimpleConsumer.kafka&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;consumer&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;SimpleConsumer&lt;/span&gt;&lt;span class="p"&gt;$$&lt;/span&gt;&lt;span class="nv"&gt;sendRequest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;SimpleConsumer.scala&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;68&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; ~[kafka_2.10-0.8.2.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;    at kafka.consumer.SimpleConsumer.getOffsetsBefore(SimpleConsumer.scala:127) ~[kafka_2.10-0.8.2.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;    at kafka.javaapi.consumer.SimpleConsumer.getOffsetsBefore(SimpleConsumer.scala:79) ~[kafka_2.10-0.8.2.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;    at storm.kafka.KafkaUtils.getOffset(KafkaUtils.java:77) ~[storm-kafka-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;    at storm.kafka.KafkaUtils.getOffset(KafkaUtils.java:67) ~[storm-kafka-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;    at storm.kafka.PartitionManager.&amp;lt;init&amp;gt;(PartitionManager.java:83) ~[storm-kafka-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;    at storm.kafka.ZkCoordinator.refresh(ZkCoordinator.java:98) ~[storm-kafka-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;    at storm.kafka.ZkCoordinator.getMyManagedPartitions(ZkCoordinator.java:69) ~[storm-kafka-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;    at storm.kafka.KafkaSpout.nextTuple(KafkaSpout.java:135) ~[storm-kafka-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.daemon.executor&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__3373&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__3388&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__3417&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;executor.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;565&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; ~[storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.util&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;async_loop&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;fn__464&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;util.clj&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;463&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; ~[storm-core-0.9.3.jar:0.9.3]&lt;/span&gt;
&lt;span class="x"&gt;    at clojure.lang.AFn.run(AFn.java:24) [clojure-1.5.1.jar:na]&lt;/span&gt;
&lt;span class="x"&gt;    at java.lang.Thread.run(Thread.java:744) [na:1.7.0_45]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;追根溯源，发现 &lt;code&gt;KafkaSpout&lt;/code&gt; 代码里（&lt;code&gt;storm.kafka.KafkaSpout&lt;/code&gt;）使用了 slf4j 的包，而 Kafka 系统本身（&lt;code&gt;kafka.consumer.SimpleConsumer&lt;/code&gt;）却使用了 apache 的包，这个结果着实有些尴尬。&lt;/p&gt;
&lt;p&gt;折腾了一会儿，最后还是根据 &lt;a href="http://stackoverflow.com/questions/20117720/detected-both-log4j-over-slf4j-jar-and-slf4j-log4j12-jar-on-the-class-path-pree"&gt;http://stackoverflow.com/questions/20117720/detected-both-log4j-over-slf4j-jar-and-slf4j-log4j12-jar-on-the-class-path-pree&lt;/a&gt; 这个问题的提示，在依赖定义中排除问题依赖包（也就是 Kafka 本身的依赖包）中对应的冲突的包&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.kafka&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;kafka_2.10&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;0.8.2.1&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;provided&lt;span class="nt"&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;exclusions&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.slf4j&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;slf4j-log4j12&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;log4j&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;log4j&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/exclusions&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;重新编译运行就 OK 了。&lt;/p&gt;
&lt;h2&gt;TIPS&lt;/h2&gt;
&lt;p&gt;结合这次经历和以前遇到的各种 log4j 问题（没办法，使用最广泛的包就是这么任性），总结了一下使用 log4j 的几点不算什么经验的心得。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;统一采用 slf4j 的包&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.slf4j.Logger&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.slf4j.LoggerFactory&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MyBolt&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;private&lt;/span&gt; &lt;span class="n"&gt;static&lt;/span&gt; &lt;span class="n"&gt;final&lt;/span&gt; &lt;span class="n"&gt;Logger&lt;/span&gt; &lt;span class="n"&gt;LOG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LoggerFactory&lt;/span&gt;
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getLogger&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MyBolt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在代码中不再使用 apache 的包，转而统一使用 slf4j 的包，可以避免大多数包冲突问题（只适用于 Storm 相关服务，这是因为 Storm 所依赖的 logback-classic-1.0.13.jar 是使用 slf4j 的）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Maven 的编译发布插件中最好都要排除冲突的包&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;plugins&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-compiler-plugin&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;3.1&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;source&amp;gt;&lt;/span&gt;1.7&lt;span class="nt"&gt;&amp;lt;/source&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;target&amp;gt;&lt;/span&gt;1.7&lt;span class="nt"&gt;&amp;lt;/target&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;excludes&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;exclude&amp;gt;&lt;/span&gt;log4j:log4j:jar:&lt;span class="nt"&gt;&amp;lt;/exclude&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/excludes&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-shade-plugin&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;executions&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;execution&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;phase&amp;gt;&lt;/span&gt;package&lt;span class="nt"&gt;&amp;lt;/phase&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;goals&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;shade&lt;span class="nt"&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;finalName&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;project&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;artifactId&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;-&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;project&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;-shade&lt;span class="nt"&gt;&amp;lt;/finalName&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;artifactSet&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;excludes&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;exclude&amp;gt;&lt;/span&gt;log4j:log4j:jar:&lt;span class="nt"&gt;&amp;lt;/exclude&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/excludes&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/artifactSet&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;transformers&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;transformer&lt;/span&gt;
                    &lt;span class="na"&gt;implementation=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&amp;quot;&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;transformer&lt;/span&gt;
                    &lt;span class="na"&gt;implementation=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;mainClass&amp;gt;&lt;/span&gt;storm.test.topology.SimulationTopology&lt;span class="nt"&gt;&amp;lt;/mainClass&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/transformer&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/transformers&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/plugins&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;&amp;lt;exclude&amp;gt;log4j:log4j:jar:&amp;lt;/exclude&amp;gt;&lt;/code&gt; 这样的操作可以避免拓扑发布到 Storm 集群之后可能出现的包冲突问题。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Tue, 16 Jun 2015 23:04:17 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-16:pages/techs/kafka-problem-with-log4j/</guid><category>Kafka</category><category>log4j</category></item><item><title>Storm 官方文档翻译(4) —— 消息的可靠性保障</title><link>http://weyo.me/pages/techs/storm-translations-guaranteeing-message-processing/</link><description>&lt;h1&gt;消息的可靠性保障&lt;/h1&gt;
&lt;p&gt;Storm 能够保证每一个由 Spout 发送的消息都能够得到完整地处理。本文详细解释了 Storm 如何实现这种保障机制，以及作为用户如何使用好 Storm 的可靠性机制。&lt;/p&gt;
&lt;h2&gt;消息的“完整性处理”是什么意思&lt;/h2&gt;
&lt;p&gt;一个从 spout 中发送出的 tuple 会产生上千个基于它创建的 tuples。例如，有这样一个 word-count 拓扑：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TopologyBuilder builder = new TopologyBuilder();
builder.setSpout(&amp;quot;sentences&amp;quot;, new KestrelSpout(&amp;quot;kestrel.backtype.com&amp;quot;,
                                               22133,
                                               &amp;quot;sentence_queue&amp;quot;,
                                               new StringScheme()));
builder.setBolt(&amp;quot;split&amp;quot;, new SplitSentence(), 10)
        .shuffleGrouping(&amp;quot;sentences&amp;quot;);
builder.setBolt(&amp;quot;count&amp;quot;, new WordCount(), 20)
        .fieldsGrouping(&amp;quot;split&amp;quot;, new Fields(&amp;quot;word&amp;quot;));
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个拓扑从一个 Kestrel 队列中读取句子，然后将句子分解成若干个单词，然后将它每个单词和该单词的数量发送出去。这种情况下，从 spout 中发出的 tuple 就会产生很多基于它创建的新 tuple：包括句子中单词的 tuple 和 每个单词的个数的 tuple。这些消息构成了这样一棵树：&lt;/p&gt;
&lt;p&gt;&lt;img alt="messages-tree" src="http://storm.apache.org/documentation/images/tuple_tree.png" /&gt;&lt;/p&gt;
&lt;p&gt;如果这棵 tuple 树发送完成，并且树中的每一条消息都得到了正确的处理，就表明发送 tuple 的 spout 已经得到了“完整性处理”。对应的，如果在指定的超时时间内 tuple 树中有消息没有完成处理就意味着这个 tuple 失败了。这个超时时间可以使用 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/Config.html#TOPOLOGY_MESSAGE_TIMEOUT_SECS"&gt;Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS&lt;/a&gt; 参数在构造拓扑时进行配置，如果不配置，则默认时间为 30 秒。&lt;/p&gt;
&lt;h2&gt;在消息得到完整性处理后或者处理失败后会发生什么&lt;/h2&gt;
&lt;p&gt;为了理解这个问题，让我们先了解一下 tuple 的生命周期。下面是定义 spout 的接口（可以在 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/spout/ISpout.html"&gt;Javadoc&lt;/a&gt; 中查看更多细节信息）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public interface ISpout extends Serializable {
    void open(Map conf, TopologyContext context, SpoutOutputCollector collector);
    void close();
    void nextTuple();
    void ack(Object msgId);
    void fail(Object msgId);
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;首先，通过调用 &lt;code&gt;Spout&lt;/code&gt; 的 &lt;code&gt;nextTuple&lt;/code&gt; 方法，Storm 向 &lt;code&gt;Spout&lt;/code&gt; 请求一个 tuple。&lt;code&gt;Spout&lt;/code&gt; 会使用 &lt;code&gt;open&lt;/code&gt; 方法中提供的 &lt;code&gt;SpoutOutputCollector&lt;/code&gt; 向它的一个输出数据流中发送一个 tuple。在发送 tuple 的时候，&lt;code&gt;Spout&lt;/code&gt; 会提供一个 “消息 id”，这个 id 会在后续过程中用于识别 tuple。例如，上面的 &lt;code&gt;KestrelSpout&lt;/code&gt; 就是从一个 kestrel 队列中读取一条消息，然后再发送一条带有“消息 id”的消息，这个 id 是由 Kestrel 提供的。使用 &lt;code&gt;SpoutOutputCollector&lt;/code&gt; 发送消息一般是这样的形式：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;_collector.emit(new Values(&amp;quot;field1&amp;quot;, &amp;quot;field2&amp;quot;, 3) , msgId);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;随后，tuple 会被发送到对应的 bolt 中去，在这个过程中，Storm 会很小心地跟踪创建的消息树。如果 Storm 检测到某个 tuple 被完整处理， Storm 会根据 &lt;code&gt;Spout&lt;/code&gt; 提供的“消息 id”调用最初发送 tuple 的 &lt;code&gt;Spout&lt;/code&gt; 任务的 &lt;code&gt;ack&lt;/code&gt; 方法。对应的，Storm 在检测到 tuple 超时之后就会调用 &lt;code&gt;fail&lt;/code&gt; 方法。注意，对于一个特定的 tuple，响应（ack）和失败处理（fail）都只会由最初创建这个 tuple 的任务执行。也就是说，及时 &lt;code&gt;Spout&lt;/code&gt; 在集群中有很多个任务，某个特定的 tuple 也只会由创建它的那个任务——而不是其他的任务——来处理成功或失败的结果。&lt;/p&gt;
&lt;p&gt;我们再以 &lt;code&gt;KestrlSpout&lt;/code&gt; 为例来看看在消息的可靠性处理中 &lt;code&gt;Spout&lt;/code&gt; 做了什么。在 &lt;code&gt;KestrlSpout&lt;/code&gt; 从 Kestrel 队列中取出一条消息时，可以看作它“打开”了这条消息。也就是说，这条消息实际上并没有从队列中真正地取出来，而是保持着一个“挂起”状态，等待消息处理完成的信号。在挂起状态的消息不回被发送到其他的消费者中。另外，如果消费者（客户端）断开了连接，所有处于挂起状态的消息都会重新放回到队列中。在消息“打开”的时候 Kestrel 会给客户端同时提供消息体数据和一个唯一的 id。&lt;code&gt;KestrelSpout&lt;/code&gt; 在使用 &lt;code&gt;SpoutOutputCollector&lt;/code&gt; 发送 tuple 的时候就会把这个唯一的 id 当作“消息 id”。一段时间之后，在 &lt;code&gt;KestrelSpout&lt;/code&gt; 的 &lt;code&gt;ack&lt;/code&gt; 或者 &lt;code&gt;fail&lt;/code&gt; 方法被调用的时候，&lt;code&gt;KestrelSpout&lt;/code&gt; 就会通过这个消息 id 向 Kestrel 请求将消息从队列中移除（对应 &lt;code&gt;ack&lt;/code&gt; 的情况）或者将消息重新放回队列（对应 &lt;code&gt;fail&lt;/code&gt; 的情况）。&lt;/p&gt;
&lt;h2&gt;Storm 的可靠性 API 是什么&lt;/h2&gt;
&lt;p&gt;使用 Storm 的可靠性机制的时候你需要注意两件事：首先，在 tuple 树中创建新节点连接时务必通知 Storm；其次，在每个 tuple 处理结束的时候也必须向 Storm 发出通知。通过这两个操作，Storm 就能够检测到 tuple 树会在何时完成处理，并适时地调用 ack 或者 fail 方法。Storm 的 API 提供了一种非常精确的方式来实现着两个操作。&lt;/p&gt;
&lt;p&gt;Storm 中指定 tuple 树中的一个连接称为“锚定”（anchoring）。锚定是在发送新 tuple 的同时发生的。让我们以下面的 Bolt 为例说明这一点，这个 Bolt 将一个包含句子的 tuple 分割成若干个单词 tuple：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class SplitSentence extends BaseRichBolt {
        OutputCollector _collector;

        public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
            _collector = collector;
        }

        public void execute(Tuple tuple) {
            String sentence = tuple.getString(0);
            for(String word: sentence.split(&amp;quot; &amp;quot;)) {
                _collector.emit(tuple, new Values(word));
            }
            _collector.ack(tuple);
        }

        public void declareOutputFields(OutputFieldsDeclarer declarer) {
            declarer.declare(new Fields(&amp;quot;word&amp;quot;));
        }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过将输入 tuple 指定为 &lt;code&gt;emit&lt;/code&gt; 方法的第一个参数，每个单词 tuple 都被“锚定”了。这样，如果单词 tuple 在后续处理过程中失败了，作为这棵 tuple 树的根节点的原始 Spout tuple 就会被重新处理。相对应的，如果这样发送 tuple：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;_collector.emit(new Values(word));
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;就称为“非锚定”。在这种情况下，下游的 tuple 处理失败不会触发原始 tuple 的任何处理操作。有时候发送这种“非锚定” tuple 也是必要的，这取决于你的拓扑的容错性要求。&lt;/p&gt;
&lt;p&gt;一个输出 tuple 可以被锚定到多个输入 tuple 上，这在流式连接或者聚合操作时很有用。显然，一个多锚定的 tuple 失败会导致 Spout 中多个 tuple 的重新处理。多锚定操作是通过指定一个 tuple 列表而不是单一的 tuple 来实现的，如下面的例子所示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;List&amp;lt;Tuple&amp;gt; anchors = new ArrayList&amp;lt;Tuple&amp;gt;();
anchors.add(tuple1);
anchors.add(tuple2);
_collector.emit(anchors, new Values(1, 2, 3));
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;多锚定操作会把输出 tuple 添加到多个 tuple 树中。注意，多锚定也可能会打破树的结构从而创建一个 tuple 的有向无环图（DAG），如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img alt="DAGs" src="http://storm.apache.org/documentation/images/tuple-dag.png" /&gt;&lt;/p&gt;
&lt;p&gt;Storm 的程序实现既支持对树的处理，同样也支持对 DAG 的处理（由于早期的 Storm 版本仅仅对树有效，所以“tuple 树”的这个糟糕的概念就一直沿袭下来了）。&lt;/p&gt;
&lt;p&gt;锚定其实可以看作是将 tuple 树具象化的过程 —— 在结束对一棵 tuple 树中一个单独 tuple 的处理的时候，后续以及最终的 tuple 都会在 Storm 可靠性 API 的作用下得到标定。这是通过 &lt;code&gt;OutputCollector&lt;/code&gt; 的 &lt;code&gt;ack&lt;/code&gt; 和 &lt;code&gt;fail&lt;/code&gt; 方法实现的。如果你再回过头看一下 &lt;code&gt;SplitSentence&lt;/code&gt; 的例子，你就会发现输入 tuple 是在所有的单词 tuple 发送出去之后被 ack 的。&lt;/p&gt;
&lt;p&gt;你可以使用 &lt;code&gt;OutputCollector&lt;/code&gt; 的 &lt;code&gt;fail&lt;/code&gt; 方法来使得位于 tuple 树根节点的 Spout tuple 立即失败。例如，你的应用可以在建立数据库连接的时候抓取异常，并且在异常出现的时候立即让输入 tuple 失败。通过这种立即失败的方式，原始 Spout tuple 就会比等待 tuple 超时的方式响应更快。&lt;/p&gt;
&lt;p&gt;每个待处理的 tuple 都必须显式地应答（ack）或者失效（fail）。因为 Storm 是使用内存来跟踪每个 tuple 的，所以，如果你不对每个 tuple 进行应答或者失效，那么负责跟踪的任务很快就会发生内存溢出。&lt;/p&gt;
&lt;p&gt;Bolt 处理 tuple 的一种通用模式是在 &lt;code&gt;execute&lt;/code&gt; 方法中读取输入 tuple、发送出基于输入 tuple 的新 tuple，然后在方法末尾对 tuple 进行应答。大部分 Bolt 都会使用这样的过程。这些 Bolt 大多属于过滤器或者简单的处理函数一类。Storm 有一个可以简化这种操作的简便接口，称为 &lt;code&gt;BasicBolt&lt;/code&gt;。例如，如果使用 &lt;code&gt;BasicBolt&lt;/code&gt;，&lt;code&gt;SplitSentence&lt;/code&gt; 的例子可以这样写：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;public class SplitSentence extends BaseBasicBolt {
        public void execute(Tuple tuple, BasicOutputCollector collector) {
            String sentence = tuple.getString(0);
            for(String word: sentence.split(&amp;quot; &amp;quot;)) {
                collector.emit(new Values(word));
            }
        }

        public void declareOutputFields(OutputFieldsDeclarer declarer) {
            declarer.declare(new Fields(&amp;quot;word&amp;quot;));
        }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个实现方式比之前的方式要简单许多，而且在语义上有着完全一致的效果。发送到 &lt;code&gt;BasicOutputCollector&lt;/code&gt; 的 tuple 会被自动锚定到输入 tuple 上，而且输入 tuple 会在 &lt;code&gt;execute&lt;/code&gt; 方法结束的时候自动应答。&lt;/p&gt;
&lt;p&gt;相对应的，执行聚合或者联结操作的 Bolt 可能需要延迟应答 tuple，因为它需要等待一批 tuple 来完成某种结果计算。聚合和联结操作一般也会需要对他们的输出 tuple 进行多锚定。这个过程已经超出了 &lt;code&gt;IBasicBolt&lt;/code&gt; 的应用范围。&lt;/p&gt;
&lt;h2&gt;在 tuple 可以被重新处理的前提下，如何让我的应用可以得到正确的运行？&lt;/h2&gt;
&lt;p&gt;按照软件设计的一般思路，这个问题的答案是“取决于实际情况”。Storm 0.7.0 版本引入了“事务拓扑”的特性，它能够保证大多数计算过程都能够满足恰好一次（exactly-once）的消息语义的容错性要求。想要了解“事务拓扑”的更多内容可以参考&lt;a href="http://storm.apache.org/documentation/Transactional-topologies.html"&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;Storm 是以怎样一种高效的方式实现可靠性的？&lt;/h2&gt;
&lt;p&gt;Storm 的拓扑有一些特殊的称为“acker”的任务，这些任务负责跟踪每个 Spout 发出的 tuple 的 DAG。当一个 acker 发现一个 DAG 结束了，它就会给创建 spout tuple 的 Spout 任务发送一条消息，让这个任务来应答这个消息。你可以使用 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/Config.html#TOPOLOGY_ACKERS"&gt;Config.TOPOLOGY_ACKERS&lt;/a&gt; 来配置拓扑的 acker 数量。Storm 默认会将 acker 的数量设置为一，不过如果你有大量消息的处理需求，你可能需要增加这个数量。&lt;/p&gt;
&lt;p&gt;理解 Storm 的可靠性实现的最好方式还是通过了解 tuple 和 tuple DAG 的生命周期。当一个 tuple 在拓扑中被创建出来的时候 —— 不管是在 Spout 中还是在 Bolt 中创建的 —— 这个 tuple 都会被配置一个随机的 64 位 id。acker 就是使用这些 id 来跟踪每个 spout tuple 的 tuple DAG 的。&lt;/p&gt;
&lt;p&gt;Spout tuple 的 tuple 树中的每个 tuple 都知道 spout tuple 的 id。当你在 bolt 中发送一个新 tuple 的时候，输入 tuple 中的所有 spout tuple 的 id 都会被复制到新的 tuple 中。在 tuple 被 ack 的时候，它会通过回掉函数向合适的 acker 发送一条消息，这条消息显示了 tuple 树中发生的变化。也就是说，它会告诉 acker 这样一条消息：“在这个 tuple 树中，我的处理已经结束了，接下来这个就是被我标记的新 tuple”。&lt;/p&gt;
&lt;p&gt;以下图为例，如果 D tuple 和 E tuple 是由 C tuple 创建的，那么在 C 应答的时候 tuple 树就会发生变化：&lt;/p&gt;
&lt;p&gt;&lt;img alt="ack tree" src="http://storm.apache.org/documentation/images/ack_tree.png" /&gt;&lt;/p&gt;
&lt;p&gt;由于在 D 和 E 添加到 tuple 树中的时候 C 已经从树中移除了，所以这个树并不会被过早地结束。&lt;/p&gt;
&lt;p&gt;关于 Storm 如何跟踪 tuple 树还有更多的细节。正如上面所提到的，你可以随意设置拓扑中 acker 的数量。这就会引起下面的问题：当 tuple 在拓扑中被 ack 的时候，它是怎么知道向那个 acker 任务发送信息的？&lt;/p&gt;
&lt;p&gt;对于这个问题，Storm 实际上是使用哈希算法来将 spout tuple 匹配到 acker 任务上的。由于每个 tuple 都会包含原始的 spout tuple id，所以他们会知道需要与哪个 acker 任务通信。&lt;/p&gt;
&lt;p&gt;关于 Storm 的另一个问题是 acker 是如何知道它所跟踪的 spout tuple 是由哪个 Spout 任务处理的。实际上，在 Spout 任务发送新 tuple 的时候，它也会给对应的 acker 发送一条消息，告诉 acker 这个 spout tuple 是与它的任务 id 相关联的。随后，在 acker 观察到 tuple 树结束处理的时候，它就会知道向哪个 Spout 任务发送结束消息。&lt;/p&gt;
&lt;p&gt;Acker 实际上并不会直接跟踪 tuple 树。对于一棵包含数万个 tuple 节点的树，如果直接跟踪其中的每个 tuple，显然会很快把这个 acker 的内存撑爆。所以，这里 acker 使用一个特殊的策略来实现跟踪的功能，使用这个方法对于每个 spout tuple 只需要占用固定的内存空间（大约 20 字节）。这个跟踪算法是 Storm 运行的关键，也是 Storm 的一个突破性技术。&lt;/p&gt;
&lt;p&gt;在 acker 任务中储存了一个表，用于将 spout tuple 的 id 和一对值相映射。其中第一个值是创建这个 tuple 的任务 id，这个 id 主要用于在后续操作中发送结束消息。第二个值是一个 64 比特的数字，称为“应答值”（ack val）。这个应答值是整个 tuple 树的一个完整的状态表述，而且它与树的大小无关。因为这个值仅仅是这棵树中所有被创建的或者被应答的 tuple 的 tuple id 进行异或运算的结果值。&lt;/p&gt;
&lt;p&gt;当一个 acker 任务观察到“应答值”变为 0 的时候，它就知道这个 tuple 树已经完成处理了。因为 tuple id 实际上是随机生成的 64 比特数值，所以“应答值”碰巧为 0 是一种极小概率的事件。理论计算得以得出，在每秒应答一万次的情况下，需要 5000 万年才会发生一次错误。而且即使是这样，也仅仅会在 tuple 碰巧在拓扑中失败的时候才会发生数据丢失的情况。&lt;/p&gt;
&lt;p&gt;假设你现在已经理解了这个可靠性算法，让我们再分析一下所有失败的情形，看看这些情形下 Storm 是如何避免数据缺失的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;由于任务（线程）挂掉导致 tuple 没有被应答（ack）的情况&lt;/strong&gt;：这时位于 tuple 树根节点的 spout tuple 会在任务超时后得到重新处理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Acker 任务挂掉的情形&lt;/strong&gt;：这种情况下 acker 所跟踪的所有 spout tuple 都会由于超时被重新处理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Spout 任务挂掉的情形&lt;/strong&gt;：这种情况下 Spout 任务的来源就会负责重新处理消息。例如，对于像 Kestrel 和 RabbitMQ 这样的消息队列就会在客户端断开连接时将所有的挂起状态的消息放回队列（关于挂起状态的概念可以参考&lt;a href="https://github.com/weyo/Storm-Documents/blob/master/Manual/zh/Fault-Tolerance.md"&gt;Storm 的容错性&lt;/a&gt;——译者注）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上所述，Storm 的可靠性机制完全具备分布的、可伸缩的、容错的特征。&lt;/p&gt;
&lt;h2&gt;调整可靠性&lt;/h2&gt;
&lt;p&gt;由于 acker 任务是轻量级的，在拓扑中你并不需要很多 acker 任务。你可以通过 Storm UI 监控他们的性能（acker 任务的 id 为“__acker”）。如果发现观察结果存在问题，你可能就需要增加更多的 acker 任务。&lt;/p&gt;
&lt;p&gt;如果你不关注消息的可靠性 —— 也就是说你不关心在失败情形下发生的 tuple 丢失 —— 那么你就可以通过不跟踪 tuple 树的处理来提升拓扑的性能。由于 tuple 树中的每个 tuple 都会带有一个应答消息，不追踪 tuple 树会使得传输的消息的数量减半。同时，下游数据流中的 id 也会变少，这样可以降低网络带宽的消耗。&lt;/p&gt;
&lt;p&gt;有三种方法可以移除 Storm 的可靠性机制。第一种方法是将 Config.TOPOLOGY_ACKERS 设置为0，在这种情况下，Storm 会在 Spout 发送 tuple 之后立即调用 &lt;code&gt;ack&lt;/code&gt; 方法，tuple 树叶就不会被跟踪了。&lt;/p&gt;
&lt;p&gt;第二种方法是基于消息本身移除可靠性。你可以通过在 &lt;code&gt;SpoutOutputCollector.emit&lt;/code&gt; 方法中省略消息 id 来关闭 spout tuple 的跟踪功能。&lt;/p&gt;
&lt;p&gt;最后，如果你不关心拓扑中的下游 tuple 是否会失败，你可以在发送 tuple 的时候选择发送“非锚定”的（unanchored）tuple（（注意，在使用这种方法时，如果上游有 spout 或 bolt 仍然保持可靠性机制，那么需要在 execute 方法之初调用 OutputCollector.ack 来立即响应上游的消息，否则上游组件会误认为消息没有发送成功导致所有的消息会被反复发送——译者注））。由于这些 tuple 不会被标记到任何一个 spout tuple 中，显然在他们处理失败的时候不会引起任何 spout tuple 的重新处理。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Tue, 16 Jun 2015 22:31:09 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-16:pages/techs/storm-translations-guaranteeing-message-processing/</guid><category>Storm</category><category>Translation</category></item><item><title>Storm 官方文档翻译(3) —— 容错性</title><link>http://weyo.me/pages/techs/storm-translations-fault-tolerance/</link><description>&lt;h1&gt;容错性&lt;/h1&gt;
&lt;p&gt;本文通过问答的形式解释了 Storm 的容错性原理。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;工作进程（worker）死亡时会发生什么？&lt;/h2&gt;
&lt;p&gt;工作进程死亡的时候，supervisor 会重新启动这个进程。如果在启动过程中仍然一直失败，并且无法向 Nimbus 发送心跳，Nimbus 就会将这个 worker 重新分配到其他机器上去。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;节点故障时会发生什么？&lt;/h2&gt;
&lt;p&gt;一个节点（集群中的工作节点，非 Nimbus 所在服务器）故障时，该节点上所有的任务（tasks）都会超时，然后 Nimbus 在检测到超时后悔将所有的这些任务重新分配到其他机器上去。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Nimbus 或者 Supervisor 的后台进程挂掉时会发生什么&lt;/h2&gt;
&lt;p&gt;Nimbus 和 Supervisor 的后台进程本身是设计为快速失败（无论何时发生了异常情况之后都会启动自毁操作）和无状态（所有的状态由 ZooKeeper 负责管理）的。正如&lt;a href="http://storm.apache.org/documentation/Setting-up-a-Storm-cluster.html"&gt;配置 Storm 集群&lt;/a&gt;这篇文章中所述，Nimbus 和 Supervisor 的后台进程实际上是在后台监控工具的监控之下运行的。所以，如果 Nimbus 或者 Supervisor 进程挂掉，他们就会静默地自动重启。&lt;/p&gt;
&lt;p&gt;值得一提的是，Nimbus 和 Supervisor 的故障不会影响任何工作进程。这一点与 Hadoop 形成了鲜明对比，在 Hadoop 中 JobTracker 的故障会导致所有正在运行的 job 运行失败（Hadoop 2.x 中引入的 Yarn 架构已经提升了 Hadoop 系统的稳定性，目前的架构并不会如这里所说的那么不堪——译者注）。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Nimbus 是系统的单故障点&lt;sup&gt;1&lt;/sup&gt;吗？&lt;/h2&gt;
&lt;p&gt;如果你的 Nimbus 节点出现故障无法访问，集群中的 worker 仍然会继续保持运行。另外，此时 Supervisor 也仍然会正常工作，在 worker 挂掉时自动重启挂掉的进程。但是，由于缺少 Nimbus 的协调，worker 就不会在必要的时候重新分配到不同的机器中（看上去好像你丢失了一个 worker）。&lt;/p&gt;
&lt;p&gt;所以这个问题的答案是，Nimbus 确实稍微有一点像 SPOF（单故障点，Single Point of Failure）。不过在实际应用中，Nimbus 的故障从来就不是什么问题。未来的开发计划中还会考虑让 Nimbus 具备更好的可用性。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Storm 是如何保障消息的完全处理的？&lt;/h2&gt;
&lt;p&gt;对于节点故障或者消息丢失的情况，Storm 提供了一套完善的机制保障所有的消息都能够得到正确处理。&lt;a href="http://storm.apache.org/documentation/Guaranteeing-message-processing.html"&gt;消息的可靠性保障&lt;/a&gt;一文中解释了这方面更多的技术细节。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;单故障点是指在一个系统中的某个在失效或停止运转后会导致整个系统不能工作的部件，具体概念可以参考&lt;a href="https://en.wikipedia.org/wiki/Single_point_of_failure"&gt;维基百科&lt;/a&gt;。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Mon, 15 Jun 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-15:pages/techs/storm-translations-fault-tolerance/</guid><category>Storm</category><category>Translation</category></item><item><title>Storm 官方文档翻译(2) —— 配置</title><link>http://weyo.me/pages/techs/storm-translations-configuration/</link><description>&lt;h1&gt;配置&lt;/h1&gt;
&lt;p&gt;Storm 有大量配置项用于调整 nimbus、supervisors 和拓扑的行为。有些配置项是系统级的配置项，在拓扑中不能修改，另外一些配置项则是可以在拓扑中修改的。&lt;/p&gt;
&lt;p&gt;每一个配置项都在 Storm 代码库的 &lt;a href="https://github.com/apache/storm/blob/master/conf/defaults.yaml"&gt;defaults.yaml&lt;/a&gt; 中有一个默认值。可以通过在 Nimbus 和 Supervisors 的环境变量中定义一个 storm.yaml 来覆盖默认值。最后，在使用 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/StormSubmitter.html"&gt;StormSubmitter&lt;/a&gt; 提交拓扑时也可以定义基于具体拓扑的配置项。但是，基于拓扑的配置项仅仅能够覆盖那些以 “TOPOLOGY” 作为前缀的配置项。&lt;/p&gt;
&lt;p&gt;Storm 0.7.0 以上版本支持覆写每个 Bolt/Spout 的配置信息。不过，使用这种方式只能修改以下几个配置项：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;"topology.debug"&lt;/li&gt;
&lt;li&gt;"topology.max.spout.pending"&lt;/li&gt;
&lt;li&gt;"topology.max.task.parallelism"&lt;/li&gt;
&lt;li&gt;"topology.kryo.register"：由于序列化对拓扑中的所有组件都是可见的，这一项与其他几项稍微有一些不同，详细信息可以参考 &lt;a href="http://storm.apache.org/documentation/Serialization.html"&gt;Serialization&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Storm 的 Java API 支持两种自定义组件配置信息的方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;内置型：在需要配置的 Spout/Bolt 中覆写 &lt;code&gt;getComponentConfiguration&lt;/code&gt; 方法，使其返回特定组件的配置表；&lt;/li&gt;
&lt;li&gt;外置型：&lt;code&gt;TopologyBuilder&lt;/code&gt; 中的 &lt;code&gt;setSpout&lt;/code&gt; 与 &lt;code&gt;setBolt&lt;/code&gt; 方法会返回一个带有 &lt;code&gt;addConfiguration&lt;/code&gt; 方法的 &lt;code&gt;ComponentConfigurationDeclarer&lt;/code&gt; 对象，通过 &lt;code&gt;addConfiguration&lt;/code&gt; 方法就可以覆写对应组件的配置项（同时也可以添加自定义的配置信息——译者注）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;配置信息的优先级依次为：defaults.yaml &amp;lt; storm.yaml &amp;lt; 拓扑配置 &amp;lt; 内置型组件信息配置 &amp;lt; 外置型组件信息配置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相关资料&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/Config.html"&gt;Config&lt;/a&gt;：此类包含所有可配置项的列表，对于创建拓扑配置信息很有帮助&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/storm/blob/master/conf/defaults.yaml"&gt;defaults.yaml&lt;/a&gt;：所有配置项的默认值&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/documentation/Setting-up-a-Storm-cluster.html"&gt;配置 Storm 集群&lt;/a&gt;：说明了如何创建、配置一个 Storm 集群&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/documentation/Running-topologies-on-a-production-cluster.html"&gt;在生产环境中运行拓扑&lt;/a&gt;：列出了在集群中运行拓扑的一些有用的配置项&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/documentation/Local-mode.html"&gt;本地模式&lt;/a&gt;：列出了使用本地模式时比较有用的配置项&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sun, 14 Jun 2015 19:15:55 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-14:pages/techs/storm-translations-configuration/</guid><category>Storm</category><category>Translation</category></item><item><title>Storm 官方文档翻译(1) —— 基础概念</title><link>http://weyo.me/pages/techs/storm-translations-concepts/</link><description>&lt;h1&gt;基础概念&lt;/h1&gt;
&lt;p&gt;Storm 系统中包含以下几个基本概念：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;拓扑（Topologies）&lt;/li&gt;
&lt;li&gt;流（Streams）&lt;/li&gt;
&lt;li&gt;数据源（Spouts）&lt;/li&gt;
&lt;li&gt;数据流处理组件（Bolts）&lt;/li&gt;
&lt;li&gt;数据流分组（Stream groupings）&lt;/li&gt;
&lt;li&gt;可靠性（Reliability）&lt;/li&gt;
&lt;li&gt;任务（Tasks）&lt;/li&gt;
&lt;li&gt;工作进程（Workers）&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;由于 Storm 的几个基础概念无论是直译还是意译均不够简洁明了，而且还会让习惯了 Storm 编程模型的用户感到困惑，因此后文在提及这些概念时大多还会以英文原文出现，希望大家能够谅解。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h1&gt;拓扑（Topologies）&lt;/h1&gt;
&lt;p&gt;Storm 的拓扑是对实时计算应用逻辑的封装，它的作用与 MapReduce 的任务（Job）很相似，区别在于 MapReduce 的一个 Job 在得到结果之后总会结束，而拓扑会一直在集群中运行，直到你手动去终止它。拓扑还可以理解成由一系列通过数据流（Stream Grouping）相互关联的 Spout 和 Bolt 组成的的拓扑结构。Spout 和 Bolt 称为拓扑的组件（Component）。我们会在后文中给出这些概念的解释。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相关资料&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/TopologyBuilder.html"&gt;TopologyBuilder&lt;/a&gt;：在 Java 中使用此类构造拓扑&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/documentation/Running-topologies-on-a-production-cluster.html"&gt;在生产环境中运行拓扑&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/documentation/Local-mode.html"&gt;本地模式&lt;/a&gt;：通过本文学习如何在本地模式中开发、测试拓扑&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;数据流（Streams）&lt;/h1&gt;
&lt;p&gt;数据流（Streams）是 Storm 中最核心的抽象概念。一个数据流指的是在分布式环境中并行创建、处理的一组元组（tuple）的无界序列。数据流可以由一种能够表述数据流中元组的域（fields）的模式来定义。在默认情况下，元组（tuple）包含有整型（Integer）数字、长整型（Long）数字、短整型（Short）数字、字节（Byte）、双精度浮点数（Double）、单精度浮点数（Float）、布尔值以及字节数组等基本类型对象。当然，你也可以通过定义可序列化的对象来实现自定义的元组类型。&lt;/p&gt;
&lt;p&gt;在声明数据流的时候需要给数据流定义一个有效的 id。不过，由于在实际应用中使用最多的还是单一数据流的 Spout 与 Bolt，这种场景下不需要使用 id 来区分数据流，因此可以直接使用 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/OutputFieldsDeclarer.html"&gt;OutputFieldsDeclarer&lt;/a&gt;来定义“无 id”的数据流。实际上，系统默认会给这种数据流定义一个名为“default”的 id。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相关资料&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;元组（Tuple）：数据流由多个元组构成&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/OutputFieldsDeclarer.html"&gt;OutputFieldsDeclarer&lt;/a&gt;：用于声明数据流和数据流对应的模式&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/documentation/Serialization.html"&gt;序列化（Serialization）&lt;/a&gt;：关于 Storm 元组的动态类型以及声明自定义序列化模型的相关内容&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/serialization/ISerialization.html"&gt;ISerialization&lt;/a&gt;：自定义的序列化模型必须实现该接口&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/Config.html#TOPOLOGY_SERIALIZATIONS"&gt;CONFIG.TOPOLOGY_SERIALIZATIONS&lt;/a&gt;：自定义的序列化模型可以通过这个配置项实现注册&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;数据源（Spouts）&lt;/h1&gt;
&lt;p&gt;数据源（Spout）是拓扑中数据流的来源。一般 Spout 会从一个外部的数据源读取元组然后将他们发送到拓扑中。根据需求的不同，Spout 既可以定义为&lt;strong&gt;可靠的&lt;/strong&gt;数据源，也可以定义为&lt;strong&gt;不可靠的&lt;/strong&gt;数据源。一个可靠的 Spout 能够在它发送的元组处理失败时重新发送该元组，以确保所有的元组都能得到正确的处理；相对应的，不可靠的 Spout 就不会在元组发送之后对元组进行任何其他的处理。&lt;/p&gt;
&lt;p&gt;一个 Spout 可以发送多个数据流。为了实现这个功能，可以先通过 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/OutputFieldsDeclarer.html"&gt;OutputFieldsDeclarer&lt;/a&gt; 的 &lt;code&gt;declareStream&lt;/code&gt; 方法来声明定义不同的数据流，然后在发送数据时在 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/spout/SpoutOutputCollector.html"&gt;SpoutOutputCollector&lt;/a&gt; 的 &lt;code&gt;emit&lt;/code&gt; 方法中将数据流 id 作为参数来实现数据发送的功能。&lt;/p&gt;
&lt;p&gt;Spout 中的关键方法是 &lt;code&gt;nextTuple&lt;/code&gt;。顾名思义，&lt;code&gt;nextTuple&lt;/code&gt; 要么会向拓扑中发送一个新的元组，要么会在没有可发送的元组时直接返回。需要特别注意的是，由于 Storm 是在同一个线程中调用所有的 Spout 方法，&lt;code&gt;nextTuple&lt;/code&gt; 不能被 Spout 的任何其他功能方法所阻塞，否则会直接导致数据流的中断（关于这一点，阿里的 JStorm 修改了 Spout 的模型，使用不同的线程来处理消息的发送，这种做法有利有弊，好处在于可以更加灵活地实现 Spout，坏处在于系统的调度模型更加复杂，如何取舍还是要看具体的需求场景吧——译者注）。&lt;/p&gt;
&lt;p&gt;Spout 中另外两个关键方法是 &lt;code&gt;ack&lt;/code&gt; 和 &lt;code&gt;fail&lt;/code&gt;，他们分别用于在 Storm 检测到一个发送过的元组已经被成功处理或处理失败后的进一步处理。注意，&lt;code&gt;ack&lt;/code&gt; 和 &lt;code&gt;fail&lt;/code&gt; 方法仅仅对上述“可靠的” Spout 有效。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相关资料&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/IRichSpout.html"&gt;IRichSpout&lt;/a&gt;：这是实现 Spout 的接口&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/documentation/Guaranteeing-message-processing.html"&gt;消息的可靠性处理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;数据流处理组件（Bolts）&lt;/h1&gt;
&lt;p&gt;拓扑中所有的数据处理均是由 Bolt 完成的。通过数据过滤（filtering）、函数处理（functions）、聚合（aggregations）、联结（joins）、数据库交互等功能，Bolt 几乎能够完成任何一种数据处理需求。&lt;/p&gt;
&lt;p&gt;一个 Bolt 可以实现简单的数据流转换，而更复杂的数据流变换通常需要使用多个 Bolt 并通过多个步骤完成。例如，将一个微博数据流转换成一个趋势图像的数据流至少包含两个步骤：其中一个 Bolt 用于对每个图片的微博转发进行滚动计数，另一个或多个 Bolt 将数据流输出为“转发最多的图片”结果（相对于使用2个Bolt，如果使用3个 Bolt 你可以让这种转换具有更好的可扩展性）。&lt;/p&gt;
&lt;p&gt;与 Spout 相同，Bolt 也可以输出多个数据流。为了实现这个功能，可以先通过 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/OutputFieldsDeclarer.html"&gt;OutputFieldsDeclarer&lt;/a&gt; 的 &lt;code&gt;declareStream&lt;/code&gt; 方法来声明定义不同的数据流，然后在发送数据时在 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/OutputCollector.html"&gt;OutputCollector&lt;/a&gt; 的 &lt;code&gt;emit&lt;/code&gt; 方法中将数据流 id 作为参数来实现数据发送的功能。&lt;/p&gt;
&lt;p&gt;在定义 Bolt 的输入数据流时，你需要从其他的 Storm 组件中订阅指定的数据流。如果你需要从其他所有的组件中订阅数据流，你就必须要在定义 Bolt 时分别注册每一个组件。对于声明为默认 id（即上文中提到的“default”——译者注）的数据流，&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/InputDeclarer.html"&gt;InputDeclarer&lt;/a&gt;支持订阅此类数据流的语法糖。也就是说，如果需要订阅来自组件“1”的数据流，&lt;code&gt;declarer.shuffleGrouping("1")&lt;/code&gt; 与 &lt;code&gt;declarer.shuffleGrouping("1", DEFAULT_STREAM_ID)&lt;/code&gt; 两种声明方式是等价的。&lt;/p&gt;
&lt;p&gt;Bolt 的关键方法是 &lt;code&gt;execute&lt;/code&gt; 方法。&lt;code&gt;execute&lt;/code&gt; 方法负责接收一个元组作为输入，并且使用 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/OutputCollector.html"&gt;OutputCollector&lt;/a&gt; 对象发送新的元组。如果有消息可靠性保障的需求，Bolt 必须为它所处理的每个元组调用 &lt;code&gt;OutputCollector&lt;/code&gt; 的 &lt;code&gt;ack&lt;/code&gt; 方法，以便 Storm 能够了解元组是否处理完成（并且最终决定是否可以响应最初的 Spout 输出元组树）。一般情况下，对于每个输入元组，在处理之后可以根据需要选择不发送还是发送多个新元组，然后再响应（ack）输入元组。&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/IBasicBolt.html"&gt;IBasicBolt&lt;/a&gt; 接口能够实现元组的自动应答。&lt;/p&gt;
&lt;p&gt;在 Bolt 中启动新线程来进行异步处理是一种非常好的方式，因为 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/OutputCollector.html"&gt;OutputCollector&lt;/a&gt; 是线程安全的对象，可以在任意时刻被调用（此处译者保留意见，由于 Storm 的并发设计和集群的弹性扩展机制，在 Bolt 中新建的线程可能存在一定的不可控风险——译者注）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相关资料&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/IRichBolt.html"&gt;IRichBolt&lt;/a&gt;：用于定义 Bolt 的基本接口&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/IBasicBolt.html"&gt;IBasicBolt&lt;/a&gt;: 用于定义带有过滤或者其他简单的函数操作功能的 Bolt 的简便接口&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/OutputCollector.html"&gt;OutputCollector&lt;/a&gt;：Bolt 使用此类来发送数据流&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/documentation/Guaranteeing-message-processing.html"&gt;消息的可靠性处理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;数据流分组（Stream groupings）&lt;/h1&gt;
&lt;p&gt;为拓扑中的每个 Bolt 的确定输入数据流是定义一个拓扑的重要环节。数据流分组定义了在 Bolt 的不同任务（tasks）中划分数据流的方式。&lt;/p&gt;
&lt;p&gt;在 Storm 中有八种内置的数据流分组方式（原文有误，现在已经已经有八种分组模型——译者注），而且你还可以通过 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/grouping/CustomStreamGrouping.html"&gt;CustomStreamGrouping&lt;/a&gt; 接口实现自定义的数据流分组模型。这八种分组分时分别为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;随机分组（Shuffle grouping）：这种方式下元组会被尽可能随机地分配到 Bolt 的不同任务（tasks）中，使得每个任务所处理元组数量能够能够保持基本一致，以确保集群的负载均衡。&lt;/li&gt;
&lt;li&gt;域分组（Fields grouping）：这种方式下数据流根据定义的“域”来进行分组。例如，如果某个数据流是基于一个名为“user-id”的域进行分组的，那么所有包含相同的“user-id”的元组都会被分配到同一个任务中，这样就可以确保消息处理的一致性。&lt;/li&gt;
&lt;li&gt;部分关键字分组（Partial Key grouping）：这种方式与域分组很相似，根据定义的域来对数据流进行分组，不同的是，这种方式会考虑下游 Bolt 数据处理的均衡性问题，在输入数据源关键字不平衡时会有更好的性能&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;。感兴趣的读者可以参考&lt;a href="https://melmeric.files.wordpress.com/2014/11/the-power-of-both-choices-practical-load-balancing-for-distributed-stream-processing-engines.pdf"&gt;这篇论文&lt;/a&gt;，其中详细解释了这种分组方式的工作原理以及它的优点。&lt;/li&gt;
&lt;li&gt;完全分组（All grouping）：这种方式下数据流会被同时发送到 Bolt 的所有任务中（也就是说同一个元组会被复制多份然后被所有的任务处理），使用这种分组方式要特别小心。&lt;/li&gt;
&lt;li&gt;全局分组（Global grouping）：这种方式下所有的数据流都会被发送到 Bolt 的同一个任务中，也就是 id 最小的那个任务。&lt;/li&gt;
&lt;li&gt;非分组（None grouping）：使用这种方式说明你不关心数据流如何分组。目前这种方式的结果与随机分组完全等效，不过未来 Storm 社区可能会考虑通过非分组方式来让 Bolt 和它所订阅的 Spout 或 Bolt 在同一个线程中执行。&lt;/li&gt;
&lt;li&gt;直接分组（Direct grouping）：这是一种特殊的分组方式。使用这种方式意味着元组的发送者可以指定下游的哪个任务可以接收这个元组。只有在数据流被声明为直接数据流时才能够使用直接分组方式。使用直接数据流发送元组需要使用 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/OutputCollector.html"&gt;OutputCollector&lt;/a&gt; 的其中一个 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/OutputCollector.html#emitDirect-int-java.lang.String-java.util.List-"&gt;emitDirect&lt;/a&gt; 方法。Bolt 可以通过 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/TopologyContext.html"&gt;TopologyContext&lt;/a&gt; 来获取它的下游消费者的任务 id，也可以通过跟踪 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/OutputCollector.html"&gt;OutputCollector&lt;/a&gt; 的 &lt;code&gt;emit&lt;/code&gt; 方法（该方法会返回它所发送元组的目标任务的 id）的数据来获取任务 id。&lt;/li&gt;
&lt;li&gt;本地或随机分组（Local or shuffle grouping）：如果在源组件的 worker 进程里目标 Bolt 有一个或更多的任务线程，元组会被随机分配到那些同进程的任务中。换句话说，这与随机分组的方式具有相似的效果。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;相关资料&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/TopologyBuilder.html"&gt;TopologyBuilder&lt;/a&gt;：使用此类构造拓扑&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/InputDeclarer.html"&gt;InputDeclarer&lt;/a&gt;：在 &lt;code&gt;TopologyBuilder&lt;/code&gt; 中调用 &lt;code&gt;setBolt&lt;/code&gt; 方法时会返回这个对象的实例，通过该对象就可以定义 Bolt 的输入数据流以及数据流的分组方式&lt;/li&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/CoordinatedBolt.html"&gt;CoordinatedBolt&lt;/a&gt;：这个 Bolt 主要用于分布式 RPC 拓扑，其中大量使用了直接数据流与直接分组模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;可靠性（Reliability）&lt;/h1&gt;
&lt;p&gt;Storm 可以通过拓扑来确保每个发送的元组都能得到正确处理。通过跟踪由 Spout 发出的每个元组构成的元组树可以确定元组是否已经完成处理。每个拓扑都有一个“消息延时”参数，如果 Storm 在延时时间内没有检测到元组是否处理完成，就会将该元组标记为处理失败，并会在稍后重新发送该元组。&lt;/p&gt;
&lt;p&gt;为了充分利用 Storm 的可靠性机制，你必须在元组树创建新结点的时候以及元组处理完成的时候通知 Storm。这个过程可以在 Bolt 发送元组时通过 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/task/OutputCollector.html"&gt;OutputCollector&lt;/a&gt; 实现：在 &lt;code&gt;emit&lt;/code&gt; 方法中实现元组的锚定（Anchoring），同时使用 &lt;code&gt;ack&lt;/code&gt; 方法表明你已经完成了元组的处理。&lt;/p&gt;
&lt;p&gt;关于可靠性保障的更多内容可以参考这篇文章：&lt;a href="http://storm.apache.org/documentation/Guaranteeing-message-processing.html"&gt;消息的可靠性处理&lt;/a&gt;。&lt;/p&gt;
&lt;h1&gt;任务（Tasks）&lt;/h1&gt;
&lt;p&gt;在 Storm 集群中每个 Spout 和 Bolt 都由若干个任务（tasks）来执行。每个任务都与一个执行线程相对应。数据流分组可以决定如何由一组任务向另一组任务发送元组。你可以在 &lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/topology/TopologyBuilder.html"&gt;TopologyBuilder&lt;/a&gt; 的 &lt;code&gt;setSpout&lt;/code&gt; 方法和 &lt;code&gt;setBolt&lt;/code&gt; 方法中设置 Spout/Bolt 的并行度。&lt;/p&gt;
&lt;h1&gt;工作进程（Workers）&lt;/h1&gt;
&lt;p&gt;拓扑是在一个或多个工作进程（worker processes）中运行的。每个工作进程都是一个实际的 JVM 进程，并且执行拓扑的一个子集。例如，如果拓扑的并行度定义为300，工作进程数定义为50，那么每个工作进程就会执行6个任务（进程内部的线程）。Storm 会在所有的 worker 中分散任务，以便实现集群的负载均衡。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相关资料&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://storm.apache.org/javadoc/apidocs/backtype/storm/Config.html#TOPOLOGY_WORKERS"&gt;Config.TOPOLOGY_WORKERS&lt;/a&gt;：这个配置项用于设置拓扑的工作进程数&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Partial Key grouping 方式目前仅支持开发版，尚未加入 Storm 的正式发行版，不过可以通过 &lt;code&gt;CustomStreamGrouping&lt;/code&gt; 间接实现该分组功能，具体的实现可以参考 &lt;code&gt;PartialKeyGrouping&lt;/code&gt; &lt;a href="https://github.com/apache/storm/blob/master/storm-core/src/jvm/backtype/storm/grouping/PartialKeyGrouping.java"&gt;源代码&lt;/a&gt;。&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sat, 13 Jun 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-13:pages/techs/storm-translations-concepts/</guid><category>Storm</category><category>Translation</category></item><item><title>Jedis &amp; Benchmark</title><link>http://weyo.me/pages/techs/jedis-and-benchmark/</link><description>&lt;h1&gt;Jedis&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/xetorthio/jedis"&gt;Jedis&lt;/a&gt; 是 &lt;a href="http://redis.io/"&gt;Redis&lt;/a&gt; 官方推荐的 Java 客户端，目前已经更新到 2.7 版本，支持 Redis 2.8.x ~ 3.0.x。&lt;/p&gt;
&lt;p&gt;Jedis 的 Maven 依赖包如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;redis.clients&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;jedis&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;2.7.2&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;type&amp;gt;&lt;/span&gt;jar&lt;span class="nt"&gt;&amp;lt;/type&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;compile&lt;span class="nt"&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;单条数据处理模式&lt;/h2&gt;
&lt;p&gt;此模式下 Jedis 的每一个操作都会被当作一个独立的 “Request-Response” 模型进行执行，这种模式的使用非常简单：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5
6
7&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;JedisPool&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;JedisPool&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;redis.host&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;Jedis&lt;/span&gt; &lt;span class="n"&gt;jedis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getResource&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;jedis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;set&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;poop&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;poobar&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;poobar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jedis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;poop&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

&lt;span class="n"&gt;jedis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;close&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;close&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;h2&gt;批量数据处理模式&lt;/h2&gt;
&lt;p&gt;批量数据处理模式主要是指通过 &lt;code&gt;Pipeline&lt;/code&gt;(管道) 缓冲数据，将多个 command，依次发送给 server 的一种批处理模式（注意，这里的批处理与事务是不同的概念，批处理并不能保证请求的成功性）。在 server 处理 command 期间，客户端无法获得单个 command 的响应数据，只有在 server 处理完成、关闭 Pipeline 请求之后才可以依次获取每个 command 的响应结果，也就是说每次获取结果之前关闭 Pipeline 请求的过程是必不可少的。&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5
6
7
8
9&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;JedisPool&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;JedisPool&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;redis.host&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;Jedis&lt;/span&gt; &lt;span class="n"&gt;jedis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getResource&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;Pipeline&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jedis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;pipelined&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;Response&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;poop&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;pipeline&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;sync&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;poobar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

&lt;span class="n"&gt;jedis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;close&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;close&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;由于 Pipeline 实际上减少了客户端与服务端之间反复的连接时间，使得数据处理的效率大大提高。笔者在一开始使用 Jedis 时发现效率极低，基本上一秒钟只能处理几千条数据，而且不论怎么优化 Redis，这个结果都没有明显的提高。为此笔者纠结了很长一段时间不得其解，直到最近了解到 Pipeline 这个利器之后才豁然开朗。下面的 Benchmark 测试结果就直接显示了两种方式的性能差异。&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;Benchmark&lt;/h1&gt;
&lt;blockquote&gt;
&lt;h2&gt;基本信息&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;单点 Redis 服务器（虚拟机环境）&lt;/li&gt;
&lt;li&gt;CPU：Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz，核心数：2&lt;/li&gt;
&lt;li&gt;内存：3.8 G&lt;/li&gt;
&lt;li&gt;操作系统：CentOS release 5.4&lt;/li&gt;
&lt;li&gt;不开启 DB save&lt;/li&gt;
&lt;li&gt;单线程客户端&lt;/li&gt;
&lt;li&gt;由于几次试验测试结果相似，就选取一次的测试结果作为最终结果，没有使用多次测试选取均值的方式，可能与真实性能稍微有些出入&lt;/li&gt;
&lt;li&gt;单条数据处理指的是直接使用 &lt;code&gt;Jedis&lt;/code&gt; 接口操作，批量处理指的是使用 &lt;code&gt;Pipeline&lt;/code&gt; 接口操作&lt;/li&gt;
&lt;li&gt;网络访问指的是客户端与 Redis 服务器位于同一网段的不同机器上，本机访问指的是客户端与 Redis 服务器位于同一台机器上&lt;/li&gt;
&lt;li&gt;简单起见，读写的 key 设置为字符串 "Jedis:i"(i 为循环的次数)，value 与 key 相同&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;网络访问&lt;/h2&gt;
&lt;h3&gt;单条数据处理&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;百万级数据写（key-String, value-String）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;  452,730,121,946 纳秒 约等于 453 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;百万级数据读&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 508,386,552,562 纳秒 约等于 508 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;百万级数据删除&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 508,714,438,156 纳秒 约等于 509 秒&lt;/p&gt;
&lt;h3&gt;批量数据处理&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;百万级数据写（key-String, value-String）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;  6,151,898,431 纳秒 约等于 6 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;百万级数据读&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 3,519,384,281 纳秒 约等于 3 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;百万级数据删除&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 5,186,055,510 纳秒 约等于 5 秒&lt;/p&gt;
&lt;h2&gt;本机访问&lt;/h2&gt;
&lt;h3&gt;单条数据处理&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;说明：为了减少测试时间，这里只测试了1W条数据的读写&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;万级数据写（key-String, value-String）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;  1,199,071,735 纳秒 约等于 1 秒&lt;/p&gt;
&lt;p&gt;对比：网络访问单条数据处理模式万级数据写时间约等于 5 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;万级数据读&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 1,111,957,283 纳秒 约等于 1 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;万级数据删除&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 1,121,649,753 纳秒 约等于 1 秒&lt;/p&gt;
&lt;h3&gt;批量数据处理&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;万级数据写（key-String, value-String）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;  352,212,255 纳秒 约等于 0.35 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;万级数据读&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 344,821,892 纳秒 约等于 0.34 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;万级数据删除&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 341,540,726 纳秒 约等于 0.7 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;十万级数据写（key-String, value-String）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;  827,447,969 纳秒 约等于 0.8 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;十万级数据读&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 718,332,980 纳秒 约等于 0.7 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;十万级数据删除&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 758,594,043 纳秒 约等于 0.7 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;百万级数据写（key-String, value-String）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;  6,105,554,458 纳秒 约等于 6 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;百万级数据读&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 4,034,674,889 纳秒 约等于 4 秒&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;百万级数据删除&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt; 4,921,311,797 纳秒 约等于 5 秒&lt;/p&gt;
&lt;p&gt;上面的结果可以看出 Pipeline 的读写方式比普通的读写方式提高了近百倍的效率，差距还是相当明显的。&lt;/p&gt;
&lt;h2&gt;多线程&lt;/h2&gt;
&lt;p&gt;在一个客户端上开启 100 个线程写 10000 条数据，吞吐率约为 190,222 res/s。&lt;/p&gt;
&lt;p&gt;在继续增加线程到 1000 个时报错：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;Exception in thread &amp;quot;main&amp;quot; java.util.concurrent.ExecutionException: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.concurrent.FutureTask.report(FutureTask.java:122)&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.concurrent.FutureTask.get(FutureTask.java:188)&lt;/span&gt;
&lt;span class="x"&gt;    at com.enjoyor.jedis.benchmark.Benchmark.main(Benchmark.java:97)&lt;/span&gt;
&lt;span class="x"&gt;Caused by: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool&lt;/span&gt;
&lt;span class="x"&gt;    at redis.clients.util.Pool.getResource(Pool.java:50)&lt;/span&gt;
&lt;span class="x"&gt;    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:86)&lt;/span&gt;
&lt;span class="x"&gt;    at com.enjoyor.jedis.benchmark.Benchmark&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;Ctest&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;Benchmark.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;57&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at com.enjoyor.jedis.benchmark.Benchmark&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;Ctest&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;Benchmark.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.concurrent.FutureTask.run(FutureTask.java:262)&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.concurrent.ThreadPoolExecutor&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;Worker&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;ThreadPoolExecutor.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;615&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at java.lang.Thread.run(Thread.java:744)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这是 Redis 的连接数限制的原因，需要修改 maxclients 来增大连接数。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Redis-benchmark&lt;/h2&gt;
&lt;p&gt;Redis 自带了一个 benchmark 工具，这里就使用这个官方的 redis-benchmark 工具进行对比验证。&lt;/p&gt;
&lt;h3&gt;万级数据&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[root@hd124]$&amp;gt;src/redis-benchmark -n 10000
====== PING_INLINE ======
  10000 requests completed in 0.13 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

99.01% &amp;lt;= 1 milliseconds
99.51% &amp;lt;= 5 milliseconds
99.79% &amp;lt;= 6 milliseconds
100.00% &amp;lt;= 6 milliseconds
75187.97 requests per second

====== PING_BULK ======
  10000 requests completed in 0.13 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

100.00% &amp;lt;= 0 milliseconds
79365.08 requests per second

====== SET ======
  10000 requests completed in 0.13 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

99.93% &amp;lt;= 1 milliseconds
100.00% &amp;lt;= 1 milliseconds
78125.00 requests per second

====== GET ======
  10000 requests completed in 0.13 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

99.58% &amp;lt;= 1 milliseconds
100.00% &amp;lt;= 1 milliseconds
78740.16 requests per second
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;百万级数据&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[root@hd124]$&amp;gt;src/redis-benchmark -n 1000000
====== PING_INLINE ======
  1000000 requests completed in 11.54 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

99.95% &amp;lt;= 1 milliseconds
99.98% &amp;lt;= 2 milliseconds
99.99% &amp;lt;= 3 milliseconds
100.00% &amp;lt;= 4 milliseconds
100.00% &amp;lt;= 5 milliseconds
100.00% &amp;lt;= 5 milliseconds
86662.62 requests per second

====== PING_BULK ======
  1000000 requests completed in 11.47 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

99.98% &amp;lt;= 1 milliseconds
99.99% &amp;lt;= 2 milliseconds
99.99% &amp;lt;= 3 milliseconds
100.00% &amp;lt;= 4 milliseconds
100.00% &amp;lt;= 4 milliseconds
87214.38 requests per second

====== SET ======
  1000000 requests completed in 11.70 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

99.67% &amp;lt;= 1 milliseconds
99.95% &amp;lt;= 2 milliseconds
99.97% &amp;lt;= 3 milliseconds
99.98% &amp;lt;= 4 milliseconds
99.99% &amp;lt;= 5 milliseconds
99.99% &amp;lt;= 6 milliseconds
100.00% &amp;lt;= 8 milliseconds
100.00% &amp;lt;= 8 milliseconds
85448.17 requests per second

====== GET ======
  1000000 requests completed in 11.48 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

99.97% &amp;lt;= 1 milliseconds
99.99% &amp;lt;= 2 milliseconds
100.00% &amp;lt;= 4 milliseconds
100.00% &amp;lt;= 4 milliseconds
87077.67 requests per second
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;官方的结果显示请求数在万级数据量的大小时效率比 Jedis 要稍微高一点（0.35s &amp;gt; 0.13s），但是当数据量增加到百万级的时候效率就要低很多了（6s &amp;lt; 11.7s）。这可能是官方客户端访问方式有所不同（毕竟是模拟的多客户端），后面有机会再研究一下这方面的源码。&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;Reference&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/xetorthio/jedis"&gt;https://github.com/xetorthio/jedis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://shift-alt-ctrl.iteye.com/blog/1863790"&gt;http://shift-alt-ctrl.iteye.com/blog/1863790&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Wed, 03 Jun 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-06-03:pages/techs/jedis-and-benchmark/</guid><category>Redis</category><category>Jedis</category><category>Benchmark</category></item><item><title>Strom DRPC 应用 —— 分布式实时计算应用篇(四)</title><link>http://weyo.me/pages/techs/storm-drpc-basis/</link><description>&lt;h1&gt;Storm DRPC&lt;/h1&gt;
&lt;p&gt;（翻译自 &lt;a href="http://storm.apache.org/documentation/Distributed-RPC.html"&gt;Storm 官网&lt;/a&gt;）分布式 RPC（DRPC）的设计目标是充分利用 Storm 的计算能力实现高密度的并行实时计算。Storm 接收若干个函数参数作为输入流，然后通过 DRPC 输出这些函数调用的结果。严格来说，DRPC 并不能算作是 Storm 的一个特性，因为它只是一种基于 Storm 原语 (Stream、Spout、Bolt、Topology) 实现的计算模式。虽然可以将 DRPC 从 Storm 中打包出来作为一个独立的库，但是与 Storm 集成在一起显然更有用。&lt;/p&gt;
&lt;p&gt;DRPC 是通过一个 DRPC 服务端(DRPC server)来实现分布式 RPC 功能的。DRPC server 负责接收 RPC 请求，并将该请求发送到 Storm 中运行的 Topology，等待接收 Topology 发送的处理结果，并将该结果返回给发送请求的客户端。因此，从客户端的角度来说，DPRC 与普通的 RPC 调用并没有什么区别。下图是 DRPC 的原理示意图。&lt;/p&gt;
&lt;p&gt;&lt;img alt="此处输入图片的描述" src="http://storm.apache.org/documentation/images/drpc-workflow.png" /&gt;&lt;/p&gt;
&lt;p&gt;下面结合笔者个人的实践经验介绍 Storm DRPC 的使用。&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;集群配置&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;nimbus: "hd124"&lt;/li&gt;
&lt;li&gt;DRPC server: "hd181"&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Server 端&lt;/h1&gt;
&lt;h2&gt;启动 DRPC server&lt;/h2&gt;
&lt;p&gt;在安装有 Storm 环境的服务器启动一个 DRPC server，注意，此 server 的基本配置（nimbus，ZooKeeper，……）应该与集群其他机器相同。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nohup storm drpc &amp;gt;&amp;gt; /home/storm/apache-storm-0.9.3/logs/nohup_drpc.out 2&amp;gt;&amp;amp;1 &amp;amp;&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;配置集群 DRPC server 列表&lt;/h2&gt;
&lt;p&gt;在集群其他机器上添加配置：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;drpc.servers:
  - &amp;quot;hd181&amp;quot;
  - &amp;quot;otherdrpcservers&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;hd181/otherdrpcservers 是上面启动的 DRPC server 地址。&lt;/p&gt;
&lt;h2&gt;定义 DRPC topology&lt;/h2&gt;
&lt;h3&gt;Local mode&lt;/h3&gt;
&lt;p&gt;使用 &lt;code&gt;LocalDRPC&lt;/code&gt; 定义本地 RPC 服务模式：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TopologyBuilder&lt;/span&gt; &lt;span class="n"&gt;builder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;TopologyBuilder&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;LocalDRPC&lt;/span&gt; &lt;span class="n"&gt;drpc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;LocalDRPC&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

&lt;span class="n"&gt;DRPCSpout&lt;/span&gt; &lt;span class="n"&gt;spout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;DRPCSpout&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;exclamation&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;drpc&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setSpout&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;drpc&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;spout&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;exclaim&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ExclamationBolt&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;shuffleGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;drpc&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;return&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ReturnResults&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;shuffleGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;exclaim&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

&lt;span class="n"&gt;LocalCluster&lt;/span&gt; &lt;span class="n"&gt;cluster&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;LocalCluster&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;Config&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;cluster&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;submitTopology&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;exclaim&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;createTopology&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;

&lt;span class="c1"&gt;// local mode 测试代码&lt;/span&gt;
&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;drpc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;execute&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;exclamation&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;aaa&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;h3&gt;Remote mode&lt;/h3&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TopologyBuilder&lt;/span&gt; &lt;span class="n"&gt;builder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;TopologyBuilder&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

&lt;span class="n"&gt;DRPCSpout&lt;/span&gt; &lt;span class="n"&gt;spout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;DRPCSpout&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;drpcFunc&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setSpout&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;drpc&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;spout&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;exclaim&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ExclamationBolt&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;shuffleGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;drpc&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;return&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ReturnResults&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;shuffleGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;exclaim&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

&lt;span class="n"&gt;Config&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setNumWorkers&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

&lt;span class="n"&gt;StormSubmitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;submitTopology&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;drpc-test&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;createTopology&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;hr /&gt;
&lt;h1&gt;Client 端&lt;/h1&gt;
&lt;p&gt;在 DRPC server 启动完成、DPRC Topology 提交到 Storm 集群运行之后，就可以启动 DRPC 客户端。&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5
6
7
8&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;DRPCClientDemo&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;TException&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DRPCExecutionException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;DRPCClient&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;DRPCClient&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;hd181&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3772&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;execute&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;drpcFunc&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;aaa&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;blockquote&gt;
&lt;h3&gt;说明&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;3772 是 Storm 集群中配置的 DRPC 端口（drpc.port: 3772）。&lt;/li&gt;
&lt;li&gt;客户端调用的函数名称必须与 Topology 中定义的 &lt;code&gt;DRPCSpout&lt;/code&gt; 的 componentId 相同。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果一切正常客户端会很快收到结果；如果发生错误，就会报错：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;Exception in thread &amp;quot;main&amp;quot; DRPCExecutionException(msg:Request timed out)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.generated.DistributedRPC&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;execute_result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;DistributedRPC.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;904&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.thrift7.TServiceClient.receiveBase(TServiceClient.java:78)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.generated.DistributedRPC&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;Client&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;recv_execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;DistributedRPC.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;92&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.generated.DistributedRPC&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;Client&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;DistributedRPC.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;78&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.utils.DRPCClient.execute(DRPCClient.java:71)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在服务器间网络连接正常的情况下，这种错误一般是集群或 Topology 的配置错误，例如 DRPC 服务端 IP、端口配置错误，或执行的 function 名称错误等，客户端会等待服务端的响应很长时间（默认配置为 600s，可以在 storm.yaml 中修改)，此时需要检查集群的部署是否正确。&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;Questions&lt;/h1&gt;
&lt;p&gt;修改配置或重新启动 DRPC server 后有一段时间出现错误&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;Exclamation-6:aaa203!!!&lt;/span&gt;
&lt;span class="x"&gt;Exception in thread &amp;quot;main&amp;quot; DRPCExecutionException(msg:Request failed)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.generated.DistributedRPC&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;execute_result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;DistributedRPC.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;904&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.thrift7.TServiceClient.receiveBase(TServiceClient.java:78)&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.generated.DistributedRPC&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;Client&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;recv_execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;DistributedRPC.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;92&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.generated.DistributedRPC&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;Client&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;DistributedRPC.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;78&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at backtype.storm.utils.DRPCClient.execute(DRPCClient.java:71)&lt;/span&gt;
&lt;span class="x"&gt;    at com.enjoyor.storm.kafka.example.DRPCClientDemo.main(DRPCTest.java:18)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Client 的代码如下&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5
6
7&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;TException&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DRPCExecutionException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;DRPCClient&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;DRPCClient&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;hd181&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3772&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;execute&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;drpcFunc&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;aaa&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;即在重启 DRPC server 后会存在一段服务不稳定的时间，这段时间内 DRPC server 会时而正常执行 RPC 请求，时而连接不正常，大约在十分钟后恢复正常。这个问题已经提交给 Storm 社区了，暂时还没有收到正式的回应。&lt;/p&gt;
&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sun, 24 May 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-05-24:pages/techs/storm-drpc-basis/</guid><category>Storm</category><category>分布式计算</category><category>实时计算</category><category>RPC</category></item><item><title>Strom 连续多级批处理实践 —— 分布式实时计算应用篇(三)</title><link>http://weyo.me/pages/techs/storm-continuous-batch-process/</link><description>&lt;h1&gt;业务场景&lt;/h1&gt;
&lt;p&gt;最近在开发过程中遇到了一个比较复杂的场景，需要实现如下的业务逻辑：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;有多个连续的 Bolt，例如 &lt;code&gt;BoltA--&amp;gt;BoltB--&amp;gt;BoltC--&amp;gt;BoltD...&lt;/code&gt;，每一级 Bolt 均按照 &lt;code&gt;fieldGrouping&lt;/code&gt; 的方式进行处理；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BoltA 对数据流进行定时处理，BoltA 处理后数据发送到 BoltB；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BlotA 一批数据发送完成之后发送 &lt;code&gt;“发送完成”&lt;/code&gt; 信号给 BoltB；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BoltB 接收 BoltA 所发送的数据并存储在内存(Map)中，当收到 BoltA 发送的 &lt;code&gt;“发送完成”&lt;/code&gt; 信号后，开始处理内存中的数据，并将结果依次发送到 BoltC，同样，在内存中数据处理完成之后发送 &lt;code&gt;“发送完成”&lt;/code&gt; 信号给 BoltC；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BoltC, BoltD, ... 采用与 BoltB 相同的批处理方式。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;技术难点&lt;/h1&gt;
&lt;p&gt;这个场景看上去挺简单，只需要分别实现定时处理和批处理的逻辑就可以了，实际上有很多坑：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;由于每一级 Bolt 的数据处理算法逻辑较复杂，不能直接使用 Trident；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在生产环境中集群的并发度 &amp;gt;&amp;gt; 1，每一个 Bolt 都有多个工作线程，并且分布在不同的 worker 节点上，无法确保 &lt;code&gt;“发送完成”&lt;/code&gt; 信号能够恰好发送到下一级 Bolt 的所有的 task 上；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同理，由于集群的分布式，每一级 Bolt 的缓存数据同样分布在不同的 worker 上，而且由于算法需要，每一级 Bolt 实际处理的域均有所不同，不能简单使用 fieldGrouping 方式进行汇总处理；而且也不能使用 allGrouping 的方式，否则会造成数据的重复处理；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以使用 globalGrouping 的方式依次汇总每一级 Bolt 的数据流，但是这样就严重浪费了 Strom 的并发性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;设计实现&lt;/h1&gt;
&lt;p&gt;这个问题着实困扰了我好几天的时间，期间尝试了多种方式均告失败：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;直接串联 BoltA 与 BoltB，但是 BoltA 的 &lt;code&gt;“发送完成”&lt;/code&gt; 信号始终无法保证发送到 BoltB 的所有 executor(task) 上；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在两个连续 Bolt 中间设计一个中介 Bolt，用于接收数据并发送信号，结果发现这是与 1 相同的方式；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;听说 DRPC 的组件 &lt;code&gt;CoordinatedBolt&lt;/code&gt; 具有批处理的功能，使用 CoordinatedBolt 来包装 Bolt，结果与普通的串联 Bolt 相同；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样的结果确实够打击人的，唯一的收获是了解到新版的 Storm 支持通过 &lt;code&gt;tick tuple&lt;/code&gt; 来实现定时功能，这样 BoltA 的定时处理问题就能解决了（比我一开始时设计的 &lt;code&gt;TimingSpout&lt;/code&gt; 效果要好得多，虽然还是达不到普通的 Java 程序时间控制的精确程度，但总是聊胜于无）。&lt;/p&gt;
&lt;p&gt;郁闷了好一段时间之后，决定还是从那个号称能够实现完全批处理功能的 &lt;code&gt;CoordinatedBolt&lt;/code&gt; 入手。在了解了 &lt;code&gt;CoordinatedBolt&lt;/code&gt; 的实现原理后 (&lt;a href="http://xumingming.sinaapp.com/811/twitter-storm-code-analysis-coordinated-bolt/"&gt;Twitter Storm源代码分析之CoordinatedBolt&lt;/a&gt;)，隐隐约约感觉到这应该是一个设计方向。于是尝试在 BoltA 中同时使用 &lt;code&gt;emit&lt;/code&gt; 与 &lt;code&gt;emitDirect&lt;/code&gt; 来发送消息，其中，前者仍然发送普通数据，而后者用于发送信号，但是实际运行时发现 Storm 并不支持在同一个 Bolt 中同时采用普通的 &lt;code&gt;emit&lt;/code&gt; 与 &lt;code&gt;emitDirect&lt;/code&gt; 两种数据传输方式，topology 无法运行，这次尝试再告失败。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Let there be light: and there was light.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;既然在同一个 Bolt 中同时发送两种数据无法成功，那么分成两个 Bolt 分别发送可不可行呢？&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;解决方案&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Yes, it works.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在两级 Bolt 中加入一个并联（不是之前的串联方式）的中介 Bolt —— &lt;code&gt;InterMediateBolt&lt;/code&gt;，这个 Bolt 只负责发送 &lt;code&gt;“发送完成”&lt;/code&gt; 信号，结构如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                 Stream1
BoltA ---------------------------&amp;gt;BoltB
  |                                 ^
  |Stream2                          |
  +--------&amp;gt; InterMediateBolt ------+
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;Strem1 代表普通的数据流，Stream2 代表 BoltA 发送的批处理信号。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;InterMediateBolt&lt;/code&gt; 的代码如下：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;InterMediateBolt&lt;/span&gt; &lt;span class="kd"&gt;extends&lt;/span&gt; &lt;span class="n"&gt;BaseRichBolt&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;_countOutTasks&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;targetComponents&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="n"&gt;OutputCollector&lt;/span&gt; &lt;span class="n"&gt;_collector&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;sourceNumber&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="nf"&gt;InterMediateBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="n"&gt;targetComponentIds&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;_countOutTasks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ArrayList&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;targetComponents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ArrayList&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;targetComponentIds&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;targetComponents&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;sourceNumber&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;prepare&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nd"&gt;@SuppressWarnings&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rawtypes&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="n"&gt;Map&lt;/span&gt; &lt;span class="n"&gt;stormConf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;TopologyContext&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;OutputCollector&lt;/span&gt; &lt;span class="n"&gt;collector&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;component&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;targetComponents&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt; &lt;span class="n"&gt;task&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getComponentTasks&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;component&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;_countOutTasks&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
            &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;_collector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;collector&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Tuple&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="kt"&gt;boolean&lt;/span&gt; &lt;span class="n"&gt;signal&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getBoolean&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(++&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;sourceNumber&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;InterMediateBolt received: ++++++++&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;signal&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;task&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;_countOutTasks&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;_collector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;emitDirect&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Values&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
            &lt;span class="o"&gt;}&lt;/span&gt;
            &lt;span class="c1"&gt;// 信号消息需要确保能够发送成功&lt;/span&gt;
            &lt;span class="n"&gt;_collector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;ack&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
            &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;declareOutputFields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OutputFieldsDeclarer&lt;/span&gt; &lt;span class="n"&gt;declarer&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;declarer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;declare&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;signal&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;   
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;
这时上游的 Bolt 需要发送两个数据流（这里以 word-count 为例，代码中省略了根据 tick tuple 判断定时信号的逻辑）：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Tuple&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getString&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;containsKey&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

    &lt;span class="c1"&gt;// 达到指定条件时批量发送缓存数据&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;condition&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;Iterator&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Entry&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;entrySet&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;
                &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;iterator&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;hasNext&lt;/span&gt;&lt;span class="o"&gt;())&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;Entry&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;next&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
            &lt;span class="n"&gt;_collector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;emit&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;stream1&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Values&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getKey&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt;
                    &lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getValue&lt;/span&gt;&lt;span class="o"&gt;()));&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="c1"&gt;// 缓存数据发送结束后发送“发送完成”信号&lt;/span&gt;
        &lt;span class="n"&gt;_collector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;emit&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;stream2&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Values&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
        &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;clear&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;其中，&lt;code&gt;stream1&lt;/code&gt; 仍是普通的数据流，&lt;code&gt;stream2&lt;/code&gt; 则是信号数据流。&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;
这样，下游的 Bolt 就可以很容易根据信号对数据流进行处理了：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Tuple&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;boolean&lt;/span&gt; &lt;span class="n"&gt;signal&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getBoolean&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;signal&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Handle-task-&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;taskId&lt;/span&gt;
                &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;: received ***signal***&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getString&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getInteger&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Handle-task-&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;taskId&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;: received &amp;quot;&lt;/span&gt;
                &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;-&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;_collector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;ack&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;
在 topology 中可以这样定义各个 Bolt：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;bn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;boltA&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;boltA&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;boltB&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;boltB&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;intermediate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;intermediate&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;boltA&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;BoltA&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;fieldsGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;words&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;word&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;intermediate&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;InterMediateBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;an&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;boltB&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;shuffleGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;boltA&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;stream2&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;boltB&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;HandleBolt&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;bn&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;fieldsGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;boltA&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;stream1&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;word&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;directGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;intermediate&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;h2&gt;说明&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;为了使得 &lt;code&gt;InterMediateBolt&lt;/code&gt; 能够获取下游 Bolt 的各个 taskId，这里在 &lt;code&gt;InterMediateBolt&lt;/code&gt; 的构造器中传入了下游 Bolt 的 &lt;code&gt;componentId&lt;/code&gt; 参数，根据 &lt;code&gt;componentId&lt;/code&gt; 就可以在初始化阶段从 &lt;code&gt;TopologyContext&lt;/code&gt; 中获取到所需要的 taskId。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 &lt;code&gt;InterMediateBolt&lt;/code&gt; 的构造器中传入了上游 Bolt 的并发度（parallelism_hint）参数，是为了确保上游任务处理结果的一致性，使得下游任务必须在上游所有任务全部完成之后才能开始进行。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span style="font-family:微软雅黑; color:#A52A2A"&gt;&lt;strong&gt;[注意]&lt;/strong&gt; 这里的 &lt;code&gt;InterMediateBolt&lt;/code&gt; 的 &lt;code&gt;parallelism_hint&lt;/code&gt; 必须 &lt;strong&gt;设置为 1&lt;/strong&gt;，这是为了保证上游 Bolt 的所有的 executor 都能够统一将信号发送到 &lt;code&gt;InterMediateBolt&lt;/code&gt; 的唯一一个 task。由于 &lt;code&gt;InterMediateBolt&lt;/code&gt; 只处理单一的信号消息，数据的吞吐量极小，并行度为 1 并不会降低集群的处理性能。&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Fri, 22 May 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-05-22:pages/techs/storm-continuous-batch-process/</guid><category>Storm</category><category>分布式计算</category><category>实时计算</category></item><item><title>通过 IDE 向 Storm 集群远程提交 topology</title><link>http://weyo.me/pages/techs/storm-topology-remote-submission/</link><description>&lt;blockquote&gt;
&lt;p&gt;作为一个懒癌晚期患者，虽然 Storm 只需要一条命令的任务提交方式已经够简单了，但还是一直想要有种更简(tou)单(lan)的方式，比如要是在 Windows 下写完代码之后可以直接提交任务而不需要手动把 jar 包拷到服务器上再提交那定是极好的了。谷歌了一下终于在墙外找到了解决方法: &lt;a href="http://nishutayaltech.blogspot.in/2014/06/submitting-topology-to-remote-storm.html"&gt;Submitting a topology to Remote Storm Cluster&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Storm 集群配置&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;nimbus: "hd124"&lt;/li&gt;
&lt;li&gt;nimbus.port: 6627&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;提交 Topology&lt;/h2&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Config&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setNumWorkers&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setDebug&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="c1"&gt;// ...&lt;/span&gt;
&lt;span class="c1"&gt;// topology 其他配置信息等&lt;/span&gt;

&lt;span class="c1"&gt;// 读取本地 Storm 配置文件&lt;/span&gt;
&lt;span class="n"&gt;Map&lt;/span&gt; &lt;span class="n"&gt;stormConf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Utils&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;readStormConfig&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;stormConf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nimbus.host&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;hd124&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;stormConf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;putAll&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

&lt;span class="n"&gt;Nimbus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;Client&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NimbusClient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getConfiguredClient&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stormConf&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="na"&gt;getClient&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;inputJar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;E:\\workspace\\storm-demo\\target\\storm-demo-0.0.5-SNAPSHOT-shade.jar&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;NimbusClient&lt;/span&gt; &lt;span class="n"&gt;nimbus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;NimbusClient&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stormConf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;hd124&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6627&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;// 使用 StormSubmitter 提交 jar 包&lt;/span&gt;
&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;uploadedJarLocation&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;StormSubmitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;submitJar&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stormConf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputJar&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;jsonConf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;JSONValue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;toJSONString&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stormConf&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;nimbus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getClient&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="na"&gt;submitTopology&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;remotetopology&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;uploadedJarLocation&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;jsonConf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;createTopology&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;h2&gt;说明&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;第8行会读取 Storm 的本地配置文件，如果不指定的话，&lt;code&gt;Utils.readStormConfig()&lt;/code&gt; 会读取 Storm 依赖 jar 包的默认配置文件，如 &lt;code&gt;"\maven\repository\org\apache\storm\storm-core\0.9.3\storm-core-0.9.3.jar\defaults.yaml"&lt;/code&gt;，如果集群配置与默认配置有较大不同，还需要修改对应配置信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这段代码需要在 Topology 已经完成打包之后运行，因为需要在程序中指定待提交的 jar 包。可以在 IDE 中安装 Maven 插件，Topology 开发完成之后直接打包，然后再切换到这段提交代码中执行提交任务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;任务提交完成之后可以在 Storm UI 中查看提交结果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;h1&gt;Reference&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/15781176/how-to-submit-a-topology-in-storm-production-cluster-using-ide"&gt;http://stackoverflow.com/questions/15781176/how-to-submit-a-topology-in-storm-production-cluster-using-ide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nishutayaltech.blogspot.in/2014/06/submitting-topology-to-remote-storm.html"&gt;http://nishutayaltech.blogspot.in/2014/06/submitting-topology-to-remote-storm.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Tue, 19 May 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-05-19:pages/techs/storm-topology-remote-submission/</guid><category>Storm</category><category>Translation</category></item><item><title>神奇的三门问题</title><link>http://weyo.me/pages/essays/monty-hall-problem/</link><description>&lt;p&gt;前几天遇到这么一道智力题：
在一场游戏中，主持人拿出了三个完全一样的密封盒子，其中一个盒子内有奖品，另外两个为空盒子。主持人首先让你挑选一个你认为有奖品的盒子。然后，主持人在剩下的两个盒子中拿走一个必然为空的盒子。现在，主持人问：你愿不愿意用你手中的盒子和主持人手中的盒子交换？你手中的盒子和主持人手中的盒子里面有奖品的概率各有多少？&lt;/p&gt;
&lt;p&gt;这其实就是大名鼎鼎的 &lt;strong&gt;三门问题&lt;/strong&gt; 了。&lt;/p&gt;
&lt;p&gt;&lt;img src=http://images.cnitblog.com/blog/329852/201311/24200658-c442dec3691a4e929938ba98a52d78c5.png width="60%" height="60%"  /&gt;&lt;/p&gt;
&lt;p&gt;“&lt;a href="http://baike.baidu.com/link?url=YMqqL9eOdMp1PRh7jqKHEexoqjYWS-fd-ZwJ1tyzho9ZCQX5esy4etWvBRLy1KPjiGf0gAXnfPmsgyk9wpAm7q"&gt;&lt;strong&gt;三门问题-百度百科&lt;/strong&gt;&lt;/a&gt;” 中对这个问题有详细的描述，这里我就不重复了。随便在网上搜一下“三门问题”、“三个盒子 主持人 奖品”之类的关键词就会发现有很多很多争议的帖子，而且这个问题甚至成了果壳的年经话题。不过，虽然争议的人很多，但是争议的结论无非是两个：
- 答案一：选择更换盒子，会有更高（2/3）中奖的概率；
- 答案二：换不换无所谓，都是相等（50%）的中奖概率。&lt;/p&gt;
&lt;p&gt;对这个问题的第一反应我是倾向于第二个结论的。直觉上来说，去掉一个空盒子，不就变成了两个盒子中选一个，概率当然应该是一半一半。但有时候事情往往是反直觉的，在我准备写模拟程序验证的时候就感觉有点不对劲，当时，我大概写了四五行代码：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5
6&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;boolean&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;boxes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;randomBoxes&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;chosen&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getRandoBox&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;boxes&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;removed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;removeEmptyBox&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;boxes&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;写到这里，忽然发现不管程序接下来会有什么样的操作，第一次选择的盒子中奖概率是永远不会变的，因为在一开始的时候就已经选定了盒子，中奖率自然就是1/3。实际上，这个问题就是一个盒子与两个盒子的概率对比问题，毫无疑问，两个盒子的中奖概率永远是一个盒子的两倍的。&lt;/p&gt;
&lt;p&gt;到了这里，这个问题似乎可以结束了，因为不仅有可以验证的逻辑解释，更有严格的数学证明（就是条件概率的问题，可以用贝叶斯公式证明，详见百度百科）。但是，那个该死的50%的直觉到底是怎么回事？作为一个强迫症患者是绝对不能接受这样的答案的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;子曰：有问题就要解决。&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;于是到各大论坛里面找三门问题的帖子，但是翻来覆去只有上面提到的两个答案，不过明显答案一的支持者更多一点。为了验证自己的结论，支持答案一的同学还实际做了实验（扑克牌选择，重复100次），而且不管是仿真还是实际的实验结果都是支持更换之后2/3的概率的，这一点也让答案二的支持者无话可说。不过，坚持答案二的同学同样也有理论支撑：在一个独立重复的选择实验中，概率当然是50%了；因此在空盒子拿走之后，分属于剩下两个盒子的概率都会从1/3增加到1/2。这种解释看上去也是科学的。那么，问题到底出在哪里？&lt;/p&gt;
&lt;p&gt;在反复翻阅各种帖子之后，突然看到了一个更新颖的实验：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;引用 500 楼 juven201314 的回复:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;这个我亲自做过实验，也不复杂，大家自己可以试下，结果如下：&lt;br /&gt;
一直坚持不换：中奖接近1/3&lt;br /&gt;
一直坚持换：中奖接近2/3&lt;br /&gt;
随便换或不换：中奖接近1/2&lt;br /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;怎么会有“随便换或不换”的场景呢？仔细想了想，还真的有这种场景，而且这就是这个问题产生如此大的争议的关键！&lt;/p&gt;
&lt;p&gt;我们再还原一下现场：如果让你预先（在主持人第二次操作之前）决定好换不换的话，不管你的决定是一定要换还是一定不换，本质上都是选择一个盒子还是选择两个盒子的问题，而且这与主持人知不知道奖品位置&lt;strong&gt;无关&lt;/strong&gt;；但是如果让你在主持人操作之后再做一次选择的话，由于你的选择是一个独立重复事件，会自动产生一次概率分配（即选择换与不换的概率各为50%），所以在选择之后最终概率也变成了50%（=2/3×50% + 1/3×50%）。&lt;/p&gt;
&lt;p&gt;可以看出，这个问题的结果实际上完全取决于第二次是否做选择，如果做选择，那么胜负的概率结果必然是1/2；如果不做选择，那就是明确的1/3或2/3。这一点相对不大好理解，这也是很多人感到困惑的地方。&lt;/p&gt;
&lt;p&gt;还有很多坚持换的同学会举100000000个盒子的极端情况的例子，随机选择一个盒子的中奖概率自然是只有1/100000000，拿掉99999998个空盒子之后，先前选择的中奖概率仍然是1/100000000，不会改变，这也是这些同学坚信概率不相等的一个依据。这种做法确实也有一定的道理，但是，换个角度来看，如果每拿掉一个空盒子的时候都做一次选择，或者更极端一点，只在最后空盒子都拿掉之后做一次选择，其中奖概率都是50%，因为每一次选择都是一个独立事件，本来概率很高的盒子的概率被人为的选择拉低了。&lt;/p&gt;
&lt;p&gt;很多人为2/3还是1/2争论的本质还是在于讨论的场景不同，2/3的同学坚决要换，而1/2的同学在自己心里做了一次选择……所以两群人说的都是对的；但是既然不管换不换是50%，坚持换是2/3，当然还是换好，结果总会≥50%……其实这里我还是混淆概念了 :)&lt;/p&gt;
&lt;p&gt;很多选择换与不换都一样的同学最终发现结果只有惨兮兮的1/3的概率的原因在于，在知道换与不换结果相同的情况下在心理上就有意无意地排除了更换的选项。尤其是像我这样的懒癌晚期患者，在知道无论换与不换的结果都一样之后都会毅然决然地选择不换（换不换都一样，干嘛要这么多此一举），然而这实际上就会把问题转化成了“选择坚持不换”，结果当然就由1/2变成了惨淡的1/3。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;综上，这个问题的终极答案是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;“我换”，那么中奖的概率是2/3；&lt;/li&gt;
&lt;li&gt;“我不换”，那么中奖的概率是1/3；&lt;/li&gt;
&lt;li&gt;“我选择换”，那么中奖的概率是50%；&lt;/li&gt;
&lt;li&gt;是的，答案就是坑爹的不确定 :)&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;致谢&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;感谢 &lt;strong&gt;&lt;a href="http://bbs.csdn.net/topics/350030757?page=11#post-351229731"&gt;Juvan201314&lt;/a&gt;&lt;/strong&gt; 网友启发。&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Wed, 13 May 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-05-13:pages/essays/monty-hall-problem/</guid><category>Undefined</category></item><item><title>Best Practices of Storm —— 分布式实时计算应用篇(二)</title><link>http://weyo.me/pages/techs/storm-best-practices/</link><description>&lt;h1&gt;Storm 学习曲线&lt;/h1&gt;
&lt;p&gt;目前业界 Storm 的学习资料大多比较零散，系统性的资料不多，新手（从零开始，完全没有分布式计算经验积累的新人）往往很容易会被各种概念迷惑，加上 Storm 社区非常活跃，各个发行版之间的变化较大，而网上的很多帖子、博客还是几年前的资料，并不完全兼容当前版本的特性，导致新手阶段的学习异常痛苦。笔者按照个人的经验总结了一些基本的学习路径，希望能够对新同学有所帮助。由于笔者也才入门不久，以下内容还存在不少问题，欢迎大家批评指正。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Storm 集群组件 —— nimbus/supervisor;&lt;/li&gt;
&lt;li&gt;Storm topology 组件 —— spout/bolt;&lt;/li&gt;
&lt;li&gt;Storm 的并发模型 —— worker/executor/task;&lt;/li&gt;
&lt;li&gt;Storm 高级模型 —— Trident;&lt;/li&gt;
&lt;li&gt;Storm 的分布式RPC —— DRPC;&lt;/li&gt;
&lt;li&gt;Storm 的消息可靠性保障 —— ack 机制;&lt;/li&gt;
&lt;li&gt;Storm 的集群协调 —— Storm 与 ZooKeeper;&lt;/li&gt;
&lt;li&gt;Storm 的消息传输机制（worker内部/worker之间）;&lt;/li&gt;
&lt;li&gt;Storm 实时计算的平滑窗口;&lt;/li&gt;
&lt;li&gt;大规模数据流的 partition 与 join；&lt;/li&gt;
&lt;li&gt;TBC...&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;h3&gt;几点说明&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;1~3 是 Storm 的基础，是必须掌握的内容；&lt;/li&gt;
&lt;li&gt;如果需要使用简单的封装模型快速开发，需要先了解 4；&lt;/li&gt;
&lt;li&gt;如果有 RPC 应用开发需求，需要了解 5；&lt;/li&gt;
&lt;li&gt;如果实时计算应用对消息可靠性要求较高，必须熟悉 6，进一步可以了解 7, 8的相关内容；&lt;/li&gt;
&lt;li&gt;9 及后续内容是目前实时计算的技术难点，尚未有较完美的解决方案，可以根据需要深入钻研。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Storm 最佳实践&lt;/h1&gt;
&lt;h2&gt;Good Use of Storm+Trident&lt;/h2&gt;
&lt;p&gt;摘自 Storm 官方 &lt;a href="http://storm.apache.org/documentation/FAQ.html"&gt;FAQ&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;number of workers a multiple of number of machines; parallelism a multiple of number of workers; number of kafka partitions a multiple of number of spout parallelism&lt;/li&gt;
&lt;li&gt;Use one worker per topology per machine&lt;/li&gt;
&lt;li&gt;Start with fewer, larger aggregators, one per machine with workers on it&lt;/li&gt;
&lt;li&gt;Use the isolation scheduler&lt;/li&gt;
&lt;li&gt;Use one acker per worker -- 0.9 makes that the default, but earlier versions do not.&lt;/li&gt;
&lt;li&gt;enable GC logging; you should see very few major GCs if things are in reasonable shape.&lt;/li&gt;
&lt;li&gt;set the trident batch millis to about 50% of your typical end-to-end latency.&lt;/li&gt;
&lt;li&gt;Start with a max spout pending that is for sure too small -- one for trident, or the number of executors for storm -- and increase it until you stop seeing changes in the flow. You'll probably end up with something near 2&lt;em&gt;(throughput in recs/sec)&lt;/em&gt;(end-to-end latency) (2x the Little's law capacity).&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;翻译说明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;worker 的数量最好是服务器数量的倍数；topology 的总并发度(parallelism)最好是 worker 数量的倍数；Kafka 的分区数(partitions)最好是 Spout (特指 &lt;code&gt;KafkaSpout&lt;/code&gt;)的并发度的倍数&lt;/li&gt;
&lt;li&gt;每个机器(supervisor)上最好只部署一个worker&lt;/li&gt;
&lt;li&gt;应该在一开始使用较少的大聚合器，并且最好在每个有 worker 进程的机器上分配一个&lt;/li&gt;
&lt;li&gt;使用独立的调度器(scheduler)&lt;/li&gt;
&lt;li&gt;每个 worker 上只配置使用一个 acker —— 这是 0.9.x 版本的默认特性，但在早期版本中有所不同；&lt;/li&gt;
&lt;li&gt;在配置文件中开启 GC 日志记录；如果一切正常，日志中的 major GC 应该会非常少；&lt;/li&gt;
&lt;li&gt;将 trident 的 batch interval 配置为大约50%的端到端平均时延大小的千分之一&lt;/li&gt;
&lt;li&gt;开始时设置一个很小的 &lt;code&gt;TOPOLOGY_MAX_SPOUT_PENDING&lt;/code&gt;（对于 trident 可以设置为1，对于一般的 topology 可以设置为 executor 的数量），然后逐渐增大，直到数据流不再发生变化。这时你可能会发现结果大约等于 &lt;code&gt;“2 × 吞吐率(每秒收到的消息数) × 端到端时延”&lt;/code&gt; （最小的额定容量的2倍）。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Updating...&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sat, 25 Apr 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-04-25:pages/techs/storm-best-practices/</guid><category>Storm</category><category>分布式计算</category><category>实时计算</category></item><item><title>Storm 与 ZooKeeper —— 分布式实时计算提升篇(一)</title><link>http://weyo.me/pages/techs/storm-with-zookeeper/</link><description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;本文主要参考自 xumingming 的博文 &lt;a href="http://xumingming.sinaapp.com/466/twitter-storm-code-analysis-zookeeper-dirs/"&gt;&lt;strong&gt;Twitter Storm源代码分析之ZooKeeper中的目录结构&lt;/strong&gt;&lt;/a&gt;。由于新版本的 Storm 在架构上有了较大的变化，相应的目录结构也有了一些改变。本文主要针对 0.9.x 版本的 Storm 的相关结构做了一些说明。&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Storm 的集群运行与状态记录都是由其依赖的 ZooKeeper 完成的。在 ZooKeeper 的客户端可以直接查看相关节点信息。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[zk: localhost:2181(CONNECTED) 1] ls /storm
[workerbeats, errors, supervisors, storms, assignments]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;从这里可以看出 Storm 在 ZooKeeper 的根节点下记录了5个集群相关属性节点: workerbeats, errors, supervisors, storms, assignments。具体的节点信息如下所示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/-storm                     -- storm在zookeeper上的根目录
  |
  |-/assignments            -- topology的任务分配信息
  |   |
  |   |-/{topology-id}      -- 这个下面保存的是每个
  |                            topology的assignments
  |                            信息包括： 对应的
  |                            nimbus上的代码目录,所有
  |                            task的启动时间,
  |                            每个task与机器、端口的映射
  |
  |-/storms                 -- 这个目录保存所有正在运行
  |   |                        的topology的id
  |   |
  |   |-/{topology-id}      -- 这个文件保存这个topology
  |                            的一些信息，包括topology的
  |                            名字，topology开始运行的时
  |                            间以及这个topology的状态
  |                            (具体看StormBase类)
  |
  |-/supervisors            -- 这个目录保存所有的supervisor
  |   |                        的心跳信息
  |   |
  |   |-/{supervisor-id}    -- 这个文件保存的是supervisor
  |                            的心跳信息包括:心跳时间，主
  |                            机名，这个supervisor上worker
  |                            的端口号运行时间
  |                            (具体看SupervisorInfo类)
  |
  |-/workerbeats            -- 所有worker的心跳
  |   |
  |   |-/{topology-id}      -- 这个目录保存这个topology的所
  |       |                    有的worker的心跳信息
  |       |
  |       |-/{worker-id}    -- worker的心跳信息
  |
  |-/errors                 -- 所有component所产生的error信息
      |
      |-/{topology-id}      -- 这个目录保存这个topology下面
          |                    所有component的出错信息(包括
          |                    topology的所有component与系
          |                    统的“_acker”
          |
          |-/{component-id} -- 这个component的出错信息
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;对比原先的目录结构与现在的目录结构可以发现，最大变化的是将记录 task 信息改为了记录 worker 与 component 的信息。这种改变体现在 Storm 系统设计上就是实时计算组件的功能分离简化，将 Storm 集群的最小任务单元(task)剥离了工作线程的功能，使得 task 可以聚焦于实时数据处理任务，同时使集群负载调整更加灵活。有趣的是，Hadoop 也通过 Yarn 实现了集群组件功能的分离简化，这也是分布式计算系统的一个发展方向。&lt;/p&gt;
&lt;p&gt;可以查看 ZooKeeper 中记录的具体的 topology 信息如下&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;lojure.lang.APersistentMapx��c�SpI_hashI_hasheqxp��������  ppsr0clojure.lang.PersistentHashMap&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;BitmapIndexedNode&lt;/span&gt;&lt;span class="x"&gt;�.��&amp;#39;�uIbitmap[arrayt[Ljava/lang/Object;Leditt-Ljava/util/concurrent/atomic/AtomicReference;xp@�ur[Ljava.lang.Object;��X�s)lxptother-operatorsrjava.lang.Long;��̏&lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="x"&gt;�Jvaluexrjava.lang.Number���&lt;/span&gt;
&lt;span class="x"&gt;                                                                                                                                   ���xpt&lt;/span&gt;
&lt;span class="x"&gt;                                                                                                                                              distributionsrjava.lang.Integer⠤���8Ivaluexq~t&lt;/span&gt;
&lt;span class="x"&gt;rand-spoutsq~puq~&lt;/span&gt;
&lt;span class="x"&gt;                  t&lt;/span&gt;
&lt;span class="x"&gt;                   kafka-spoutq~tspeed-operatorq~ppppsr+java.util.concurrent.atomic.AtomicReference�Wq�UxT�Lvalueq~xppt&lt;/span&gt;
&lt;span class="x"&gt;                                                                                                                               ch-operatorq~__systemsq~psq�uq~&lt;/span&gt;
&lt;span class="x"&gt;                                                                                                                                                                t__ackerq~consumersq~ppppq~sq~sq~UA�sq~srclojure.lang.PersistentArrayMap�(6�!�L_metaq~[arrayq~    xq~��������puq~&lt;/span&gt;
&lt;span class="x"&gt;                                                                                        srclojure.lang.Keyword91�bzYIhashL_strtLjava/lang/String;LsymtLclojure/lang/Symbol;xpJ��t:typesrclojure.lang.Symbol����D�IhashL_metaq~L_strq~,Lnameq~,Lnsq~,xp��c=pttypeq~2psq~+�ߵt:activesq~0��e�ptactiveq~6pttopology-alpha&lt;/span&gt;
&lt;span class="x"&gt;cZxid = 0x4000d58d2&lt;/span&gt;
&lt;span class="x"&gt;ctime = Thu Apr 10 16:41:07 CST 2015&lt;/span&gt;
&lt;span class="x"&gt;mZxid = 0x4000d58d2&lt;/span&gt;
&lt;span class="x"&gt;mtime = Thu Apr 10 16:41:07 CST 2015&lt;/span&gt;
&lt;span class="x"&gt;pZxid = 0x4000d58d2&lt;/span&gt;
&lt;span class="x"&gt;cversion = 0&lt;/span&gt;
&lt;span class="x"&gt;dataVersion = 0&lt;/span&gt;
&lt;span class="x"&gt;aclVersion = 0&lt;/span&gt;
&lt;span class="x"&gt;ephemeralOwner = 0x0&lt;/span&gt;
&lt;span class="x"&gt;dataLength = 1503&lt;/span&gt;
&lt;span class="x"&gt;numChildren = 0&lt;/span&gt;
&lt;span class="x"&gt;[zk: localhost:2181(CONNECTED) 39] get /storm/storms/topology-alpha-3-1430383278&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Updating...&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sun, 19 Apr 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-04-19:pages/techs/storm-with-zookeeper/</guid><category>Storm</category><category>ZooKeeper</category><category>分布式计算</category><category>实时计算</category></item><item><title>Storm 常见问题 —— 分布式实时计算应用篇(一)</title><link>http://weyo.me/pages/techs/storm-questions/</link><description>&lt;h1&gt;Storm 安装与运维问题&lt;/h1&gt;
&lt;h3&gt;运行 storm 命令报错&lt;/h3&gt;
&lt;p&gt;出现语法错误：&lt;br /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;File &amp;quot;/home/storm/apache-storm-0.9.3/bin/storm&amp;quot;, line 61
   normclasspath = cygpath if sys.platform == &amp;#39;cygwin&amp;#39; else identity
                            ^
SyntaxError: invalid syntax
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这是由于系统中安装的低版本 Python 部分语法不支持，需要重新安装高版本 Python（如2.7.x）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：部分系统Python默认安装位置不是 &lt;code&gt;/usr/bin/python&lt;/code&gt;，必须在 Python 安装完成之后将安装版本Python关联到该位置。参考操作方法：
 &lt;code&gt;cd /usr/bin&lt;/code&gt;
 &lt;code&gt;mv python python.bk&lt;/code&gt;
 &lt;code&gt;ln -s /usr/local/Python-2.7.8/python python&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h3&gt;Storm 在 ssh 断开后自动关闭&lt;/h3&gt;
&lt;p&gt;这是由于 Storm 是由默认的 Shell 机制打开运行，在 ssh 或 telnet 断开后终端会将挂断信号发送到控制进程，进而会关闭该 Shell 进程组中的所有进程。因此需要在 Storm 后台启动时使用 &lt;code&gt;nohup&lt;/code&gt; 命令和 &lt;code&gt;&amp;amp;&lt;/code&gt; 标记可以使进程忽略挂断信号，避免程序的异常退出：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nohup storm nimbus &amp;amp;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nohup storm ui &amp;amp;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nohup storm supervisor &amp;amp;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nohup storm logviewer &amp;amp;&lt;/code&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Storm UI 网页无法打开&lt;/h3&gt;
&lt;p&gt;检查 Storm 主机（nimbus 与 ui 所在运行服务器）的防火墙设置，是否存在监控端口屏蔽（ui 的默认端口是 8080）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;[注] 测试环境下可以不考虑安全问题直接关闭防火墙&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h3&gt;Strom UI 网页中没有 topology 信息&lt;/h3&gt;
&lt;p&gt;只有集群（Cluster）模式的 topology 才会在监控页面显示，需要将提交到集群的 topology 的运行模式由本地模式（local mode）改为集群模式&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Storm UI 网页中无法打开各个端口的 worker.log&lt;/h3&gt;
&lt;p&gt;在需要查看 log 的机器上启动 logviewer 进程：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nohup storm logviewer &amp;amp;&lt;/code&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;supervisor 启动报错&lt;/h3&gt;
&lt;p&gt;supervisor 启动后异常退出，日志中显示以下错误信息：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 2015-04-29T09:08:59.771+0800 b.s.event [ERROR] Error when processing event
 java.io.FileNotFoundException: File &amp;#39;/home/storm/workdir/supervisor/stormdist/storm-test-1-1429603683/stormconf.ser&amp;#39; does not exist
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这主要是在 storm 中有 topology 运行的情况下（错误信息中显示的 storm topology 名称为 “storm-test”），启动 supervisor 时会先尝试清空数据，supervisor 启动后准备重新载入 topology 数据时就会出错。所以，直接的解决办法是先 kill 掉 topology，然后再次启动 supervisor。  &lt;/p&gt;
&lt;p&gt;另一种解决方法是先启动另一台闲置的 supervisor 服务器，等待集群刷新 topology 数据，然后再启动第一台 supervisor 机器，当然，这种方法的前提是有另一台闲置的服务器。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;[补充说明]&lt;/strong&gt; 这是 storm 的 0.9.4 以下版本的 bug，目前已修复但未合并到发布版本中，因此仍然需要手动处理。网上盛传需要清空、重启 zookeeper，实际上没有必要，而且在生产环境中会造成严重问题。另外一种说法是将 “&lt;code&gt;nimbus.monitor.freq.secs&lt;/code&gt;” 配置为120（默认为10），这种做法没有尝试过，效果有待观察。&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h3&gt;expected '&amp;lt;document start&gt;', but found BlockMappingStart 错误&lt;/h3&gt;
&lt;p&gt;Storm 启动失败，在 nohup.out 中有如下错误信息&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Exception in thread &amp;quot;main&amp;quot; expected &amp;#39;&amp;lt;document start&amp;gt;&amp;#39;, but found BlockMappingStart
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;一般在这类信息后会有相关错误位置说明信息，如&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;in &amp;#39;reader&amp;#39;, line 23, column 2:
     nimbus.host: &amp;quot;hd124&amp;quot;
     ^
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;或者&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;in &amp;#39;reader&amp;#39;, line 7, column 1:
     storm.zookeeper.port: 2181
     ^
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这类错误主要是storm.yaml文件的配置格式错误造成的，一般是配置项的空格遗漏问题。如上面两例分别表示nimbus.host与storm.zookeeper.port两个配置项开头缺少空格，或者“:”后缺少空格。正确添加空格后重新启动Storm即可。&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;Storm 应用开发问题&lt;/h1&gt;
&lt;h3&gt;Storm 本地调试报错&lt;/h3&gt;
&lt;p&gt;本地模式运行 topology 时报错：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java.lang.NoSuchMethodError: org.yaml.snakeyaml.Yaml.&amp;lt;init&amp;gt;(Lorg/yaml/snakeyaml/constructor...&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这是由于testng的包依赖冲突造成的，需要修改 &lt;code&gt;pom.xml&lt;/code&gt;：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="nt"&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.testng&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;testng&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;6.8.5&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;test&lt;span class="nt"&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;lt;exclusions&amp;gt;&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;snakeyaml&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.yaml&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;
       &lt;span class="nt"&gt;&amp;lt;/exclusions&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h3&gt;Storm worker 数量与配置数量不一致&lt;/h3&gt;
&lt;p&gt;在 topology 中设置 worker 数量：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;conf.setNumWorkers(6);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;但是，集群中实际的 worker 数量却不到6。&lt;/p&gt;
&lt;p&gt;这是由于每个 supervisor 中有 worker 数量的上限，这个上限值除了要满足系统允许的最大 slot 上限值 &lt;code&gt;8&lt;/code&gt; 之外，还需要小于 Storm 配置文件中的端口数量：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;supervisor.slots.ports:
    - 6700
    - 6701
    - 6702
    - 6703
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;例如这里 supervisor 只配置了 4 个端口，那么在这个 supervisor 上最多只能运行 4 个 worker 进程。因此，如果需要更多的 worker 就需要配置更多的端口。&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;日志无法记录到程序中配置的路径&lt;/h3&gt;
&lt;p&gt;Storm 默认将日志统一记录到 &lt;code&gt;$STORM_HOME/logs&lt;/code&gt; 目录中，不支持在程序中自定义的路径。但是，集群的日志记录目录是可以修改的，0.9 以上版本的 Storm 可以在 &lt;code&gt;$STORM_HOME/logback/cluster.xml&lt;/code&gt; 配置文件中修改，其他早期版本可以在 &lt;code&gt;log4j/*.properties&lt;/code&gt; 配置文件中修改。&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;log4j 包冲突&lt;/h3&gt;
&lt;p&gt;传统的日志记录方法是如下所示引入 apache 的 log4j 包来记录日志&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.log4j.Logger&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ClassifyBolt&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;private&lt;/span&gt; &lt;span class="n"&gt;static&lt;/span&gt; &lt;span class="n"&gt;final&lt;/span&gt; &lt;span class="n"&gt;Logger&lt;/span&gt; &lt;span class="n"&gt;LOG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getLogger&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ClassifyBolt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这种方式在 Storm 开发中会报包冲突错误&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SLF4J&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Class&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="n"&gt;contains&lt;/span&gt; &lt;span class="n"&gt;multiple&lt;/span&gt; &lt;span class="n"&gt;SLF4J&lt;/span&gt; &lt;span class="n"&gt;bindings&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;SLF4J&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Found&lt;/span&gt; &lt;span class="n"&gt;binding&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;jar&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;:/&lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;:/&lt;/span&gt;&lt;span class="n"&gt;maven&lt;/span&gt;&lt;span class="sr"&gt;/repository/ch/qos/logback/logback-classic/1.0.13/logback-classic-1.0.13.jar!/org/slf4j/impl/&lt;/span&gt;&lt;span class="n"&gt;StaticLoggerBinder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;SLF4J&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Found&lt;/span&gt; &lt;span class="n"&gt;binding&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;jar&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;:/&lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;:/&lt;/span&gt;&lt;span class="n"&gt;maven&lt;/span&gt;&lt;span class="sr"&gt;/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/&lt;/span&gt;&lt;span class="n"&gt;StaticLoggerBinder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;SLF4J&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;See&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;://&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;slf4j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;codes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;html&lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="n"&gt;multiple_bindings&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt; &lt;span class="n"&gt;explanation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;SLF4J&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Actual&lt;/span&gt; &lt;span class="n"&gt;binding&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;type&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;qos&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;logback&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;classic&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;util&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;ContextSelectorStaticBinder&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;SLF4J&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Detected&lt;/span&gt; &lt;span class="n"&gt;both&lt;/span&gt; &lt;span class="n"&gt;log4j&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;over&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;slf4j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;jar&lt;/span&gt; &lt;span class="n"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;slf4j&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;log4j12&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;jar&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;preempting&lt;/span&gt; &lt;span class="n"&gt;StackOverflowError&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; 
&lt;span class="n"&gt;SLF4J&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;See&lt;/span&gt; &lt;span class="n"&gt;also&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;://&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;slf4j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;codes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;html&lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="n"&gt;log4jDelegationLoop&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;more&lt;/span&gt; &lt;span class="n"&gt;details&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;thread&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;main&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;java&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;ExceptionInInitializerError&lt;/span&gt;
    &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;apache&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;log4j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;Logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getLogger&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;java&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;apache&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;log4j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;Logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getLogger&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;java&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;43&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;enjoyor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;storm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;estimation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;bolt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;ClassifyBolt&lt;/span&gt;&lt;span class="o"&gt;.&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;clinit&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;(&lt;/span&gt;&lt;span class="n"&gt;ClassifyBolt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;java&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;enjoyor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;storm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;estimation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;topology&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;SimulationTopology&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SimulationTopology&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;java&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;153&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Caused&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;java&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;IllegalStateException&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Detected&lt;/span&gt; &lt;span class="n"&gt;both&lt;/span&gt; &lt;span class="n"&gt;log4j&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;over&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;slf4j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;jar&lt;/span&gt; &lt;span class="n"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;slf4j&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;log4j12&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;jar&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;preempting&lt;/span&gt; &lt;span class="n"&gt;StackOverflowError&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;See&lt;/span&gt; &lt;span class="n"&gt;also&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;://&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;slf4j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;codes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;html&lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="n"&gt;log4jDelegationLoop&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;more&lt;/span&gt; &lt;span class="n"&gt;details&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
    &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;apache&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;log4j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;Log4jLoggerFactory&lt;/span&gt;&lt;span class="o"&gt;.&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;clinit&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;(&lt;/span&gt;&lt;span class="n"&gt;Log4jLoggerFactory&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;java&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;49&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="n"&gt;more&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;解决方法是改变日志类处理方式，替换 apache 的依赖为 slf4j 原生包，如下所示&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.slf4j.Logger&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.slf4j.LoggerFactory&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ClassifyBolt&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;private&lt;/span&gt; &lt;span class="n"&gt;static&lt;/span&gt; &lt;span class="n"&gt;final&lt;/span&gt; &lt;span class="n"&gt;Logger&lt;/span&gt; &lt;span class="n"&gt;LOG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LoggerFactory&lt;/span&gt;
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getLogger&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ClassifyBolt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h3&gt;部件命名重复错误&lt;/h3&gt;
&lt;p&gt;对于具有相似功能的 Bolt/Spout 可能会出现命名冲突问题，例如这里定义了三个中介者 Bolt：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;String preInter = &amp;quot;medium&amp;quot;;
String detInter = &amp;quot;medium&amp;quot;;
String devInter = &amp;quot;medium&amp;quot;;

builder.setBolt(preInter, new InterBolt().shuffleGrouping(pre); builder.setBolt(detInter, new InterBolt().shuffleGrouping(det);
builder.setBolt(devInter, new InterBolt().shuffleGrouping(dev);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;虽然他们的变量名不同，但是实际的字符串对象名称是相同的（都是“medium”），这就会产生如下的非法参数错误&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Exception in thread &amp;quot;main&amp;quot; java.lang.IllegalArgumentException: Bolt has already been declared for id medium
    at backtype.storm.topology.TopologyBuilder.validateUnusedId(TopologyBuilder.java:212)
    at backtype.storm.topology.TopologyBuilder.setBolt(TopologyBuilder.java:139)
    at com.enjoyor.storm.estimation.topology.SimulationTopology.main(SimulationTopology.java:182)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;所以，对于不同的部件（Spout/Bolt），务必要区别命名：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;String preInter = &amp;quot;premedium&amp;quot;;
String detInter = &amp;quot;detmedium&amp;quot;;
String devInter = &amp;quot;devmedium&amp;quot;;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这样就能保证部件的ID互不相同，就能够避免错误了。&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;下游Bolt未定义数据流错误&lt;/h3&gt;
&lt;p&gt;在下游Bolt接收数据时，往往会忽略具体的接收数据流名称，例如&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;builder.setBolt(devInter, new InterBolt().shuffleGrouping(dev);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这里的 grouping 过程就忽略了“dev”的数据流ID（streamId），在运行时会报错&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;3839 [main] WARN  backtype.storm.daemon.nimbus - Topology submission exception. (topology name=&amp;#39;simulation&amp;#39;) #&amp;lt;InvalidTopologyException InvalidTopologyException(msg:Component: [devInter] subscribes from non-existent stream: [default] of component [dev])&amp;gt;
7119 [main] ERROR org.apache.storm.zookeeper.server.NIOServerCnxnFactory - Thread Thread[main,5,main] died
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;因为不定义数据流时Spout/Bolt 会默认发送/接收streamId为“default”的数据流，而当上游Bolt发送了包含自定义数据流ID的数据流时，下游Bolt就无法识别，所以此时需要在下游Bolt中定义数据流&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;builder.setBolt(devInter, new InterBolt().shuffleGrouping(dev, signalStream);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这里的“signalStream”就是上游Bolt发送的具体数据流名称。&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Updating...&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Wed, 15 Apr 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-04-15:pages/techs/storm-questions/</guid><category>Storm</category><category>分布式计算</category><category>实时计算</category></item><item><title>Yaml for Java</title><link>http://weyo.me/pages/techs/yaml-for-java/</link><description>&lt;p&gt;最近在学 Storm 的时候发现 Storm 的配置文件是 yaml 格式的，就好奇地查了下这个没听说过的格式（&lt;a href="https://en.wikipedia.org/?title=YAML"&gt;YAML - Wikipedia&lt;/a&gt;），这才发现原来不是什么新新物种，而是 2001 年就推出来了的文件格式。虽然 Yaml 相对于 XML 这种老大哥还差远了，但是后辈小子胜在年轻，有干劲，语法简单，功能强大，而且这几年相关工具的解析速度也提升了不少，大有超越 XML 这种大块头的趋势。简单地试用了下，发现压马路（“yaml”的拼音打出来就是这个）的语法真的是既简洁又优雅，让人爱不释手。于是，就这么愉快地决定了，以后的项目中没有其他要求的情况下全部使用 yaml 来做格式化，让 XML 先飞一会儿……&lt;/p&gt;
&lt;p&gt;言归正传，Google 了一下，评价最好的解析工具还是 snakeyaml：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.yaml&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;snakeyaml&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.15&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;对于下面这样基本的配置文件：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;redis.host: rhost
redis.port: 6379
parse.rule:
    - light
    - weighted
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;使用 snakeyaml 解析 yaml 配置文件非常简单：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="n"&gt;Map&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;loadMap&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;Yaml&lt;/span&gt; &lt;span class="n"&gt;yaml&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Yaml&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="n"&gt;Map&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;map&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;InputStream&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;YamlUtil&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getResourceAsStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;map&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Map&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;)&lt;/span&gt; &lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;load&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;is&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;close&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;对于下面这样比较复杂的对象 dump 文件：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;!!me.weyo.yaml.Dev {
  enabled: false,
  inn: {name: III, timeout: 600000000},
  port: 33333,
  type: T1
}
--- !!me.weyo.yaml.Dev { 
  enabled: true,
  inn: {name: UH, timeout: 180003300},
  port: 10028,
  type: T2
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;也可以很轻松的解析：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;loadObjects&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;Yaml&lt;/span&gt; &lt;span class="n"&gt;yaml&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Yaml&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;InputStream&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;YamlUtil&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getResourceAsStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ArrayList&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;loadAll&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;is&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;close&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;当然，如果有需要，还可以将对象 dump 到文件中：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Yaml&lt;/span&gt; &lt;span class="n"&gt;yaml&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Yaml&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;RedisConnection&lt;/span&gt; &lt;span class="n"&gt;redis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;RedisConnection&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;redis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setHost&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rh134&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;redis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setPort&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10029&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

&lt;span class="n"&gt;FileWriter&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;FileWriter&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;src/main/resources/topology.yaml&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;printStackTrace&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;dump&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;redis&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;close&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;综上所述，无所不能的 Yaml 真是居家旅行之必备 ：)&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;Q &amp;amp; A&lt;/h1&gt;
&lt;h3&gt;无法创建 Java 对象&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;Exception&lt;/span&gt; &lt;span class="nt"&gt;in&lt;/span&gt; &lt;span class="nt"&gt;thread&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;main&amp;quot;&lt;/span&gt; &lt;span class="nt"&gt;Can&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;t construct a java object for tag:yaml.org,2002:me.weyo.yaml.Dev; exception=java.lang.NoSuchMethodException: me.weyo.yaml.Dev.&amp;lt;init&amp;gt;()&lt;/span&gt;
&lt;span class="s1"&gt; in &amp;#39;&lt;/span&gt;&lt;span class="nt"&gt;reader&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;line&lt;/span&gt; &lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;column&lt;/span&gt; &lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;!!&lt;/span&gt;&lt;span class="nt"&gt;me&lt;/span&gt;&lt;span class="nc"&gt;.weyo.yaml.Dev&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt; 
    &lt;span class="o"&gt;^&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个错误表明被解析的对象（Dev）中没有默认的构造器（即只有带参数的构造器，没有无参构造器，snakeyaml 无法将对象解析为 Bean）。&lt;/p&gt;
&lt;h3&gt;解析错误异常&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Exception in thread &amp;quot;main&amp;quot; while parsing a flow mapping
 in &amp;#39;reader&amp;#39;, line 1, column 40:
     ... me.weyo.yaml.Dev {
                                         ^
expected &amp;#39;,&amp;#39; or &amp;#39;}&amp;#39;, but got Value
 in &amp;#39;reader&amp;#39;, line 3, column 7:
      port: 33333
          ^
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这是被解析的文件中有属性没有以逗号结束的缘故，例如，下面这样的文件描述就少了逗号：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# 错误的配置方式！
!!me.weyo.yaml.Dev {
  enabled: false # 缺少逗号
  inn: {name: III, timeout: 600000000}
  port: 33333
  type: T1
}
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;标记识别异常&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Exception in thread &amp;quot;main&amp;quot; expected &amp;#39;&amp;lt;document start&amp;gt;&amp;#39;, but found Tag
 in &amp;#39;reader&amp;#39;, line 6, column 1:
    !!me.weyo.yaml.Dev ... 
    ^
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这是由于缺少不同对象之间的分隔标识，例如这样的定义：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# 错误的配置方式！
!!me.weyo.yaml.Dev {
  enabled: false,
  inn: {name: III, timeout: 600000000},
  port: 33333,
  type: T1
}
!!me.weyo.yaml.Dev { # 缺少分隔符
  enabled: true,
  inn: {name: UH, timeout: 180003300},
  port: 10028,
  type: T2
}
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Tue, 14 Apr 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-04-14:pages/techs/yaml-for-java/</guid><category>Java</category><category>Yaml</category></item><item><title>Kafka-Storm 集成部署</title><link>http://weyo.me/pages/techs/kafka-storm-integration/</link><description>&lt;h3&gt;前言&lt;/h3&gt;
&lt;p&gt;分布式实时计算的主要组件采用基于流式计算的 Apache Storm，而实时计算的数据源来自基础数据输入组件中的 Kafka，如何将 Kafka 的消息数据传入 Storm 就是本文讨论的内容。&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;0. 材料准备&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;正常稳定运行的 Kafka 集群（版本：Kafka 0.8.2）&lt;/li&gt;
&lt;li&gt;正常稳定运行的 Storm 集群（版本：Storm 0.9.8）&lt;/li&gt;
&lt;li&gt;Maven 3.x&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt;1. Storm Topology 工程&lt;/h3&gt;
&lt;p&gt;Storm 的任务（Job）称为 Topology，为了处理实时计算任务，需要新建一个 Storm Topology 工程。由于 Kafka 的消息传输模式，所谓的 Kafka-Storm 集成部署实际上就是需要实现一个接收 Kafka 消息的 Spout 接口。幸运的是，最新的 Storm 官方版本中已经内置了可靠的 KafkaSpout，不需要再去手工编写，只需要将 KafkaSpout 配置为 Topology 的输入数据源即可。&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;2. Maven 配置&lt;/h3&gt;
&lt;p&gt;本项目工程基于 Maven 构建。&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要配置的主要依赖&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="nt"&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.storm&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;storm-kafka&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;0.9.3&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;provided&lt;span class="nt"&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.storm&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;storm-core&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;0.9.3&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;provided&lt;span class="nt"&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.kafka&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;kafka_2.10&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;0.8.2.1&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;provided&lt;span class="nt"&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;注意：这里的依赖的 scope 均为“provided”&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Maven 编译配置&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="nt"&gt;&amp;lt;build&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;finalName&amp;gt;&lt;/span&gt;storm-kafka-topology&lt;span class="nt"&gt;&amp;lt;/finalName&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;resources&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;resource&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;directory&amp;gt;&lt;/span&gt;src/main/resources&lt;span class="nt"&gt;&amp;lt;/directory&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/resource&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/resources&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;plugins&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-compiler-plugin&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;3.1&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;source&amp;gt;&lt;/span&gt;1.7&lt;span class="nt"&gt;&amp;lt;/source&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;target&amp;gt;&lt;/span&gt;1.7&lt;span class="nt"&gt;&amp;lt;/target&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-shade-plugin&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;executions&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;execution&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;phase&amp;gt;&lt;/span&gt;package&lt;span class="nt"&gt;&amp;lt;/phase&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;goals&amp;gt;&lt;/span&gt;
                            &lt;span class="nt"&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;shade&lt;span class="nt"&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;finalName&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;project&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;artifactId&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;-&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;project&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;-shade&lt;span class="nt"&gt;&amp;lt;/finalName&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;filters&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;filter&amp;gt;&lt;/span&gt;
                            &lt;span class="nt"&gt;&amp;lt;artifact&amp;gt;&lt;/span&gt;*:*&lt;span class="nt"&gt;&amp;lt;/artifact&amp;gt;&lt;/span&gt;
                            &lt;span class="nt"&gt;&amp;lt;excludes&amp;gt;&lt;/span&gt;
                                &lt;span class="nt"&gt;&amp;lt;exclude&amp;gt;&lt;/span&gt;META-INF/*.SF&lt;span class="nt"&gt;&amp;lt;/exclude&amp;gt;&lt;/span&gt;
                                &lt;span class="nt"&gt;&amp;lt;exclude&amp;gt;&lt;/span&gt;META-INF/*.DSA&lt;span class="nt"&gt;&amp;lt;/exclude&amp;gt;&lt;/span&gt;
                                &lt;span class="nt"&gt;&amp;lt;exclude&amp;gt;&lt;/span&gt;META-INF/*.RSA&lt;span class="nt"&gt;&amp;lt;/exclude&amp;gt;&lt;/span&gt;
                            &lt;span class="nt"&gt;&amp;lt;/excludes&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;/filter&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/filters&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;artifactSet&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;excludes&amp;gt;&lt;/span&gt;
                            &lt;span class="nt"&gt;&amp;lt;exclude&amp;gt;&lt;/span&gt;log4j:log4j:jar:&lt;span class="nt"&gt;&amp;lt;/exclude&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;/excludes&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/artifactSet&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;transformers&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;transformer&lt;/span&gt;
                            &lt;span class="na"&gt;implementation=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&amp;quot;&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;transformer&lt;/span&gt;
                            &lt;span class="na"&gt;implementation=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                            &lt;span class="nt"&gt;&amp;lt;mainClass&amp;gt;&lt;/span&gt;storm.kafka.example.StormTopology&lt;span class="nt"&gt;&amp;lt;/mainClass&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;/transformer&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/transformers&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/plugins&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/build&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h3&gt;3. 实现 Topology&lt;/h3&gt;
&lt;p&gt;以下是 Topology 的一个简单示例（Java 版）。  &lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;StormTopology&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;// Topology 关闭命令（通过外部传入消息控制）&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;boolean&lt;/span&gt; &lt;span class="n"&gt;shutdown&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="c1"&gt;// 注册 ZooKeeper 主机&lt;/span&gt;
        &lt;span class="n"&gt;BrokerHosts&lt;/span&gt; &lt;span class="n"&gt;brokerHosts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ZkHosts&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;
                &lt;span class="s"&gt;&amp;quot;hd182:2181,hd185:2181,hd128:2181&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="c1"&gt;// 所接收 Kafka 的 topic 名称&lt;/span&gt;
        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;topic&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;flumeTopic&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="c1"&gt;// ZooKeeper 的注册 node 名称（注意：需要加“/”，否则 ZooKeeper 会无法识别）&lt;/span&gt;
        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;zkRoot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/kafkastorm&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

        &lt;span class="c1"&gt;// 配置 Spout&lt;/span&gt;
        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;spoutId&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;myKafka&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;SpoutConfig&lt;/span&gt; &lt;span class="n"&gt;spoutConfig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;SpoutConfig&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;brokerHosts&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zkRoot&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
                &lt;span class="n"&gt;spoutId&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="c1"&gt;// 配置 Scheme（可选）&lt;/span&gt;
        &lt;span class="n"&gt;spoutConfig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;scheme&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;SchemeAsMultiScheme&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;SimpleMessageScheme&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
        &lt;span class="n"&gt;KafkaSpout&lt;/span&gt; &lt;span class="n"&gt;kafkaSpout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;KafkaSpout&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;spoutConfig&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

        &lt;span class="n"&gt;TopologyBuilder&lt;/span&gt; &lt;span class="n"&gt;builder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;TopologyBuilder&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setSpout&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;kafka-spout&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kafkaSpout&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBolt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;operator&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;OperatorBolt&lt;/span&gt;&lt;span class="o"&gt;())&lt;/span&gt;
                &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;shuffleGrouping&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;kafka-spout&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

        &lt;span class="n"&gt;Config&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setDebug&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setNumWorkers&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

        &lt;span class="c1"&gt;// 测试环境采用 local mode 模式&lt;/span&gt;
        &lt;span class="n"&gt;LocalCluster&lt;/span&gt; &lt;span class="n"&gt;cluster&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;LocalCluster&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;cluster&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;submitTopology&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;createTopology&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="o"&gt;(!&lt;/span&gt;&lt;span class="n"&gt;shutdown&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;Utils&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;sleep&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;cluster&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;killTopology&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;cluster&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;shutdown&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;由于一个 KafkaSpout 只能接收一个指定 topic 的消息数据，因此，在实际生产环境 Topology 的实现中需要根据业务需求配置 Spout 的个数。&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;4. 必要的依赖包&lt;/h3&gt;
&lt;p&gt;由于 Topology 工程的依赖均为“provided”的 scope，需要将涉及到的依赖jar包拷贝到 Storm 安装目录的 lib 文件夹下，包括：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;kafka_2.10-0.8.2.1.jar&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;storm-kafka-0.9.3.jar&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;scala-library-2.10.4.jar&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;zookeeper-3.4.6.jar&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;curator-client-2.6.0.jar&lt;/li&gt;
&lt;li&gt;curator-framework-2.6.0.jar&lt;/li&gt;
&lt;li&gt;curator-recipes-2.6.0.jar&lt;/li&gt;
&lt;li&gt;guava-16.0.1.jar&lt;/li&gt;
&lt;li&gt;metrics-core-2.2.0.jar  &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h3&gt;5. 上线运行&lt;/h3&gt;
&lt;p&gt;向 Storm 集群提交任务，观察数据输出结果。另外，还可以在 Storm 的 UI 界面查看 Topology 内部组件运行状态（需要使用 &lt;strong&gt;Cluster&lt;/strong&gt; 模式）。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Mon, 13 Apr 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-04-13:pages/techs/kafka-storm-integration/</guid><category>Kafka</category><category>Storm</category><category>环境搭建</category><category>分布式计算</category></item><item><title>Apache Storm —— 分布式实时计算基础篇</title><link>http://weyo.me/pages/techs/storm-basis/</link><description>&lt;h2&gt;关于 Apache Storm&lt;/h2&gt;
&lt;p&gt;&lt;img src=http://storm.apache.org/images/topology.png width="60%" height="60%"  /&gt;  &lt;/p&gt;
&lt;p&gt;（翻译自 &lt;a href="http://storm.apache.org/"&gt;Storm 官网&lt;/a&gt;）Apache Storm 是 Apache 基金会的开源的分布式实时计算系统。与 Hadoop 的批处理相类似，Storm 可以对大量的数据流进行可靠的实时处理，这一过程也称为“流式处理”，是分布式大数据处理的一个重要方向。Storm 支持多种类型的应用，包括：实时分析、在线机器学习、连续计算、分布式RPC（DRPC）、ETL等。Strom 的一个重要特点就是“&lt;strong&gt;快速&lt;/strong&gt;”的数据处理，有 benchmark 显示 Storm 能够达到单个节点每秒百万级 tuple 处理（tuple 是 Storm 的最小数据单元）的速度。快速的数据处理、优秀的可扩展性与容错性、便捷的可操作性与维护性、活跃的社区技术支持，这就是 Storm。&lt;br /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Storm 集群组件&lt;/h2&gt;
&lt;p&gt;&lt;img alt="此处输入图片的描述" src="http://pic002.cnblogs.com/images/2012/79962/2012113013552970.png" /&gt;&lt;/p&gt;
&lt;p&gt;Storm 集群中包含两类节点：主控节点（Master Node）和工作节点（Work Node）。其分别对应的角色如下： &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;主控节点（Master Node）上运行一个被称为Nimbus的后台程序，它负责在Storm集群内分发代码，分配任务给工作机器，并且负责监控集群运行状态。Nimbus的作用类似于Hadoop中JobTracker的角色。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每个工作节点（Work Node）上运行一个被称为Supervisor的后台程序。Supervisor负责监听从Nimbus分配给它执行的任务，据此启动或停止执行任务的工作进程。每一个工作进程执行一个Topology的子集；一个运行中的Topology由分布在不同工作节点上的多个工作进程组成。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nimbus 和 Supervisor 节点之间所有的协调工作是通过 Zookeeper 集群来实现的。此外，Nimbus 和 Supervisor 进程都是快速失败（fail-fast)和无状态（stateless）的；Storm 集群所有的状态要么在 Zookeeper 集群中，要么存储在本地磁盘上。这意味着你可以用 kill -9 来杀死 Nimbus 和 Supervisor 进程，它们在重启后可以继续工作。这个设计使得Storm集群拥有不可思议的稳定性。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Storm 部署步骤&lt;/h2&gt;
&lt;p&gt;搭建一个Storm集群需要依次完成的安装步骤：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;搭建Zookeeper集群；&lt;/li&gt;
&lt;li&gt;安装Storm依赖库(Java、Python)；&lt;/li&gt;
&lt;li&gt;下载并解压Storm发布版本；&lt;/li&gt;
&lt;li&gt;修改storm.yaml配置文件；&lt;/li&gt;
&lt;li&gt;启动Storm各个后台进程。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;storm.yaml 配置&lt;/h2&gt;
&lt;p&gt;Storm发行版本解压目录下有一个conf/storm.yaml文件，用于配置Storm。默认配置在&lt;a href="https://github.com/nathanmarz/storm/blob/master/conf/defaults.yaml"&gt;这里&lt;/a&gt;可以查看。conf/storm.yaml中的配置选项将覆盖defaults.yaml中的默认配置。以下配置选项是必须在conf/storm.yaml中进行配置的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;storm.zookeeper.servers&lt;/strong&gt;: Storm集群使用的Zookeeper集群地址，其格式如下：
storm.zookeeper.servers:  - "111.222.333.444"  - "555.666.777.888"
如果Zookeeper集群使用的不是默认端口，那么还需要storm.zookeeper.port选项。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;storm.local.dir&lt;/strong&gt;: Nimbus和Supervisor进程用于存储少量状态，如jars、confs等的本地磁盘目录，需要提前创建该目录并给以足够的访问权限。然后在storm.yaml中配置该目录，如：
storm.local.dir: "/home/admin/storm/workdir"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;java.library.path: Storm使用的本地库加载路径，默认为"/usr/local/lib:/opt/local/lib:/usr/lib"，一般不需要配置。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;nimbus.host&lt;/strong&gt;: Storm集群Nimbus机器地址，各个Supervisor工作节点需要知道哪个机器是Nimbus，以便下载Topologies的jars、confs等文件，如：
nimbus.host: "111.222.333.444"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;supervisor.slots.ports&lt;/strong&gt;: 对于每个Supervisor工作节点，需要配置该工作节点可以运行的worker数量。每个worker占用一个单独的端口用于接收消息，该配置选项即用于定义哪些端口是可被worker使用的。如果需要在每个节点上运行4个workers，可以分别使用6700、6701、6702和6703端口，如：
 supervisor.slots.ports:    - 6700    - 6701    - 6702    - 6703&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;JVM options&lt;/em&gt;&lt;/strong&gt;: 用于配置Storm使用JVM参数&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;[注]&lt;/strong&gt; yaml 文件的配置使用&lt;code&gt;“-”&lt;/code&gt;来表示数据的层次结构，配置项的&lt;code&gt;:&lt;/code&gt;后必须有空格，否则该配置项无法识别&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;集群配置示例如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;########### These MUST be filled in for a storm configuration
# storm.zookeeper.servers:
#     - &amp;quot;server1&amp;quot;
#     - &amp;quot;server2&amp;quot;
 storm.zookeeper.servers:
    - &amp;quot;192.168.9.182&amp;quot;
    - &amp;quot;192.168.9.185&amp;quot;
    - &amp;quot;192.168.91.128&amp;quot;
 storm.zookeeper.port: 2181
# storm&amp;#39;s work directory
 storm.local.dir: &amp;quot;/home/storm/workdir&amp;quot;
# nimbus.host: &amp;quot;nimbus&amp;quot;
 nimbus.host: &amp;quot;192.168.9.185&amp;quot;
# supervisor&amp;#39;s work ports
 supervisor.slots.ports:
    -6700
    -6701
    -6702
    -6703

# #### Netty transport configuration
# transmission protocol
 storm.messaging.transport: &amp;quot;backtype.storm.messaging.netty.Context&amp;quot;
# server&amp;#39;s work threads number
 storm.messaging.netty.server_worker_threads: 1
# client&amp;#39;s work threads number
 storm.messaging.netty.client_worker_threads: 1
# buffer size
 storm.messaging.netty.buffer_size: 5242880
# max retry times
 storm.messaging.netty.max_retries: 100
# max waiting time(ms)
 storm.messaging.netty.max_wait_ms: 1000
# min waiting time(ms)
 storm.messaging.netty.min_wait_ms: 100

## JVM parameters can be configured here
 nimbus.childopts: &amp;quot;-Xloggc:/home/enjoyor/storm/apache-storm-0.9.3/logs/nimbusGC.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps&amp;quot;
 supervisor.childopts: &amp;quot;-Xloggc:/home/enjoyor/storm/apache-storm-0.9.3/logs/nimbusGC.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps&amp;quot;
 worker.childopts: &amp;quot;-Xloggc:/home/enjoyor/storm/apache-storm-0.9.3/logs/nimbusGC.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h2&gt;Storm 运行&lt;/h2&gt;
&lt;p&gt;和Zookeeper一样，Storm也是快速失败（fail-fast)的系统，这样Storm才能在任意时刻被停止，并且当进程重启后被正确地恢复执行。这也是为什么Storm不在进程内保存状态的原因，即使Nimbus或Supervisors被重启，运行中的Topologies不会受到影响。以下是启动Storm各个后台进程的方式： &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Nimbus&lt;/strong&gt;: 在Storm主控节点上运行 &lt;code&gt;nohup storm nimbus &amp;amp;&lt;/code&gt; 启动Nimbus后台程序，并放到后台执行；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Supervisor&lt;/strong&gt;: 在Storm各个工作节点上运行&lt;code&gt;nohup storm supervisor &amp;amp;&lt;/code&gt; 启动Supervisor后台程序，并放到后台执行；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;UI&lt;/strong&gt;: 在Storm主控节点上运行&lt;code&gt;nohup storm ui &amp;amp;&lt;/code&gt; 启动UI后台程序，并放到后台执行，启动后可以通过 &lt;em&gt;http://{nimbus host}:8080&lt;/em&gt; 观察集群的worker资源使用情况、Topologies的运行状态等信息。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;h4&gt;注意事项：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Storm后台进程被启动后，将在Storm安装部署目录下的logs/子目录下生成各个进程的日志文件。&lt;/li&gt;
&lt;li&gt;经测试，Storm UI必须和Storm Nimbus 部署在同一台机器上，否则UI无法正常工作，因为UI进程会检查本机是否存在Nimbus链接。&lt;/li&gt;
&lt;li&gt;为了方便使用，可以将bin/storm加入到系统环境变量中。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;至此，Storm集群已经部署、配置完毕，可以向集群提交拓扑运行了。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;向 Storm 集群提交任务&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;启动 Storm Topology：&lt;br /&gt;
&lt;code&gt;storm jar allmycode.jar org.me.MyTopology arg1 arg2 arg3&lt;/code&gt;&lt;br /&gt;
 其中，allmycode.jar 是包含 Topology 实现代码的 jar 包，org.me.MyTopology 的 main 方法是 Topology 的入口，arg1、arg2 和 arg3 为 org.me.MyTopology 执行时需要传入的参数。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;停止 Storm Topology：&lt;br /&gt;
&lt;code&gt;storm kill {toponame}&lt;/code&gt;&lt;br /&gt;
 其中，{toponame} 为 Topology 提交到 Storm 集群时指定的 Topology 任务名称。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;h2&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;https://github.com/nathanmarz/storm/wiki/Tutorial&lt;/li&gt;
&lt;li&gt;https://github.com/nathanmarz/storm/wiki/Setting-up-a-Storm-cluster&lt;/li&gt;
&lt;li&gt;http://www.cnblogs.com/panfeng412/archive/2012/11/30/how-to-install-and-deploy-storm-cluster.html&lt;/li&gt;
&lt;li&gt;http://blog.csdn.net/tonylee0329/article/details/42738729&lt;/li&gt;
&lt;li&gt;http://blog.csdn.net/wind19/article/details/4986458&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Sun, 12 Apr 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-04-12:pages/techs/storm-basis/</guid><category>Storm</category><category>环境搭建</category><category>分布式计算</category><category>实时计算</category></item><item><title>Flume-Kafka 集成部署</title><link>http://weyo.me/pages/techs/flume-kafka-integration/</link><description>&lt;h1&gt;前言&lt;/h1&gt;
&lt;p&gt;数据采集与数据传输是大数据/分布式计算技术的两项基本需求。对应于这两项需求，开源社区有很多成熟的解决方案，例如 Scribe，Flume，Chukwa，Kafka，各类MQ等等，基于不同的业务场景可以灵活选择。考虑到我们的实际业务模式与技术特点，在分布式计算系统中需要选择轻量级、可定制性好、扩展性强、易于维护的数据采集与传输单元。其中，采集单元选用模块化程度极高的 Flume-ng，传输单元选择高吞吐率的 Kafka，将两者结合共同构成分布式计算集群的基础数据输入组件。&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;0. 材料准备&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Flume 安装程序（版本：Flume-ng 1.5.3）&lt;/li&gt;
&lt;li&gt;Kafka 安装程序（版本：Kafka 0.8.2）&lt;/li&gt;
&lt;li&gt;Flume-Kafka 插件&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;1. 配置 Flume&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# 配置 flume agent
vi conf/flume-conf.properties
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;## 定义 agent
# 本agent的名称为 “agent181”
agent181.sources = src1
agent181.channels = ch1
agent181.sinks = k1

## 定义 sources
agent181.sources.src1.type = avro
agent181.sources.src1.channels = ch1
# 本地 flume 服务器地址，需要在 hosts 中注册
agent181.sources.src1.bind = hd181
# source 绑定端口
agent181.sources.src1.port = 41414

## 定义 sinks
agent181.sinks.k1.type = com.thilinamb.flume.sink.KafkaSink
# 需要连接的 topic 名称
# 注意：如果此 topic 不存在（即在 Kafka 集群中未创建）则默认连接到一个名为 “default-flume-topic” 的 topic
agent181.sinks.k1.custom-topic = flumeTopic
agent181.sinks.k1.preprocessor = com.thilinamb.flume.sink.example.SimpleMessagePreprocessor
# 需要连接到的 Kafka 服务器地址与端口（这里是 kafka182 ）
agent181.sinks.k1.kafka.metadata.broker.list=kafka182:9092
agent181.sinks.k1.kafka.serializer.class = kafka.serializer.StringEncoder
agent181.sinks.k1.kafka.request.required.acks = 1
agent181.sinks.k1.channel = ch1

## 定义 channels
agent181.channels.ch1.type = memory
agent181.channels.ch1.capacity = 1000
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h1&gt;2. 准备 flume-kafka 插件&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;下载插件&lt;/strong&gt;：（该插件即将集成到1.6版本的 Flume 官方程序中，但在1.5及以下的版本中仍然需要手动配置）&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/thilinamb/flume-ng-kafka-sink"&gt;https://github.com/thilinamb/flume-ng-kafka-sink&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;编译&lt;/strong&gt;：&lt;code&gt;mvn clean install&lt;/code&gt; 或者 &lt;code&gt;mvn package&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;编译完成之后在 &lt;code&gt;dist/target&lt;/code&gt; 目录下会生成 &lt;code&gt;flume-kafka-sink-dist-0.5.0-bin.zip&lt;/code&gt;，解压缩后，在 lib 目录下有四个依赖jar包：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;flume-kafka-sink-impl-x.x.x.jar&lt;/li&gt;
&lt;li&gt;kafka_x.x.-x.x.x.x.jar&lt;/li&gt;
&lt;li&gt;metrics-core-x.x.x.jar&lt;/li&gt;
&lt;li&gt;scala-library-x.x.x.jar&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;添加依赖包&lt;/strong&gt;：在Flume的安装目录下建立 &lt;code&gt;plugins.d&lt;/code&gt; 文件夹，再在该文件夹下建立 &lt;code&gt;kafka-sink&lt;/code&gt; 文件夹，然后在kafka-sink文件夹下建立 &lt;code&gt;lib&lt;/code&gt; 与 &lt;code&gt;libext&lt;/code&gt; 两个文件夹，将 flume-kafka-sink-impl-0.5.0.jar 拷贝到 lib 下，其他三个jar包拷贝到 libext 下，整个目录结构如下所示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;FLUME_HOME&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;
 |-- plugins.d
        |-- kafka-sink
            |-- lib
                |-- flume-kafka-sink-impl-x.x.x.jar
            |-- libext
                |-- kafka_x.x.-x.x.x.x.jar
                |-- metrics-core-x.x.x.jar
                |-- scala-library-x.x.x.jar
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;h2&gt;NOTES&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;上述 Flume 配置文件中提到的 &lt;strong&gt;"默认连接到一个名为 ‘default-flume-topic’ 的 topic"&lt;/strong&gt; 实际上是在&lt;code&gt;flume-ng-kafka-sink&lt;/code&gt;项目中定义的，如果需要修改默认名称等属性，可以修改 &lt;code&gt;Constants&lt;/code&gt; 与 &lt;code&gt;MessagePreprocessor&lt;/code&gt; 接口实现类的 &lt;code&gt;extractTopic&lt;/code&gt; 方法。Key 和 Message 的处理也可以根据需要通过 &lt;code&gt;MessagePreprocessor&lt;/code&gt; 接口的另外两个方法类似实现。由于插件作者写的 &lt;code&gt;SimpleMessagePreprocessor&lt;/code&gt; 中定义了属性名为 &lt;code&gt;custom-topic&lt;/code&gt; 的 topic名称，会对使用者造成一定的混淆，同时额外的 example module 也不便于集成到编译后的插件中，因此，我在原始插件代码的基础上做了一点修改，并更新到 &lt;a href="https://github.com/weyo/flume-ng-kafka-sink"&gt;weyo/flume-ng-kafka-sink&lt;/a&gt; 项目中，可以直接下载并使用 Maven 编译生成需要的插件。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h1&gt;3. 运行&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;启动 Kafka server（每个 flume agent 对应的 Kafka broker，本例中为 kafka182）  &lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bin/kafka-server-start.sh config/server.properties &amp;amp; 
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;创建 Kafka topic（上面 Flume 配置文件中对应的topic名称）  &lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bin/kafka-topics.sh --create --zookeeper zk1:2181 --replication 1 --partition 1 --topic flumeTopic 
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;启动 Kafka consumer  &lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bin/kafka-console-consumer.sh --zookeeper zk1:2181 --topic flumeTopic --from-beginning
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;启动 Flume （本例中为 agent181）  &lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;flume-ng agent -c /home/flume/conf/ -f /home/flume/conf/flume-conf.properties -n agent181 &amp;amp;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;h4&gt;TIPS&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;如果需要监控 agent 配置信息，可以添加 &lt;code&gt;-Dflume.monitoring.type=http -Dflume.monitoring.port=34545&lt;/code&gt; 参数，通过 &lt;code&gt;http://agenthost:34545&lt;/code&gt; 访问 agent 配置信息。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;启动 Flume 数据源发送数据  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 Kafka consumer 客户端观察数据接收情况  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Fri, 10 Apr 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2015-04-10:pages/techs/flume-kafka-integration/</guid><category>Flume</category><category>Kafka</category><category>环境搭建</category><category>分布式计算</category></item><item><title>Bash Shell 获取进程 PID</title><link>http://weyo.me/pages/techs/linux-get-pid/</link><description>&lt;blockquote&gt;
&lt;h2&gt;导读&lt;/h2&gt;
&lt;p&gt;Linux 的交互式 Shell 与 Shell 脚本存在一定的差异，主要是由于后者存在一个独立的运行进程，因此在获取进程 pid 上二者也有所区别。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;交互式 Bash Shell 获取进程 pid&lt;/h2&gt;
&lt;p&gt;在已知进程名(&lt;code&gt;name&lt;/code&gt;)的前提下，交互式 Shell 获取进程 pid 有很多种方法，典型的通过 grep 获取 pid 的方法为（这里添加 &lt;code&gt;-v grep&lt;/code&gt;是为了避免匹配到 grep 进程）：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ps -ef | grep "name" | grep -v grep | awk '{print $2}'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;或者不使用 &lt;code&gt;grep&lt;/code&gt;（这里名称首字母加&lt;code&gt;[]&lt;/code&gt;的目的是为了避免匹配到 awk 自身的进程）：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ps -ef | awk '/[n]ame/{print $2}'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果只使用 x 参数的话则 pid 应该位于第一位：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ps x | awk '/[n]ame/{print $1}'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;最简单的方法是使用 &lt;code&gt;pgrep&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pgrep -f name&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果需要查找到 pid 之后 kill 掉该进程，还可以使用 &lt;code&gt;pkill&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pkill -f name&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果是可执行程序的话，可以直接使用 &lt;code&gt;pidof&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pidof name&lt;/code&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Bash Shell 脚本获取进程 pid&lt;/h2&gt;
&lt;h4&gt;根据进程名获取进程 pid&lt;/h4&gt;
&lt;p&gt;在使用 Shell 脚本获取进程 pid 时，如果直接使用上述命令，会出现多个 pid 结果，例如：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#! /bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;# process-monitor.sh&lt;/span&gt;
&lt;span class="nv"&gt;process&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;
&lt;span class="nv"&gt;pid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;ps x &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="nv"&gt;$process&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; grep -v grep &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$pid&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;执行 &lt;code&gt;process-monitor.sh&lt;/code&gt; 会出现多个结果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&amp;gt; sh process-monitor.sh
3036  3098  3099
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;进一步排查可以发现，多出来的几个进程实际上是子 Shell 的（临时）进程：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;root      3036  2905  0 09:03 pts/1    00:00:45 /usr/java/jdk1.7.0_71/bin/java ...name
root      4522  2905  0 16:12 pts/1    00:00:00 sh process-monitor.sh name
root      4523  4522  0 16:12 pts/1    00:00:00 sh process-monitor.sh name
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;其中 3036 是需要查找的进程pid，而 4522、4523 就是子 Shell 的 pid。
为了避免这种情况，需要进一步明确查找条件，考虑到所要查找的是 Java 程序，就可以通过 Java 的关键字进行匹配：&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#! /bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;# process-monitor.sh&lt;/span&gt;
&lt;span class="nv"&gt;process&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;
&lt;span class="nv"&gt;pid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;ps -ef &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="nv"&gt;$process&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s1"&gt;&amp;#39;/bin/java&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; grep -v grep &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$pid&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;hr /&gt;
&lt;h4&gt;获取 Shell 脚本自身进程 pid&lt;/h4&gt;
&lt;p&gt;这里涉及两个指令：
 1. &lt;code&gt;$$&lt;/code&gt; ：当前 Shell 进程的 pid
 2. &lt;code&gt;$!&lt;/code&gt; ：上一个后台进程的 pid
可以使用这两个指令来获取相应的进程 pid。例如，如果需要获取某个正在执行的进程的 pid（并写入指定的文件）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;myCommand &amp;amp;&amp;amp; pid=$!
myCommand &amp;amp; echo $! &amp;gt;/path/to/pid.file
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;注意，在脚本中执行 &lt;code&gt;$!&lt;/code&gt; 只会显示子 Shell 的后台进程 pid，如果子 Shell 先前没有启动后台进程，则没有输出。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;查看指定进程是否存在&lt;/h2&gt;
&lt;p&gt;在获取到 pid 之后，还可以根据 pid 查看对应的进程是否存在（运行），这个方法也可以用于 kill 指定的进程。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;if ps -p &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;PID&lt;/span&gt;&lt;span class="x"&gt; &amp;gt; /dev/null&lt;/span&gt;
&lt;span class="x"&gt;then&lt;/span&gt;
&lt;span class="x"&gt;   echo &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;PID&lt;/span&gt;&lt;span class="x"&gt; is running&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;   &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="x"&gt; Do something knowing the pid exists, i.e. the process with &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;PID&lt;/span&gt;&lt;span class="x"&gt; is running&lt;/span&gt;
&lt;span class="x"&gt;fi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Thu, 22 May 2014 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2014-05-22:pages/techs/linux-get-pid/</guid><category>Linux</category><category>Shell</category></item><item><title>Linux 系统时间配置</title><link>http://weyo.me/pages/techs/linux-time-setting/</link><description>&lt;blockquote&gt;
&lt;p&gt;本文根据网络资料整理。
Linux 系统时间配置大致可以大致分为“手动”设置与基于 ntp 的配置两种方式。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h3&gt;手动设置系统时间&lt;/h3&gt;
&lt;h4&gt;1. 说明&lt;/h4&gt;
&lt;p&gt;Linux将时钟分为系统时钟(System Clock)和硬件(Real Time Clock，简称RTC)时钟两种。系统时间是指当前Linux Kernel中的时钟，而硬件时钟则是主板上由电池供电的那个主板硬件时钟，这个时钟可以在BIOS的“Standard BIOS Feture”项中进行设置。Linux并没有默认哪个时钟系统。当Linux启动时，硬件时钟会去读取系统时钟的设置，然后系统时钟就会独立于硬件运作。&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;2. 设置方法&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;date 042612492015.28
hwclock –w
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;说明：&lt;br /&gt;
第一步是设置时间，设置完成可以使用date命令查看是否正确，&lt;strong&gt;注意&lt;/strong&gt;：时间设置格式为&lt;strong&gt;&lt;code&gt;月日时分年.秒&lt;/code&gt;&lt;/strong&gt;；&lt;br /&gt;
第二步是将系统时间写入硬件时钟，这样可以避免重启之后需要重新设置系统时间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h4&gt;3. 相关操作命令&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;查看硬件时钟&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;hwclock --show 
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;设置硬件时钟
通用的设置格式：hwclock/clock --set --date=“月/日/年 时：分：秒”。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;hwclock --set --date&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;09/17/2003 13:26:00&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;硬件时钟与系统时钟同步&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;hwclock –hctosys
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;系统时钟与硬件时钟同步&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;hwclock –systohc
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h3&gt;通过 ntpd 服务同步设置时间&lt;/h3&gt;
&lt;h4&gt;1. 说明&lt;/h4&gt;
&lt;p&gt;ntpd 服务是通过网络对系统时间进行同步配置的 Linux 服务，可以确保系统时间的一致性。&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;2. 配置同步时间&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ntpdate &lt;span class="nv"&gt;$ntpserver&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;ntpserver 是网络时间服务器地址。&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;3. 配置系统开机时间同步&lt;/h4&gt;
&lt;p&gt;在&lt;code&gt;/etc/rc.local&lt;/code&gt;中添加&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/usr/sbin/ntpdate &lt;span class="nv"&gt;$ntpserver&lt;/span&gt; &amp;gt;&amp;gt; /var/log/ntpdate.log
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;另外，也可以使用 crontab 来定时对时间进行同步，在&lt;code&gt;/etc/crontab&lt;/code&gt;中添加&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt; * * * root ntpdate &lt;span class="nv"&gt;$ntpserver&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;hwclock -w
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这样每天5:10自动进行网络校时，并同时更新BIOS的时间。&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;4. 网络时间同步服务器&lt;/h4&gt;
&lt;p&gt;时间服务器分为两种，一种是一级时间服务器，另外一种是二级时间服务器。如果是同步自己的服务器的时间，那么选择二级时间服务器，因为一级时间服务器是为二级时间服务器提供时间校对服务器，我们尽量不要增加一级服务器的压力。这种层级的概念和DNS的层级概念是一致的。&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一级时间服务器列表： http://support.ntp.org/bin/view/Servers/StratumOneTimeServers&lt;/li&gt;
&lt;li&gt;二级时间服务器列表： http://support.ntp.org/bin/view/Servers/StratumTwoTimeServers
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;附二级服务器列表&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0.pool.ntp.org            有域名负载均衡
0.cn.pool.ntp.org         有域名负载均衡
ntp.tuna.tsinghua.edu.cn  清华大学
time.windows.com          微软
ntp.fudan.edu.cn          复旦大学
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;注：除了使用外部时间服务器之外，也可以在局域网中搭建独立的时间同步服务器，其他机器从该时间同步服务器获取同步时间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h3&gt;Q&amp;amp;A&lt;/h3&gt;
&lt;h4&gt;1. &lt;strong&gt;no server suitable for synchronization found&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;执行ntpdate命令更新NTP客户端的时间时，如果报以下错误：&lt;br /&gt; 
&lt;code&gt;no server suitable for synchronization found&lt;/code&gt;&lt;br /&gt;
则可采用以下步骤检测：&lt;br /&gt;
(1) 在NTP服务端执行以下命令检测NTP服务是否运行&lt;br /&gt;
&lt;code&gt;service ntpd status&lt;/code&gt;&lt;br /&gt;
(2) 运行ping命令检测NTP客户端与NTP服务端是否连通&lt;br /&gt;
&lt;code&gt;ping NTP服务端IP&lt;/code&gt;&lt;br /&gt;
(3) 在NTP客户端执行&lt;br /&gt;
&lt;code&gt;ntpdate -d NTP服务端IP&lt;/code&gt;&lt;br /&gt;
如果输出结果如下：&lt;br /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="n"&gt;Nov&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="n"&gt;ntpdate&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3521&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ntpdate&lt;/span&gt; &lt;span class="mf"&gt;4.2.2&lt;/span&gt;&lt;span class="n"&gt;p1&lt;/span&gt;&lt;span class="mf"&gt;@1.1570&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="n"&gt;Tue&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;Looking&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;host&lt;/span&gt; &lt;span class="mf"&gt;10.75.80.47&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;service&lt;/span&gt; &lt;span class="n"&gt;ntp&lt;/span&gt;
&lt;span class="n"&gt;host&lt;/span&gt; &lt;span class="nl"&gt;found&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;10.75.80.47&lt;/span&gt;
&lt;span class="n"&gt;transmit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;10.75.80.47&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;transmit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;10.75.80.47&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;transmit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;10.75.80.47&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;transmit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;10.75.80.47&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;transmit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;10.75.80.47&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mf"&gt;10.75.80.47&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;Server&lt;/span&gt; &lt;span class="nl"&gt;dropped&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;no&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="n"&gt;Nov&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt; &lt;span class="n"&gt;ntpdate&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3521&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;no&lt;/span&gt; &lt;span class="n"&gt;server&lt;/span&gt; &lt;span class="n"&gt;suitable&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;synchronization&lt;/span&gt; &lt;span class="n"&gt;found&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;请按以下步骤处理：&lt;br /&gt;
a) 检查NTP服务端使用的ntp版本：&lt;br /&gt;
&lt;code&gt;ntpq -c version&lt;/code&gt;&lt;br /&gt;
如果输出版本是 ntp4.2之后（含4.2）的版本，则请检测是否在restrict的定义中使用了notrust。如果有则删除notrust，再进行NTP时间同步。&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在 /etc/ntp.conf 中检查 restrict 定义
如果有类似 &lt;code&gt;restrict 192.168.0.0 mask 255.255.255.0 notrust nomodify notrap&lt;/code&gt; 的 notrust 定义，则对应删除。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;b) 检查NTP服务端的防火墙是否开放NTP服务端口：udp 123&lt;br /&gt;
&lt;code&gt;service iptables stop&lt;/code&gt;&lt;br /&gt;
执行以上命令关闭NTP服务端的防火墙，然后再进行NTP时间同步&lt;br /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;h3&gt;Reference&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;http://blog.chinaunix.net/uid-234760-id-761243.html&lt;/li&gt;
&lt;li&gt;http://www.chenyudong.com/archives/linux-ntpdate-time-synchronize.html&lt;/li&gt;
&lt;li&gt;http://bbs.chinaunix.net/thread-4131894-1-1.html&lt;/li&gt;
&lt;li&gt;http://blog.csdn.net/weidan1121/article/details/3953021&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">WeYo</dc:creator><pubDate>Tue, 04 Mar 2014 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:weyo.me,2014-03-04:pages/techs/linux-time-setting/</guid><category>Linux</category></item></channel></rss>